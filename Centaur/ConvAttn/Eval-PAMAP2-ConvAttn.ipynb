{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c11f73-2263-44a8-9ab6-5c4e78b53e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 20:00:19.915976: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-05 20:00:21.332634: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#!/home/xyang18/miniconda3/envs/pytorch/bin/ python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import WeightedRandomSampler, TensorDataset\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, BatchNorm1d, Dropout, Flatten, BCELoss\n",
    "from torch.optim import Adam, SGD\n",
    "from torch import nn\n",
    "# from torchsummary import summary\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocess.preprocessing import Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a592452e-18a3-4ca4-b953-3bf3b114df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00555511-7293-4968-828b-561d95ba82f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "if gpu_id>=0:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    cuda_id = \"cuda:\" + str(0)  # cuda:2\n",
    "\n",
    "device = torch.device(cuda_id if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.set_device(cuda_id)\n",
    "    print(\"Current GPU ID:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0876c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tahoora/Projects/Alberta/Centaur/Centaur/ConvAttn'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUR_DIR = os.path.dirname(os.path.abspath('__file__')) \n",
    "CUR_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d07df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_signal(signal: pd.DataFrame) -> pd.DataFrame:\n",
    "    _signal = signal.copy()\n",
    "    of = Preprocess()\n",
    "    _signal = of.apply_filter(_signal, filter=\"median\")\n",
    "    _signal = of.apply_filter(_signal, filter=\"butterworth\")\n",
    "    _signal = of.segment_signal(_signal)\n",
    "    return _signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "032d5c46-5306-41bd-87e4-9bb5725d6a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_PAMAP2(root_path='../../data/PAMAP2_Dataset/Protocol/subject10'):\n",
    "    X=[]\n",
    "    user_labels=[]\n",
    "    act_labels=[]\n",
    "\n",
    "    window_len = 512\n",
    "    stride_len = 20\n",
    "    # columns for IMU data\n",
    "    imu_locs = [4,5,6, 10,11,12, 13,14,15, \n",
    "                21,22,23, 27,28,29, 30,31,32, \n",
    "                38,39,40, 44,45,46, 47,48,49\n",
    "            ] \n",
    "    \n",
    "    act_list = [1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    # scaler = StandardScaler()\n",
    "\n",
    "    for uid in np.arange(1,10):\n",
    "        path = root_path + str(uid) + '.dat'\n",
    "        df = pd.read_table(path, sep=' ', header=None)\n",
    "        act_imu_filter = df.iloc[:, imu_locs] \n",
    "\n",
    "        for act_id in range(len(act_list)):\n",
    "            act_filter =  act_imu_filter[df.iloc[:, 1] == act_list[act_id]]\n",
    "            # print(\"tt\", type(act_filter))\n",
    "            act_data = act_filter.to_numpy()\n",
    "                \n",
    "            act_data = np.transpose(act_data)\n",
    "            # sliding window segmentation\n",
    "            start_idx = 0\n",
    "            while start_idx + window_len < act_data.shape[1]:\n",
    "                window_data = act_data[:, start_idx:start_idx + window_len]\n",
    "                \n",
    "                downsamp_data = window_data[:, ::3] # downsample from 100hz to 33.3hz\n",
    "                downsamp_data = np.nan_to_num(downsamp_data) # remove nan\n",
    "\n",
    "                X.append(downsamp_data)\n",
    "                user_labels.append(uid)\n",
    "                act_labels.append(act_id)\n",
    "                start_idx = start_idx + stride_len\n",
    "\n",
    "    X_n = np.array(X).astype('float32')\n",
    "\n",
    "    normalized_X = np.zeros_like(X_n) # allocate numpy array for normalized data\n",
    "    for ch_id in range(X_n.shape[1]): # loop the 27 sensor channels\n",
    "        ch_data = X_n[:, ch_id, :] # the data of channel id\n",
    "        scaler = MinMaxScaler() # maybe different scalers?\n",
    "        ch_data = scaler.fit_transform(ch_data) # scale the data in this channel to [0,1]\n",
    "        \n",
    "        # add preprocess\n",
    "        ch_data = pd.DataFrame(ch_data, columns=[i for i in range(171)])\n",
    "        \n",
    "        ch_data = preprocess_signal(ch_data)\n",
    "        # ch_data = ch_data.to_numpy()\n",
    "\n",
    "        normalized_X[:, ch_id, :] = ch_data # assign normalized data to normalized_X\n",
    "    normalized_X = np.transpose(normalized_X, (0, 2, 1)) # overwrote X here, changed dimensions into: num_samples, sequence_length, feature_length\n",
    "        \n",
    "    # convert list to numpy array\n",
    "    # normalized_X= normalized_X.reshape(normalized_X.shape[0], 1, normalized_X.shape[1], normalized_X.shape[2]) \n",
    "    act_labels = np.array(act_labels).astype('float32')\n",
    "    act_labels = act_labels.reshape(act_labels.shape[0],1)\n",
    "    act_labels = to_categorical(act_labels, num_classes=len(act_list))\n",
    "\n",
    "    return normalized_X, act_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "733e11ee-95e2-4ac7-8f05-8d919813562a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "normalized_X, act_labels = prepare_data_PAMAP2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead0f4dc-2c91-4ffc-882c-f78348566762",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(normalized_X, act_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665d9a1-3e17-43b5-b2d9-eda196cf8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HARModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_sensor_channels=113, len_seq=24, n_hidden=128, n_layers=1, n_filters=64, \n",
    "                 n_classes=5, filter_size=(1,5), drop_prob=0.5):\n",
    "        super(HARModel, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_filters = n_filters\n",
    "        self.n_classes = n_classes\n",
    "        self.filter_size = filter_size\n",
    "        self.n_sensor_channels = n_sensor_channels\n",
    "        self.len_seq = len_seq\n",
    "\n",
    "             \n",
    "        self.conv1 = nn.Conv2d(1, n_filters, filter_size)\n",
    "        self.conv2 = nn.Conv2d(n_filters, n_filters, filter_size)\n",
    "        self.conv3 = nn.Conv2d(n_filters, n_filters, filter_size)\n",
    "        self.conv4 = nn.Conv2d(n_filters, n_filters, filter_size)\n",
    "        \n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=n_sensor_channels*n_filters, num_heads=1) # 7232=113*64\n",
    "        self.fc = nn.Linear(n_sensor_channels*n_filters*(len_seq-4*(filter_size[1]-1)), n_classes) #57856 = 8*113*64\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.permute(x, (0,2,1))\n",
    "        x = torch.unsqueeze(x, dim=1)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x)) # [64, 113, 8]\n",
    "        x = torch.permute(x, (3,0,1,2))\n",
    "        x = x.view(x.shape[0], x.shape[1],-1)\n",
    "        \n",
    "    \n",
    "        x, attn_output_weights = self.multihead_attn(x,x,x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = torch.permute(x, (1,0,2))\n",
    "        \n",
    "\n",
    "        x = torch.reshape(x, (x.shape[0],-1))\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "  \n",
    "    \n",
    "net = HARModel(n_sensor_channels=X_train.shape[2], len_seq=X_train.shape[1], n_classes=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf4b5b-2e10-43fc-8e4e-1cb59c708251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(net, epochs=10, batch_size=64, lr=0.01):\n",
    "    # opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    opt = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "    # opt = torch.optim.RMSprop(net.parameters(), lr=lr, momentum=0.1)\n",
    "    # opt = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "        batch_size=batch_size, shuffle=True, drop_last = True)  \n",
    "\n",
    "    test_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "        batch_size=batch_size, shuffle=False, drop_last = True) \n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "     \n",
    "    for e in range(epochs):\n",
    "        print(\"e\",e)\n",
    "        # initialize hidden state\n",
    "        train_losses = []    \n",
    "        net.train()\n",
    "        # for batch in iterate_minibatches(X_train, y_train, batch_size):\n",
    "        for batch in train_loader:\n",
    "            x, y = batch\n",
    "\n",
    "            # inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            inputs, targets = x.to(device), y.to(device)  \n",
    "\n",
    "            opt.zero_grad()   \n",
    "            \n",
    "            # get the output from the model\n",
    "            output = net(inputs)\n",
    "            loss = criterion(output, torch.argmax(targets,dim=1))\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            \n",
    "        # val_h = net.init_hidden(batch_size)\n",
    "        val_losses = []\n",
    "        accuracy=0\n",
    "        f1score=0\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_true = []\n",
    "        total_pred = []\n",
    "        \n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                x, y = batch\n",
    "                inputs, targets = x.to(device), y.to(device)  \n",
    " \n",
    "                # print(images.shape)            \n",
    "            # for batch in iterate_minibatches(X_test, y_test, batch_size):\n",
    "            #     x, y = batch     \n",
    "\n",
    "                # inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "                # val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                    \n",
    "                output = net(inputs)\n",
    "\n",
    "                # val_loss = criterion(output, torch.from_numpy(to_categorical(y, num_classes=NUM_CLASSES)).to(device))\n",
    "                val_loss = criterion(output, torch.argmax(targets,dim=1))\n",
    "                # val_loss = criterion(output, targets)\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "                predicted = torch.argmax(output.data, dim=1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == torch.argmax(targets, dim=1)).sum().item()\n",
    "\n",
    "                total_pred = total_pred + predicted.cpu().numpy().tolist()\n",
    "                total_true = total_true + (torch.argmax(targets, dim=1).cpu().numpy().tolist())\n",
    "\n",
    "\n",
    "#                 top_p, top_class = output.topk(1, dim=1)\n",
    "                \n",
    "#                 # equals = top_class == torch.argmax(targets, dim=1)\n",
    "#                 equals = top_class == targets.view(*top_class.shape).long()\n",
    "#                 accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "#                 # f1score += metrics.f1_score(top_class.cpu(), torch.argmax(targets, dim=1).cpu(), average='micro')\n",
    "#                 f1score += metrics.f1_score(top_class.cpu(), targets.view(*top_class.shape).long().cpu(), average='micro')\n",
    "        net.train() # reset to train mode after iterationg through validation data\n",
    "    \n",
    "        # print(f'Test Accuracy: {100.0 * correct / total} %')\n",
    "        # print(\" | \".join(act_labels_txt))\n",
    "        # conf_mat = confusion_matrix(y_true = total_true, y_pred = total_pred)\n",
    "        # conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "        # print(np.array(conf_mat).round(3) * 100)  \n",
    "        f1_score = metrics.f1_score(y_true = total_true, y_pred = total_pred, average='weighted')\n",
    "        # print('F1 score:', f1_score)\n",
    "        # print('')      \n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "        \"Train Loss: {:.4f}...\".format(np.mean(train_losses)),\n",
    "        \"Val Loss: {:.4f}...\".format(np.mean(val_losses)),\n",
    "        \"Val Acc: {:.4f}...\".format(correct / total),\n",
    "        \"F1-Score: {:.4f}...\".format(f1_score))\n",
    "        \n",
    "        PATH = 'pamap2_ConvAttn_ep'+str(e)+'.pt'\n",
    "        torch.save(net.state_dict(), PATH)\n",
    "        \n",
    "## check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')\n",
    "\n",
    "train(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
