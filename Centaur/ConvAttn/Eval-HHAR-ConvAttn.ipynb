{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c11f73-2263-44a8-9ab6-5c4e78b53e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/home/xyang18/miniconda3/envs/pytorch/bin/ python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import WeightedRandomSampler, TensorDataset\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, BatchNorm1d, Dropout, Flatten, BCELoss\n",
    "from torch.optim import Adam, SGD\n",
    "from torch import nn\n",
    "# from torchsummary import summary\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import sklearn.metrics as metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55258ae9-b9b8-4ff7-b954-c7a018c6367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a592452e-18a3-4ca4-b953-3bf3b114df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id=0\n",
    "seed=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c39ffb-2e60-47bf-a5a8-0b09b454732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00555511-7293-4968-828b-561d95ba82f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Current GPU ID: 0\n"
     ]
    }
   ],
   "source": [
    "if gpu_id>=0:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    cuda_id = \"cuda:\" + str(0)  # cuda:2\n",
    "\n",
    "device = torch.device(cuda_id if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.set_device(cuda_id)\n",
    "    print(\"Current GPU ID:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aebff0da-e2f9-41a6-958c-8ef12bffe8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_total = np.load('hhar_time_X.npy').astype('float32')\n",
    "y_total = np.load('hhar_time_y.npy').astype(int)\n",
    "\n",
    "X_total=np.nan_to_num(X_total)\n",
    "for i in range(X_total.shape[1]):\n",
    "    # print(type(i))\n",
    "    \n",
    "    ch_data = X_total[:,i,:] # the data of channel id\n",
    "    scaler = MinMaxScaler() # maybe different scalers?\n",
    "    ch_data = scaler.fit_transform(ch_data) # scale the data in this channel to [0,1]\n",
    "    X_total[:,i,:] = ch_data # assign normalized data to normalized_X\n",
    "    \n",
    "    # ch_max = np.max(X_total[:,i,:])\n",
    "    # ch_min = np.min(X_total[:,i,:])\n",
    "    # # print(ch_max, ch_min)\n",
    "    # X_total[:,i,:] = (X_total[:,i,:] - ch_min) / (ch_max - ch_min)\n",
    "    \n",
    "X_total = np.transpose(X_total, (0,2,1))\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_total, y_total, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be83225-f5bb-4c32-b345-23c7216aee51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4665d9a1-3e17-43b5-b2d9-eda196cf8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HARModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_sensor_channels=6, len_seq=100, n_hidden=128, n_layers=1, n_filters=64, \n",
    "                 n_classes=6, filter_size=(1,5), drop_prob=0.5):\n",
    "        super(HARModel, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_filters = n_filters\n",
    "        self.n_classes = n_classes\n",
    "        self.filter_size = filter_size\n",
    "        self.n_sensor_channels = n_sensor_channels\n",
    "        self.len_seq = len_seq\n",
    "\n",
    "             \n",
    "        self.conv1 = nn.Conv2d(1, n_filters, filter_size)\n",
    "        self.conv2 = nn.Conv2d(n_filters, n_filters, filter_size)\n",
    "        self.conv3 = nn.Conv2d(n_filters, n_filters, filter_size)\n",
    "        self.conv4 = nn.Conv2d(n_filters, n_filters, filter_size)\n",
    "        \n",
    "        # self.fc0 = nn.Linear(n_sensor_channels*n_filters,n_sensor_channels*4)\n",
    "        \n",
    "        # self.lstm1  = nn.LSTM(64, n_hidden, n_layers)\n",
    "        # self.lstm2  = nn.LSTM(n_hidden, n_hidden, n_layers)\n",
    "        # self.multihead_attn = nn.MultiheadAttention(embed_dim=n_sensor_channels*4, num_heads=1) # 7232=113*64\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=n_sensor_channels*n_filters, num_heads=1) # 7232=113*64\n",
    "        # self.multihead_attn = nn.MultiheadAttention(embed_dim=n_sensor_channels, num_heads=1) # 7232=113*64\n",
    "        \n",
    "        # self.fc = nn.Linear(2712, n_classes) #57856 = 8*113*64\n",
    "        # self.fc = nn.Linear(n_sensor_channels*n_filters*(len_seq-0*(filter_size[1]-1)), n_classes) #57856 = 8*113*64\n",
    "        self.fc = nn.Linear(n_sensor_channels*n_filters*(len_seq-4*(filter_size[1]-1)), n_classes) #57856 = 8*113*64\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x = x.view(-1, NB_SENSOR_CHANNELS, SLIDING_WINDOW_LENGTH,1) # for direct channel_gate\n",
    "        # batch_size = x.shape[0]\n",
    "\n",
    "        # x = x.view(-1, NB_SENSOR_CHANNELS, SLIDING_WINDOW_LENGTH) # for deepconvlstm conv layers\n",
    "        # x = torch.permute(x,(1,0,2))\n",
    "        # print(x.shape)\n",
    "        # x, attn_output_weights = self.multihead_attn0(x,x,x)\n",
    "\n",
    "        # print(x.shape)\n",
    "        # x = torch.permute(x,(2,1,0))\n",
    "        # print(x.shape)\n",
    "        # x = x.view(-1, 1, NB_SENSOR_CHANNELS, SLIDING_WINDOW_LENGTH) # draft\n",
    "        x = torch.permute(x, (0,2,1))\n",
    "        x = torch.unsqueeze(x, dim=1)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x)) # [64, 113, 8]\n",
    "        \n",
    "        # x = x.view(-1, NB_SENSOR_CHANNELS, 8, 1)\n",
    "        # x = x.view(x.shape[0], x.shape[1], x.shape[2], 1)\n",
    "        # x = x.view(x.shape[0], -1, 8)\n",
    "        \n",
    "        # print(x.shape)\n",
    "        x = torch.permute(x, (3,0,1,2))\n",
    "        x = x.view(x.shape[0], x.shape[1],-1)\n",
    "        \n",
    "        # print(x.shape)\n",
    "        # x = x.view(8, x.shape[0], -1) # bak\n",
    "        # x = F.relu(self.fc0(x))\n",
    "        \n",
    "    \n",
    "        x, attn_output_weights = self.multihead_attn(x,x,x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "#         x, attn_output_weights = self.multihead_attn1(x,x,x)\n",
    "#         # x = self.dropout(x)\n",
    "#         x = F.relu(x)    \n",
    "        \n",
    "        x = torch.permute(x, (1,0,2))\n",
    "        \n",
    "        # x, hidden = self.lstm1(x, hidden)\n",
    "        # # x = self.dropout(x)\n",
    "        # x, hidden = self.lstm2(x, hidden)\n",
    "        # x = self.dropout(x)\n",
    "        \n",
    "        # x = x.contiguous().view(-1, self.n_hidden)\n",
    "\n",
    "        x = torch.reshape(x, (x.shape[0],-1))\n",
    "        # x = F.relu(self.fc0(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = HARModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fcf4b5b-2e10-43fc-8e4e-1cb59c708251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n",
      "Epoch: 1/600... Train Loss: 1.7882... Val Loss: 1.7870... Val Acc: 0.1840... F1-Score: 0.0580...\n",
      "Epoch: 2/600... Train Loss: 1.7820... Val Loss: 1.7725... Val Acc: 0.3030... F1-Score: 0.1933...\n",
      "Epoch: 3/600... Train Loss: 1.6323... Val Loss: 1.4911... Val Acc: 0.3544... F1-Score: 0.2855...\n",
      "Epoch: 4/600... Train Loss: 1.4686... Val Loss: 1.4309... Val Acc: 0.4228... F1-Score: 0.3925...\n",
      "Epoch: 5/600... Train Loss: 1.3921... Val Loss: 1.3472... Val Acc: 0.4038... F1-Score: 0.3926...\n",
      "Epoch: 6/600... Train Loss: 1.3001... Val Loss: 1.1623... Val Acc: 0.5502... F1-Score: 0.5412...\n",
      "Epoch: 7/600... Train Loss: 0.9763... Val Loss: 0.8949... Val Acc: 0.6737... F1-Score: 0.6753...\n",
      "Epoch: 8/600... Train Loss: 0.8941... Val Loss: 0.9129... Val Acc: 0.6137... F1-Score: 0.6066...\n",
      "Epoch: 9/600... Train Loss: 0.8432... Val Loss: 0.8784... Val Acc: 0.6583... F1-Score: 0.6312...\n",
      "Epoch: 10/600... Train Loss: 0.7996... Val Loss: 0.7274... Val Acc: 0.7307... F1-Score: 0.7154...\n",
      "Epoch: 11/600... Train Loss: 0.7672... Val Loss: 0.7674... Val Acc: 0.7180... F1-Score: 0.7072...\n",
      "Epoch: 12/600... Train Loss: 0.7288... Val Loss: 0.7138... Val Acc: 0.7331... F1-Score: 0.7306...\n",
      "Epoch: 13/600... Train Loss: 0.7063... Val Loss: 0.6588... Val Acc: 0.7383... F1-Score: 0.7334...\n",
      "Epoch: 14/600... Train Loss: 0.6700... Val Loss: 0.6193... Val Acc: 0.7597... F1-Score: 0.7618...\n",
      "Epoch: 15/600... Train Loss: 0.6178... Val Loss: 0.6212... Val Acc: 0.7733... F1-Score: 0.7706...\n",
      "Epoch: 16/600... Train Loss: 0.5678... Val Loss: 0.5697... Val Acc: 0.7928... F1-Score: 0.7874...\n",
      "Epoch: 17/600... Train Loss: 0.5059... Val Loss: 0.4298... Val Acc: 0.8603... F1-Score: 0.8595...\n",
      "Epoch: 18/600... Train Loss: 0.4761... Val Loss: 0.4712... Val Acc: 0.8404... F1-Score: 0.8412...\n",
      "Epoch: 19/600... Train Loss: 0.4315... Val Loss: 0.3976... Val Acc: 0.8618... F1-Score: 0.8625...\n",
      "Epoch: 20/600... Train Loss: 0.4120... Val Loss: 0.3808... Val Acc: 0.8800... F1-Score: 0.8804...\n",
      "Epoch: 21/600... Train Loss: 0.3851... Val Loss: 0.3821... Val Acc: 0.8817... F1-Score: 0.8826...\n",
      "Epoch: 22/600... Train Loss: 0.3654... Val Loss: 0.3509... Val Acc: 0.8876... F1-Score: 0.8875...\n",
      "Epoch: 23/600... Train Loss: 0.3445... Val Loss: 0.3229... Val Acc: 0.8925... F1-Score: 0.8923...\n",
      "Epoch: 24/600... Train Loss: 0.3195... Val Loss: 0.3499... Val Acc: 0.8867... F1-Score: 0.8867...\n",
      "Epoch: 25/600... Train Loss: 0.3175... Val Loss: 0.3049... Val Acc: 0.9068... F1-Score: 0.9074...\n",
      "Epoch: 26/600... Train Loss: 0.2778... Val Loss: 0.3015... Val Acc: 0.9005... F1-Score: 0.8999...\n",
      "Epoch: 27/600... Train Loss: 0.2769... Val Loss: 0.2643... Val Acc: 0.9176... F1-Score: 0.9179...\n",
      "Epoch: 28/600... Train Loss: 0.2646... Val Loss: 0.2573... Val Acc: 0.9176... F1-Score: 0.9173...\n",
      "Epoch: 29/600... Train Loss: 0.2393... Val Loss: 0.2552... Val Acc: 0.9234... F1-Score: 0.9239...\n",
      "Epoch: 30/600... Train Loss: 0.2373... Val Loss: 0.2711... Val Acc: 0.9150... F1-Score: 0.9149...\n",
      "Epoch: 31/600... Train Loss: 0.2310... Val Loss: 0.2961... Val Acc: 0.8992... F1-Score: 0.8979...\n",
      "Epoch: 32/600... Train Loss: 0.2173... Val Loss: 0.2494... Val Acc: 0.9219... F1-Score: 0.9227...\n",
      "Epoch: 33/600... Train Loss: 0.2107... Val Loss: 0.2555... Val Acc: 0.9206... F1-Score: 0.9207...\n",
      "Epoch: 34/600... Train Loss: 0.2024... Val Loss: 0.2374... Val Acc: 0.9327... F1-Score: 0.9330...\n",
      "Epoch: 35/600... Train Loss: 0.1931... Val Loss: 0.2104... Val Acc: 0.9371... F1-Score: 0.9374...\n",
      "Epoch: 36/600... Train Loss: 0.1933... Val Loss: 0.2630... Val Acc: 0.9178... F1-Score: 0.9177...\n",
      "Epoch: 37/600... Train Loss: 0.1850... Val Loss: 0.2225... Val Acc: 0.9271... F1-Score: 0.9280...\n",
      "Epoch: 38/600... Train Loss: 0.1814... Val Loss: 0.2143... Val Acc: 0.9328... F1-Score: 0.9329...\n",
      "Epoch: 39/600... Train Loss: 0.1826... Val Loss: 0.2217... Val Acc: 0.9306... F1-Score: 0.9311...\n",
      "Epoch: 40/600... Train Loss: 0.1708... Val Loss: 0.2050... Val Acc: 0.9338... F1-Score: 0.9342...\n",
      "Epoch: 41/600... Train Loss: 0.1628... Val Loss: 0.2199... Val Acc: 0.9312... F1-Score: 0.9312...\n",
      "Epoch: 42/600... Train Loss: 0.1588... Val Loss: 0.1965... Val Acc: 0.9366... F1-Score: 0.9369...\n",
      "Epoch: 43/600... Train Loss: 0.1583... Val Loss: 0.1948... Val Acc: 0.9422... F1-Score: 0.9426...\n",
      "Epoch: 44/600... Train Loss: 0.1517... Val Loss: 0.2183... Val Acc: 0.9336... F1-Score: 0.9341...\n",
      "Epoch: 45/600... Train Loss: 0.1467... Val Loss: 0.1906... Val Acc: 0.9399... F1-Score: 0.9406...\n",
      "Epoch: 46/600... Train Loss: 0.1488... Val Loss: 0.1915... Val Acc: 0.9440... F1-Score: 0.9448...\n",
      "Epoch: 47/600... Train Loss: 0.1479... Val Loss: 0.2012... Val Acc: 0.9425... F1-Score: 0.9431...\n",
      "Epoch: 48/600... Train Loss: 0.1505... Val Loss: 0.2239... Val Acc: 0.9260... F1-Score: 0.9267...\n",
      "Epoch: 49/600... Train Loss: 0.1377... Val Loss: 0.2396... Val Acc: 0.9347... F1-Score: 0.9348...\n",
      "Epoch: 50/600... Train Loss: 0.1348... Val Loss: 0.1946... Val Acc: 0.9444... F1-Score: 0.9448...\n",
      "Epoch: 51/600... Train Loss: 0.1377... Val Loss: 0.2109... Val Acc: 0.9362... F1-Score: 0.9369...\n",
      "Epoch: 52/600... Train Loss: 0.1374... Val Loss: 0.2089... Val Acc: 0.9388... F1-Score: 0.9390...\n",
      "Epoch: 53/600... Train Loss: 0.1288... Val Loss: 0.1995... Val Acc: 0.9392... F1-Score: 0.9394...\n",
      "Epoch: 54/600... Train Loss: 0.1318... Val Loss: 0.2057... Val Acc: 0.9325... F1-Score: 0.9333...\n",
      "Epoch: 55/600... Train Loss: 0.1309... Val Loss: 0.1838... Val Acc: 0.9451... F1-Score: 0.9454...\n",
      "Epoch: 56/600... Train Loss: 0.1250... Val Loss: 0.1907... Val Acc: 0.9399... F1-Score: 0.9403...\n",
      "Epoch: 57/600... Train Loss: 0.1216... Val Loss: 0.1817... Val Acc: 0.9446... F1-Score: 0.9453...\n",
      "Epoch: 58/600... Train Loss: 0.1207... Val Loss: 0.1884... Val Acc: 0.9466... F1-Score: 0.9469...\n",
      "Epoch: 59/600... Train Loss: 0.1190... Val Loss: 0.1837... Val Acc: 0.9457... F1-Score: 0.9460...\n",
      "Epoch: 60/600... Train Loss: 0.1151... Val Loss: 0.1977... Val Acc: 0.9448... F1-Score: 0.9453...\n",
      "Epoch: 61/600... Train Loss: 0.1153... Val Loss: 0.2243... Val Acc: 0.9347... F1-Score: 0.9354...\n",
      "Epoch: 62/600... Train Loss: 0.1194... Val Loss: 0.2169... Val Acc: 0.9410... F1-Score: 0.9413...\n",
      "Epoch: 63/600... Train Loss: 0.1170... Val Loss: 0.1943... Val Acc: 0.9455... F1-Score: 0.9457...\n",
      "Epoch: 64/600... Train Loss: 0.1101... Val Loss: 0.1927... Val Acc: 0.9472... F1-Score: 0.9475...\n",
      "Epoch: 65/600... Train Loss: 0.1100... Val Loss: 0.1932... Val Acc: 0.9474... F1-Score: 0.9478...\n",
      "Epoch: 66/600... Train Loss: 0.1054... Val Loss: 0.2066... Val Acc: 0.9423... F1-Score: 0.9429...\n",
      "Epoch: 67/600... Train Loss: 0.1094... Val Loss: 0.1952... Val Acc: 0.9425... F1-Score: 0.9429...\n",
      "Epoch: 68/600... Train Loss: 0.1099... Val Loss: 0.1842... Val Acc: 0.9472... F1-Score: 0.9477...\n",
      "Epoch: 69/600... Train Loss: 0.1054... Val Loss: 0.1886... Val Acc: 0.9488... F1-Score: 0.9492...\n",
      "Epoch: 70/600... Train Loss: 0.1087... Val Loss: 0.1865... Val Acc: 0.9442... F1-Score: 0.9448...\n",
      "Epoch: 71/600... Train Loss: 0.1071... Val Loss: 0.1899... Val Acc: 0.9457... F1-Score: 0.9463...\n",
      "Epoch: 72/600... Train Loss: 0.1033... Val Loss: 0.2124... Val Acc: 0.9414... F1-Score: 0.9418...\n",
      "Epoch: 73/600... Train Loss: 0.1007... Val Loss: 0.1978... Val Acc: 0.9475... F1-Score: 0.9480...\n",
      "Epoch: 74/600... Train Loss: 0.0973... Val Loss: 0.1975... Val Acc: 0.9474... F1-Score: 0.9476...\n",
      "Epoch: 75/600... Train Loss: 0.1045... Val Loss: 0.1950... Val Acc: 0.9464... F1-Score: 0.9467...\n",
      "Epoch: 76/600... Train Loss: 0.0925... Val Loss: 0.2007... Val Acc: 0.9455... F1-Score: 0.9457...\n",
      "Epoch: 77/600... Train Loss: 0.1005... Val Loss: 0.2081... Val Acc: 0.9457... F1-Score: 0.9460...\n",
      "Epoch: 78/600... Train Loss: 0.0930... Val Loss: 0.2029... Val Acc: 0.9453... F1-Score: 0.9456...\n",
      "Epoch: 79/600... Train Loss: 0.0922... Val Loss: 0.2080... Val Acc: 0.9449... F1-Score: 0.9452...\n",
      "Epoch: 80/600... Train Loss: 0.1002... Val Loss: 0.2230... Val Acc: 0.9436... F1-Score: 0.9440...\n",
      "Epoch: 81/600... Train Loss: 0.0898... Val Loss: 0.2048... Val Acc: 0.9468... F1-Score: 0.9471...\n",
      "Epoch: 82/600... Train Loss: 0.0940... Val Loss: 0.2015... Val Acc: 0.9449... F1-Score: 0.9454...\n",
      "Epoch: 83/600... Train Loss: 0.0890... Val Loss: 0.2134... Val Acc: 0.9427... F1-Score: 0.9431...\n",
      "Epoch: 84/600... Train Loss: 0.0910... Val Loss: 0.2063... Val Acc: 0.9440... F1-Score: 0.9444...\n",
      "Epoch: 85/600... Train Loss: 0.0900... Val Loss: 0.2035... Val Acc: 0.9462... F1-Score: 0.9466...\n",
      "Epoch: 86/600... Train Loss: 0.0863... Val Loss: 0.2254... Val Acc: 0.9481... F1-Score: 0.9483...\n",
      "Epoch: 87/600... Train Loss: 0.0887... Val Loss: 0.1876... Val Acc: 0.9492... F1-Score: 0.9496...\n",
      "Epoch: 88/600... Train Loss: 0.0905... Val Loss: 0.2007... Val Acc: 0.9431... F1-Score: 0.9436...\n",
      "Epoch: 89/600... Train Loss: 0.0911... Val Loss: 0.2053... Val Acc: 0.9451... F1-Score: 0.9455...\n",
      "Epoch: 90/600... Train Loss: 0.0840... Val Loss: 0.2181... Val Acc: 0.9416... F1-Score: 0.9419...\n",
      "Epoch: 91/600... Train Loss: 0.0842... Val Loss: 0.2246... Val Acc: 0.9435... F1-Score: 0.9440...\n",
      "Epoch: 92/600... Train Loss: 0.0807... Val Loss: 0.1972... Val Acc: 0.9509... F1-Score: 0.9514...\n",
      "Epoch: 93/600... Train Loss: 0.0829... Val Loss: 0.2247... Val Acc: 0.9422... F1-Score: 0.9427...\n",
      "Epoch: 94/600... Train Loss: 0.0804... Val Loss: 0.2182... Val Acc: 0.9472... F1-Score: 0.9475...\n",
      "Epoch: 95/600... Train Loss: 0.0813... Val Loss: 0.2187... Val Acc: 0.9472... F1-Score: 0.9477...\n",
      "Epoch: 96/600... Train Loss: 0.0810... Val Loss: 0.2053... Val Acc: 0.9485... F1-Score: 0.9489...\n",
      "Epoch: 97/600... Train Loss: 0.0790... Val Loss: 0.1990... Val Acc: 0.9496... F1-Score: 0.9500...\n",
      "Epoch: 98/600... Train Loss: 0.0896... Val Loss: 0.2044... Val Acc: 0.9479... F1-Score: 0.9485...\n",
      "Epoch: 99/600... Train Loss: 0.0774... Val Loss: 0.2099... Val Acc: 0.9475... F1-Score: 0.9480...\n",
      "Epoch: 100/600... Train Loss: 0.0750... Val Loss: 0.2155... Val Acc: 0.9487... F1-Score: 0.9491...\n",
      "Epoch: 101/600... Train Loss: 0.0769... Val Loss: 0.2181... Val Acc: 0.9485... F1-Score: 0.9489...\n",
      "Epoch: 102/600... Train Loss: 0.0780... Val Loss: 0.2239... Val Acc: 0.9466... F1-Score: 0.9469...\n",
      "Epoch: 103/600... Train Loss: 0.0776... Val Loss: 0.2745... Val Acc: 0.9420... F1-Score: 0.9422...\n",
      "Epoch: 104/600... Train Loss: 0.0773... Val Loss: 0.2553... Val Acc: 0.9355... F1-Score: 0.9360...\n",
      "Epoch: 105/600... Train Loss: 0.0714... Val Loss: 0.2024... Val Acc: 0.9509... F1-Score: 0.9515...\n",
      "Epoch: 106/600... Train Loss: 0.0712... Val Loss: 0.2356... Val Acc: 0.9451... F1-Score: 0.9459...\n",
      "Epoch: 107/600... Train Loss: 0.0791... Val Loss: 0.2417... Val Acc: 0.9451... F1-Score: 0.9455...\n",
      "Epoch: 108/600... Train Loss: 0.0735... Val Loss: 0.2181... Val Acc: 0.9474... F1-Score: 0.9480...\n",
      "Epoch: 109/600... Train Loss: 0.0693... Val Loss: 0.2082... Val Acc: 0.9507... F1-Score: 0.9511...\n",
      "Epoch: 110/600... Train Loss: 0.0702... Val Loss: 0.2120... Val Acc: 0.9483... F1-Score: 0.9486...\n",
      "Epoch: 111/600... Train Loss: 0.0758... Val Loss: 0.2301... Val Acc: 0.9498... F1-Score: 0.9503...\n",
      "Epoch: 112/600... Train Loss: 0.0709... Val Loss: 0.2395... Val Acc: 0.9492... F1-Score: 0.9498...\n",
      "Epoch: 113/600... Train Loss: 0.0743... Val Loss: 0.2454... Val Acc: 0.9483... F1-Score: 0.9486...\n",
      "Epoch: 114/600... Train Loss: 0.0747... Val Loss: 0.2180... Val Acc: 0.9535... F1-Score: 0.9539...\n",
      "Epoch: 115/600... Train Loss: 0.0745... Val Loss: 0.2368... Val Acc: 0.9410... F1-Score: 0.9419...\n",
      "Epoch: 116/600... Train Loss: 0.0724... Val Loss: 0.2150... Val Acc: 0.9479... F1-Score: 0.9484...\n",
      "Epoch: 117/600... Train Loss: 0.0692... Val Loss: 0.2197... Val Acc: 0.9492... F1-Score: 0.9498...\n",
      "Epoch: 118/600... Train Loss: 0.0715... Val Loss: 0.2256... Val Acc: 0.9483... F1-Score: 0.9486...\n",
      "Epoch: 119/600... Train Loss: 0.0673... Val Loss: 0.2177... Val Acc: 0.9516... F1-Score: 0.9520...\n",
      "Epoch: 120/600... Train Loss: 0.0672... Val Loss: 0.2316... Val Acc: 0.9496... F1-Score: 0.9500...\n",
      "Epoch: 121/600... Train Loss: 0.0628... Val Loss: 0.2359... Val Acc: 0.9451... F1-Score: 0.9456...\n",
      "Epoch: 122/600... Train Loss: 0.0731... Val Loss: 0.2407... Val Acc: 0.9451... F1-Score: 0.9457...\n",
      "Epoch: 123/600... Train Loss: 0.0658... Val Loss: 0.2332... Val Acc: 0.9500... F1-Score: 0.9503...\n",
      "Epoch: 124/600... Train Loss: 0.0675... Val Loss: 0.2342... Val Acc: 0.9498... F1-Score: 0.9502...\n",
      "Epoch: 125/600... Train Loss: 0.0640... Val Loss: 0.2240... Val Acc: 0.9507... F1-Score: 0.9512...\n",
      "Epoch: 126/600... Train Loss: 0.0761... Val Loss: 0.2421... Val Acc: 0.9401... F1-Score: 0.9408...\n",
      "Epoch: 127/600... Train Loss: 0.0724... Val Loss: 0.2321... Val Acc: 0.9442... F1-Score: 0.9449...\n",
      "Epoch: 128/600... Train Loss: 0.0611... Val Loss: 0.2208... Val Acc: 0.9492... F1-Score: 0.9497...\n",
      "Epoch: 129/600... Train Loss: 0.0704... Val Loss: 0.2153... Val Acc: 0.9526... F1-Score: 0.9531...\n",
      "Epoch: 130/600... Train Loss: 0.0657... Val Loss: 0.2379... Val Acc: 0.9468... F1-Score: 0.9473...\n",
      "Epoch: 131/600... Train Loss: 0.0638... Val Loss: 0.2560... Val Acc: 0.9435... F1-Score: 0.9439...\n",
      "Epoch: 132/600... Train Loss: 0.0652... Val Loss: 0.2419... Val Acc: 0.9429... F1-Score: 0.9432...\n",
      "Epoch: 133/600... Train Loss: 0.0666... Val Loss: 0.2442... Val Acc: 0.9503... F1-Score: 0.9507...\n",
      "Epoch: 134/600... Train Loss: 0.0692... Val Loss: 0.2331... Val Acc: 0.9496... F1-Score: 0.9500...\n",
      "Epoch: 135/600... Train Loss: 0.0640... Val Loss: 0.2135... Val Acc: 0.9535... F1-Score: 0.9539...\n",
      "Epoch: 136/600... Train Loss: 0.0597... Val Loss: 0.2591... Val Acc: 0.9435... F1-Score: 0.9441...\n",
      "Epoch: 137/600... Train Loss: 0.0612... Val Loss: 0.2374... Val Acc: 0.9470... F1-Score: 0.9475...\n",
      "Epoch: 138/600... Train Loss: 0.0631... Val Loss: 0.2356... Val Acc: 0.9513... F1-Score: 0.9516...\n",
      "Epoch: 139/600... Train Loss: 0.0636... Val Loss: 0.2399... Val Acc: 0.9488... F1-Score: 0.9491...\n",
      "Epoch: 140/600... Train Loss: 0.0659... Val Loss: 0.2351... Val Acc: 0.9511... F1-Score: 0.9516...\n",
      "Epoch: 141/600... Train Loss: 0.0630... Val Loss: 0.2331... Val Acc: 0.9511... F1-Score: 0.9517...\n",
      "Epoch: 142/600... Train Loss: 0.0592... Val Loss: 0.2312... Val Acc: 0.9513... F1-Score: 0.9516...\n",
      "Epoch: 143/600... Train Loss: 0.0624... Val Loss: 0.2478... Val Acc: 0.9515... F1-Score: 0.9519...\n",
      "Epoch: 144/600... Train Loss: 0.0626... Val Loss: 0.2481... Val Acc: 0.9487... F1-Score: 0.9490...\n",
      "Epoch: 145/600... Train Loss: 0.0654... Val Loss: 0.2375... Val Acc: 0.9507... F1-Score: 0.9514...\n",
      "Epoch: 146/600... Train Loss: 0.0580... Val Loss: 0.2316... Val Acc: 0.9526... F1-Score: 0.9529...\n",
      "Epoch: 147/600... Train Loss: 0.0622... Val Loss: 0.2458... Val Acc: 0.9496... F1-Score: 0.9500...\n",
      "Epoch: 148/600... Train Loss: 0.0577... Val Loss: 0.2343... Val Acc: 0.9528... F1-Score: 0.9531...\n",
      "Epoch: 149/600... Train Loss: 0.0656... Val Loss: 0.2455... Val Acc: 0.9444... F1-Score: 0.9450...\n",
      "Epoch: 150/600... Train Loss: 0.0630... Val Loss: 0.2460... Val Acc: 0.9492... F1-Score: 0.9496...\n",
      "Epoch: 151/600... Train Loss: 0.0705... Val Loss: 0.2306... Val Acc: 0.9533... F1-Score: 0.9537...\n",
      "Epoch: 152/600... Train Loss: 0.0575... Val Loss: 0.2464... Val Acc: 0.9520... F1-Score: 0.9525...\n",
      "Epoch: 153/600... Train Loss: 0.0592... Val Loss: 0.2481... Val Acc: 0.9507... F1-Score: 0.9511...\n",
      "Epoch: 154/600... Train Loss: 0.0566... Val Loss: 0.2318... Val Acc: 0.9511... F1-Score: 0.9518...\n",
      "Epoch: 155/600... Train Loss: 0.0534... Val Loss: 0.2489... Val Acc: 0.9440... F1-Score: 0.9444...\n",
      "Epoch: 156/600... Train Loss: 0.0625... Val Loss: 0.2412... Val Acc: 0.9507... F1-Score: 0.9512...\n",
      "Epoch: 157/600... Train Loss: 0.0550... Val Loss: 0.2436... Val Acc: 0.9501... F1-Score: 0.9505...\n",
      "Epoch: 158/600... Train Loss: 0.0599... Val Loss: 0.2437... Val Acc: 0.9492... F1-Score: 0.9497...\n",
      "Epoch: 159/600... Train Loss: 0.0661... Val Loss: 0.2711... Val Acc: 0.9462... F1-Score: 0.9468...\n",
      "Epoch: 160/600... Train Loss: 0.0589... Val Loss: 0.2451... Val Acc: 0.9490... F1-Score: 0.9495...\n",
      "Epoch: 161/600... Train Loss: 0.0581... Val Loss: 0.2492... Val Acc: 0.9488... F1-Score: 0.9493...\n",
      "Epoch: 162/600... Train Loss: 0.0560... Val Loss: 0.2415... Val Acc: 0.9524... F1-Score: 0.9530...\n",
      "Epoch: 163/600... Train Loss: 0.0559... Val Loss: 0.2392... Val Acc: 0.9490... F1-Score: 0.9495...\n",
      "Epoch: 164/600... Train Loss: 0.0612... Val Loss: 0.2332... Val Acc: 0.9492... F1-Score: 0.9496...\n",
      "Epoch: 165/600... Train Loss: 0.0637... Val Loss: 0.2723... Val Acc: 0.9503... F1-Score: 0.9507...\n",
      "Epoch: 166/600... Train Loss: 0.0579... Val Loss: 0.2640... Val Acc: 0.9498... F1-Score: 0.9503...\n",
      "Epoch: 167/600... Train Loss: 0.0571... Val Loss: 0.2643... Val Acc: 0.9513... F1-Score: 0.9519...\n",
      "Epoch: 168/600... Train Loss: 0.0557... Val Loss: 0.2687... Val Acc: 0.9485... F1-Score: 0.9489...\n",
      "Epoch: 169/600... Train Loss: 0.0584... Val Loss: 0.3178... Val Acc: 0.9375... F1-Score: 0.9380...\n",
      "Epoch: 170/600... Train Loss: 0.0605... Val Loss: 0.2488... Val Acc: 0.9500... F1-Score: 0.9505...\n",
      "Epoch: 171/600... Train Loss: 0.0565... Val Loss: 0.2889... Val Acc: 0.9479... F1-Score: 0.9483...\n",
      "Epoch: 172/600... Train Loss: 0.0531... Val Loss: 0.2531... Val Acc: 0.9541... F1-Score: 0.9544...\n",
      "Epoch: 173/600... Train Loss: 0.0576... Val Loss: 0.2500... Val Acc: 0.9526... F1-Score: 0.9529...\n",
      "Epoch: 174/600... Train Loss: 0.0561... Val Loss: 0.2545... Val Acc: 0.9511... F1-Score: 0.9516...\n",
      "Epoch: 175/600... Train Loss: 0.0575... Val Loss: 0.2561... Val Acc: 0.9511... F1-Score: 0.9515...\n",
      "Epoch: 176/600... Train Loss: 0.0660... Val Loss: 0.2463... Val Acc: 0.9518... F1-Score: 0.9524...\n",
      "Epoch: 177/600... Train Loss: 0.0533... Val Loss: 0.2600... Val Acc: 0.9466... F1-Score: 0.9471...\n",
      "Epoch: 178/600... Train Loss: 0.0563... Val Loss: 0.2383... Val Acc: 0.9537... F1-Score: 0.9543...\n",
      "Epoch: 179/600... Train Loss: 0.0534... Val Loss: 0.2631... Val Acc: 0.9488... F1-Score: 0.9494...\n",
      "Epoch: 180/600... Train Loss: 0.0616... Val Loss: 0.2668... Val Acc: 0.9503... F1-Score: 0.9507...\n",
      "Epoch: 181/600... Train Loss: 0.0501... Val Loss: 0.2358... Val Acc: 0.9524... F1-Score: 0.9529...\n",
      "Epoch: 182/600... Train Loss: 0.0511... Val Loss: 0.2508... Val Acc: 0.9516... F1-Score: 0.9521...\n",
      "Epoch: 183/600... Train Loss: 0.0528... Val Loss: 0.2527... Val Acc: 0.9507... F1-Score: 0.9513...\n",
      "Epoch: 184/600... Train Loss: 0.0520... Val Loss: 0.2524... Val Acc: 0.9537... F1-Score: 0.9541...\n",
      "Epoch: 185/600... Train Loss: 0.0535... Val Loss: 0.2463... Val Acc: 0.9535... F1-Score: 0.9540...\n",
      "Epoch: 186/600... Train Loss: 0.0516... Val Loss: 0.2622... Val Acc: 0.9531... F1-Score: 0.9536...\n",
      "Epoch: 187/600... Train Loss: 0.0558... Val Loss: 0.2675... Val Acc: 0.9500... F1-Score: 0.9503...\n",
      "Epoch: 188/600... Train Loss: 0.0598... Val Loss: 0.2463... Val Acc: 0.9509... F1-Score: 0.9516...\n",
      "Epoch: 189/600... Train Loss: 0.0526... Val Loss: 0.2711... Val Acc: 0.9515... F1-Score: 0.9518...\n",
      "Epoch: 190/600... Train Loss: 0.0512... Val Loss: 0.2835... Val Acc: 0.9513... F1-Score: 0.9518...\n",
      "Epoch: 191/600... Train Loss: 0.0546... Val Loss: 0.2383... Val Acc: 0.9528... F1-Score: 0.9531...\n",
      "Epoch: 192/600... Train Loss: 0.0506... Val Loss: 0.2595... Val Acc: 0.9544... F1-Score: 0.9548...\n",
      "Epoch: 193/600... Train Loss: 0.0511... Val Loss: 0.2460... Val Acc: 0.9511... F1-Score: 0.9516...\n",
      "Epoch: 194/600... Train Loss: 0.0572... Val Loss: 0.2632... Val Acc: 0.9518... F1-Score: 0.9522...\n",
      "Epoch: 195/600... Train Loss: 0.0556... Val Loss: 0.2528... Val Acc: 0.9516... F1-Score: 0.9521...\n",
      "Epoch: 196/600... Train Loss: 0.0527... Val Loss: 0.2696... Val Acc: 0.9513... F1-Score: 0.9519...\n",
      "Epoch: 197/600... Train Loss: 0.0487... Val Loss: 0.2742... Val Acc: 0.9509... F1-Score: 0.9515...\n",
      "Epoch: 198/600... Train Loss: 0.0521... Val Loss: 0.2645... Val Acc: 0.9529... F1-Score: 0.9535...\n",
      "Epoch: 199/600... Train Loss: 0.0510... Val Loss: 0.2774... Val Acc: 0.9513... F1-Score: 0.9518...\n",
      "Epoch: 200/600... Train Loss: 0.0529... Val Loss: 0.2636... Val Acc: 0.9528... F1-Score: 0.9533...\n",
      "Epoch: 201/600... Train Loss: 0.0483... Val Loss: 0.2653... Val Acc: 0.9520... F1-Score: 0.9524...\n",
      "Epoch: 202/600... Train Loss: 0.0493... Val Loss: 0.2735... Val Acc: 0.9515... F1-Score: 0.9518...\n",
      "Epoch: 203/600... Train Loss: 0.0555... Val Loss: 0.2589... Val Acc: 0.9520... F1-Score: 0.9526...\n",
      "Epoch: 204/600... Train Loss: 0.0514... Val Loss: 0.2777... Val Acc: 0.9481... F1-Score: 0.9488...\n",
      "Epoch: 205/600... Train Loss: 0.0523... Val Loss: 0.2662... Val Acc: 0.9511... F1-Score: 0.9517...\n",
      "Epoch: 206/600... Train Loss: 0.0464... Val Loss: 0.2776... Val Acc: 0.9518... F1-Score: 0.9524...\n",
      "Epoch: 207/600... Train Loss: 0.0503... Val Loss: 0.2750... Val Acc: 0.9500... F1-Score: 0.9506...\n",
      "Epoch: 208/600... Train Loss: 0.0491... Val Loss: 0.2724... Val Acc: 0.9464... F1-Score: 0.9471...\n",
      "Epoch: 209/600... Train Loss: 0.0527... Val Loss: 0.2686... Val Acc: 0.9513... F1-Score: 0.9516...\n",
      "Epoch: 210/600... Train Loss: 0.0517... Val Loss: 0.2852... Val Acc: 0.9509... F1-Score: 0.9513...\n",
      "Epoch: 211/600... Train Loss: 0.0555... Val Loss: 0.2530... Val Acc: 0.9542... F1-Score: 0.9547...\n",
      "Epoch: 212/600... Train Loss: 0.0596... Val Loss: 0.2756... Val Acc: 0.9531... F1-Score: 0.9535...\n",
      "Epoch: 213/600... Train Loss: 0.0514... Val Loss: 0.2842... Val Acc: 0.9522... F1-Score: 0.9525...\n",
      "Epoch: 214/600... Train Loss: 0.0492... Val Loss: 0.2583... Val Acc: 0.9539... F1-Score: 0.9544...\n",
      "Epoch: 215/600... Train Loss: 0.0491... Val Loss: 0.2908... Val Acc: 0.9453... F1-Score: 0.9458...\n",
      "Epoch: 216/600... Train Loss: 0.0527... Val Loss: 0.2753... Val Acc: 0.9520... F1-Score: 0.9525...\n",
      "Epoch: 217/600... Train Loss: 0.0487... Val Loss: 0.2972... Val Acc: 0.9498... F1-Score: 0.9502...\n",
      "Epoch: 218/600... Train Loss: 0.0496... Val Loss: 0.2965... Val Acc: 0.9490... F1-Score: 0.9494...\n",
      "Epoch: 219/600... Train Loss: 0.0502... Val Loss: 0.2669... Val Acc: 0.9522... F1-Score: 0.9526...\n",
      "Epoch: 220/600... Train Loss: 0.0531... Val Loss: 0.2579... Val Acc: 0.9511... F1-Score: 0.9517...\n",
      "Epoch: 221/600... Train Loss: 0.0496... Val Loss: 0.2834... Val Acc: 0.9479... F1-Score: 0.9485...\n",
      "Epoch: 222/600... Train Loss: 0.0498... Val Loss: 0.2954... Val Acc: 0.9492... F1-Score: 0.9498...\n",
      "Epoch: 223/600... Train Loss: 0.0478... Val Loss: 0.2911... Val Acc: 0.9474... F1-Score: 0.9480...\n",
      "Epoch: 224/600... Train Loss: 0.0511... Val Loss: 0.2592... Val Acc: 0.9513... F1-Score: 0.9519...\n",
      "Epoch: 225/600... Train Loss: 0.0477... Val Loss: 0.2687... Val Acc: 0.9513... F1-Score: 0.9516...\n",
      "Epoch: 226/600... Train Loss: 0.0511... Val Loss: 0.2622... Val Acc: 0.9501... F1-Score: 0.9505...\n",
      "Epoch: 227/600... Train Loss: 0.0453... Val Loss: 0.2633... Val Acc: 0.9516... F1-Score: 0.9521...\n",
      "Epoch: 228/600... Train Loss: 0.0504... Val Loss: 0.2735... Val Acc: 0.9529... F1-Score: 0.9533...\n",
      "Epoch: 229/600... Train Loss: 0.0484... Val Loss: 0.2537... Val Acc: 0.9535... F1-Score: 0.9539...\n",
      "Epoch: 230/600... Train Loss: 0.0467... Val Loss: 0.2726... Val Acc: 0.9520... F1-Score: 0.9525...\n",
      "Epoch: 231/600... Train Loss: 0.0469... Val Loss: 0.2546... Val Acc: 0.9520... F1-Score: 0.9526...\n",
      "Epoch: 232/600... Train Loss: 0.0546... Val Loss: 0.2896... Val Acc: 0.9483... F1-Score: 0.9490...\n",
      "Epoch: 233/600... Train Loss: 0.0502... Val Loss: 0.2622... Val Acc: 0.9520... F1-Score: 0.9526...\n",
      "Epoch: 234/600... Train Loss: 0.0454... Val Loss: 0.2800... Val Acc: 0.9466... F1-Score: 0.9471...\n",
      "Epoch: 235/600... Train Loss: 0.0542... Val Loss: 0.3084... Val Acc: 0.9427... F1-Score: 0.9429...\n",
      "Epoch: 236/600... Train Loss: 0.0530... Val Loss: 0.2600... Val Acc: 0.9546... F1-Score: 0.9551...\n",
      "Epoch: 237/600... Train Loss: 0.0476... Val Loss: 0.2735... Val Acc: 0.9501... F1-Score: 0.9506...\n",
      "Epoch: 238/600... Train Loss: 0.0465... Val Loss: 0.2737... Val Acc: 0.9515... F1-Score: 0.9517...\n",
      "Epoch: 239/600... Train Loss: 0.0505... Val Loss: 0.3040... Val Acc: 0.9487... F1-Score: 0.9488...\n",
      "Epoch: 240/600... Train Loss: 0.0531... Val Loss: 0.2959... Val Acc: 0.9490... F1-Score: 0.9494...\n",
      "Epoch: 241/600... Train Loss: 0.0526... Val Loss: 0.2815... Val Acc: 0.9507... F1-Score: 0.9512...\n",
      "Epoch: 242/600... Train Loss: 0.0464... Val Loss: 0.2893... Val Acc: 0.9511... F1-Score: 0.9515...\n",
      "Epoch: 243/600... Train Loss: 0.0451... Val Loss: 0.2725... Val Acc: 0.9522... F1-Score: 0.9527...\n",
      "Epoch: 244/600... Train Loss: 0.0449... Val Loss: 0.2871... Val Acc: 0.9509... F1-Score: 0.9514...\n",
      "Epoch: 245/600... Train Loss: 0.0485... Val Loss: 0.3746... Val Acc: 0.9427... F1-Score: 0.9434...\n",
      "Epoch: 246/600... Train Loss: 0.0528... Val Loss: 0.3216... Val Acc: 0.9470... F1-Score: 0.9474...\n",
      "Epoch: 247/600... Train Loss: 0.0489... Val Loss: 0.3011... Val Acc: 0.9466... F1-Score: 0.9474...\n",
      "Epoch: 248/600... Train Loss: 0.0475... Val Loss: 0.2906... Val Acc: 0.9528... F1-Score: 0.9531...\n",
      "Epoch: 249/600... Train Loss: 0.0465... Val Loss: 0.3123... Val Acc: 0.9494... F1-Score: 0.9499...\n",
      "Epoch: 250/600... Train Loss: 0.0484... Val Loss: 0.2962... Val Acc: 0.9511... F1-Score: 0.9514...\n",
      "Epoch: 251/600... Train Loss: 0.0457... Val Loss: 0.3087... Val Acc: 0.9479... F1-Score: 0.9484...\n",
      "Epoch: 252/600... Train Loss: 0.0462... Val Loss: 0.2836... Val Acc: 0.9524... F1-Score: 0.9529...\n",
      "Epoch: 253/600... Train Loss: 0.0483... Val Loss: 0.3159... Val Acc: 0.9488... F1-Score: 0.9492...\n",
      "Epoch: 254/600... Train Loss: 0.0453... Val Loss: 0.2793... Val Acc: 0.9516... F1-Score: 0.9521...\n",
      "Epoch: 255/600... Train Loss: 0.0435... Val Loss: 0.2829... Val Acc: 0.9503... F1-Score: 0.9509...\n",
      "Epoch: 256/600... Train Loss: 0.0581... Val Loss: 0.3089... Val Acc: 0.9498... F1-Score: 0.9502...\n",
      "Epoch: 257/600... Train Loss: 0.0516... Val Loss: 0.2848... Val Acc: 0.9500... F1-Score: 0.9502...\n",
      "Epoch: 258/600... Train Loss: 0.0479... Val Loss: 0.2755... Val Acc: 0.9524... F1-Score: 0.9528...\n",
      "Epoch: 259/600... Train Loss: 0.0478... Val Loss: 0.3187... Val Acc: 0.9472... F1-Score: 0.9477...\n",
      "Epoch: 260/600... Train Loss: 0.0489... Val Loss: 0.2771... Val Acc: 0.9531... F1-Score: 0.9535...\n",
      "Epoch: 261/600... Train Loss: 0.0489... Val Loss: 0.3803... Val Acc: 0.9483... F1-Score: 0.9489...\n",
      "Epoch: 262/600... Train Loss: 0.0490... Val Loss: 0.2783... Val Acc: 0.9542... F1-Score: 0.9547...\n",
      "Epoch: 263/600... Train Loss: 0.0509... Val Loss: 0.2666... Val Acc: 0.9529... F1-Score: 0.9535...\n",
      "Epoch: 264/600... Train Loss: 0.0534... Val Loss: 0.2937... Val Acc: 0.9487... F1-Score: 0.9490...\n",
      "Epoch: 265/600... Train Loss: 0.0535... Val Loss: 0.2531... Val Acc: 0.9524... F1-Score: 0.9530...\n",
      "Epoch: 266/600... Train Loss: 0.0468... Val Loss: 0.2755... Val Acc: 0.9501... F1-Score: 0.9504...\n",
      "Epoch: 267/600... Train Loss: 0.0478... Val Loss: 0.2717... Val Acc: 0.9516... F1-Score: 0.9520...\n",
      "Epoch: 268/600... Train Loss: 0.0451... Val Loss: 0.2829... Val Acc: 0.9541... F1-Score: 0.9545...\n",
      "Epoch: 269/600... Train Loss: 0.0440... Val Loss: 0.2814... Val Acc: 0.9533... F1-Score: 0.9537...\n",
      "Epoch: 270/600... Train Loss: 0.0459... Val Loss: 0.2799... Val Acc: 0.9548... F1-Score: 0.9553...\n",
      "Epoch: 271/600... Train Loss: 0.0423... Val Loss: 0.2829... Val Acc: 0.9515... F1-Score: 0.9520...\n",
      "Epoch: 272/600... Train Loss: 0.0440... Val Loss: 0.2890... Val Acc: 0.9529... F1-Score: 0.9535...\n",
      "Epoch: 273/600... Train Loss: 0.0444... Val Loss: 0.2887... Val Acc: 0.9522... F1-Score: 0.9526...\n",
      "Epoch: 274/600... Train Loss: 0.0442... Val Loss: 0.3005... Val Acc: 0.9528... F1-Score: 0.9531...\n",
      "Epoch: 275/600... Train Loss: 0.0500... Val Loss: 0.2629... Val Acc: 0.9555... F1-Score: 0.9560...\n",
      "Epoch: 276/600... Train Loss: 0.0439... Val Loss: 0.2671... Val Acc: 0.9552... F1-Score: 0.9556...\n",
      "Epoch: 277/600... Train Loss: 0.0449... Val Loss: 0.2910... Val Acc: 0.9520... F1-Score: 0.9524...\n",
      "Epoch: 278/600... Train Loss: 0.0458... Val Loss: 0.2846... Val Acc: 0.9513... F1-Score: 0.9518...\n",
      "Epoch: 279/600... Train Loss: 0.0718... Val Loss: 0.2610... Val Acc: 0.9492... F1-Score: 0.9499...\n",
      "Epoch: 280/600... Train Loss: 0.0484... Val Loss: 0.2632... Val Acc: 0.9533... F1-Score: 0.9538...\n",
      "Epoch: 281/600... Train Loss: 0.0436... Val Loss: 0.2792... Val Acc: 0.9528... F1-Score: 0.9534...\n",
      "Epoch: 282/600... Train Loss: 0.0446... Val Loss: 0.2674... Val Acc: 0.9546... F1-Score: 0.9550...\n",
      "Epoch: 283/600... Train Loss: 0.0450... Val Loss: 0.2689... Val Acc: 0.9541... F1-Score: 0.9545...\n",
      "Epoch: 284/600... Train Loss: 0.0480... Val Loss: 0.2466... Val Acc: 0.9531... F1-Score: 0.9535...\n",
      "Epoch: 285/600... Train Loss: 0.0453... Val Loss: 0.2660... Val Acc: 0.9528... F1-Score: 0.9533...\n",
      "Epoch: 286/600... Train Loss: 0.0439... Val Loss: 0.3209... Val Acc: 0.9505... F1-Score: 0.9508...\n",
      "Epoch: 287/600... Train Loss: 0.0441... Val Loss: 0.3217... Val Acc: 0.9462... F1-Score: 0.9466...\n",
      "Epoch: 288/600... Train Loss: 0.0483... Val Loss: 0.2939... Val Acc: 0.9526... F1-Score: 0.9530...\n",
      "Epoch: 289/600... Train Loss: 0.0485... Val Loss: 0.2925... Val Acc: 0.9546... F1-Score: 0.9550...\n",
      "Epoch: 290/600... Train Loss: 0.0463... Val Loss: 0.2882... Val Acc: 0.9533... F1-Score: 0.9539...\n",
      "Epoch: 291/600... Train Loss: 0.0463... Val Loss: 0.2869... Val Acc: 0.9505... F1-Score: 0.9509...\n",
      "Epoch: 292/600... Train Loss: 0.0462... Val Loss: 0.3082... Val Acc: 0.9529... F1-Score: 0.9533...\n",
      "Epoch: 293/600... Train Loss: 0.0452... Val Loss: 0.2863... Val Acc: 0.9537... F1-Score: 0.9540...\n",
      "Epoch: 294/600... Train Loss: 0.0478... Val Loss: 0.2759... Val Acc: 0.9546... F1-Score: 0.9551...\n",
      "Epoch: 295/600... Train Loss: 0.0458... Val Loss: 0.2994... Val Acc: 0.9522... F1-Score: 0.9527...\n",
      "Epoch: 296/600... Train Loss: 0.0456... Val Loss: 0.3091... Val Acc: 0.9513... F1-Score: 0.9518...\n",
      "Epoch: 297/600... Train Loss: 0.0455... Val Loss: 0.3038... Val Acc: 0.9511... F1-Score: 0.9516...\n",
      "Epoch: 298/600... Train Loss: 0.0446... Val Loss: 0.3036... Val Acc: 0.9511... F1-Score: 0.9516...\n",
      "Epoch: 299/600... Train Loss: 0.0426... Val Loss: 0.2914... Val Acc: 0.9533... F1-Score: 0.9536...\n",
      "Epoch: 300/600... Train Loss: 0.0436... Val Loss: 0.3241... Val Acc: 0.9526... F1-Score: 0.9530...\n",
      "Epoch: 301/600... Train Loss: 0.0481... Val Loss: 0.2934... Val Acc: 0.9533... F1-Score: 0.9538...\n",
      "Epoch: 302/600... Train Loss: 0.0427... Val Loss: 0.3000... Val Acc: 0.9528... F1-Score: 0.9530...\n",
      "Epoch: 303/600... Train Loss: 0.0453... Val Loss: 0.3048... Val Acc: 0.9518... F1-Score: 0.9524...\n",
      "Epoch: 304/600... Train Loss: 0.0434... Val Loss: 0.3129... Val Acc: 0.9511... F1-Score: 0.9515...\n",
      "Epoch: 305/600... Train Loss: 0.0432... Val Loss: 0.2971... Val Acc: 0.9528... F1-Score: 0.9533...\n",
      "Epoch: 306/600... Train Loss: 0.0479... Val Loss: 0.3030... Val Acc: 0.9503... F1-Score: 0.9510...\n",
      "Epoch: 307/600... Train Loss: 0.0478... Val Loss: 0.3018... Val Acc: 0.9544... F1-Score: 0.9549...\n",
      "Epoch: 308/600... Train Loss: 0.0462... Val Loss: 0.2811... Val Acc: 0.9528... F1-Score: 0.9532...\n",
      "Epoch: 309/600... Train Loss: 0.0444... Val Loss: 0.2950... Val Acc: 0.9542... F1-Score: 0.9547...\n",
      "Epoch: 310/600... Train Loss: 0.0432... Val Loss: 0.3033... Val Acc: 0.9537... F1-Score: 0.9542...\n",
      "Epoch: 311/600... Train Loss: 0.0418... Val Loss: 0.3146... Val Acc: 0.9537... F1-Score: 0.9540...\n",
      "Epoch: 312/600... Train Loss: 0.0440... Val Loss: 0.3115... Val Acc: 0.9505... F1-Score: 0.9511...\n",
      "Epoch: 313/600... Train Loss: 0.0424... Val Loss: 0.3018... Val Acc: 0.9541... F1-Score: 0.9545...\n",
      "Epoch: 314/600... Train Loss: 0.0446... Val Loss: 0.3132... Val Acc: 0.9479... F1-Score: 0.9486...\n",
      "Epoch: 315/600... Train Loss: 0.0434... Val Loss: 0.3033... Val Acc: 0.9518... F1-Score: 0.9522...\n",
      "Epoch: 316/600... Train Loss: 0.0435... Val Loss: 0.2961... Val Acc: 0.9537... F1-Score: 0.9542...\n",
      "Epoch: 317/600... Train Loss: 0.0424... Val Loss: 0.3020... Val Acc: 0.9531... F1-Score: 0.9536...\n",
      "Epoch: 318/600... Train Loss: 0.0444... Val Loss: 0.3355... Val Acc: 0.9479... F1-Score: 0.9481...\n",
      "Epoch: 319/600... Train Loss: 0.0443... Val Loss: 0.3023... Val Acc: 0.9470... F1-Score: 0.9477...\n",
      "Epoch: 320/600... Train Loss: 0.0534... Val Loss: 0.3158... Val Acc: 0.9485... F1-Score: 0.9488...\n",
      "Epoch: 321/600... Train Loss: 0.0610... Val Loss: 0.2797... Val Acc: 0.9531... F1-Score: 0.9535...\n",
      "Epoch: 322/600... Train Loss: 0.0453... Val Loss: 0.2766... Val Acc: 0.9537... F1-Score: 0.9542...\n",
      "Epoch: 323/600... Train Loss: 0.0422... Val Loss: 0.3030... Val Acc: 0.9492... F1-Score: 0.9499...\n",
      "Epoch: 324/600... Train Loss: 0.0449... Val Loss: 0.3041... Val Acc: 0.9520... F1-Score: 0.9526...\n",
      "Epoch: 325/600... Train Loss: 0.0449... Val Loss: 0.3031... Val Acc: 0.9537... F1-Score: 0.9543...\n",
      "Epoch: 326/600... Train Loss: 0.0448... Val Loss: 0.3001... Val Acc: 0.9520... F1-Score: 0.9523...\n",
      "Epoch: 327/600... Train Loss: 0.0418... Val Loss: 0.2954... Val Acc: 0.9529... F1-Score: 0.9534...\n",
      "Epoch: 328/600... Train Loss: 0.0407... Val Loss: 0.3101... Val Acc: 0.9524... F1-Score: 0.9528...\n",
      "Epoch: 329/600... Train Loss: 0.0423... Val Loss: 0.3260... Val Acc: 0.9537... F1-Score: 0.9540...\n",
      "Epoch: 330/600... Train Loss: 0.0505... Val Loss: 0.3400... Val Acc: 0.9490... F1-Score: 0.9494...\n",
      "Epoch: 331/600... Train Loss: 0.0585... Val Loss: 0.2919... Val Acc: 0.9505... F1-Score: 0.9511...\n",
      "Epoch: 332/600... Train Loss: 0.0447... Val Loss: 0.3027... Val Acc: 0.9479... F1-Score: 0.9484...\n",
      "Epoch: 333/600... Train Loss: 0.0429... Val Loss: 0.2882... Val Acc: 0.9520... F1-Score: 0.9526...\n",
      "Epoch: 334/600... Train Loss: 0.0421... Val Loss: 0.2898... Val Acc: 0.9526... F1-Score: 0.9531...\n",
      "Epoch: 335/600... Train Loss: 0.0413... Val Loss: 0.2927... Val Acc: 0.9531... F1-Score: 0.9537...\n",
      "Epoch: 336/600... Train Loss: 0.0456... Val Loss: 0.2954... Val Acc: 0.9522... F1-Score: 0.9528...\n",
      "Epoch: 337/600... Train Loss: 0.0431... Val Loss: 0.2945... Val Acc: 0.9528... F1-Score: 0.9532...\n",
      "Epoch: 338/600... Train Loss: 0.0489... Val Loss: 0.7688... Val Acc: 0.9232... F1-Score: 0.9239...\n",
      "Epoch: 339/600... Train Loss: 0.0764... Val Loss: 0.3047... Val Acc: 0.9509... F1-Score: 0.9513...\n",
      "Epoch: 340/600... Train Loss: 0.0430... Val Loss: 0.2862... Val Acc: 0.9528... F1-Score: 0.9532...\n",
      "Epoch: 341/600... Train Loss: 0.0448... Val Loss: 0.2832... Val Acc: 0.9524... F1-Score: 0.9528...\n",
      "Epoch: 342/600... Train Loss: 0.0409... Val Loss: 0.3065... Val Acc: 0.9539... F1-Score: 0.9544...\n",
      "Epoch: 343/600... Train Loss: 0.0416... Val Loss: 0.2947... Val Acc: 0.9498... F1-Score: 0.9503...\n",
      "Epoch: 344/600... Train Loss: 0.0441... Val Loss: 0.2829... Val Acc: 0.9535... F1-Score: 0.9539...\n",
      "Epoch: 345/600... Train Loss: 0.0437... Val Loss: 0.3101... Val Acc: 0.9507... F1-Score: 0.9512...\n",
      "Epoch: 346/600... Train Loss: 0.0419... Val Loss: 0.2995... Val Acc: 0.9518... F1-Score: 0.9524...\n",
      "Epoch: 347/600... Train Loss: 0.0435... Val Loss: 0.2958... Val Acc: 0.9528... F1-Score: 0.9534...\n",
      "Epoch: 348/600... Train Loss: 0.0438... Val Loss: 0.2930... Val Acc: 0.9533... F1-Score: 0.9538...\n",
      "Epoch: 349/600... Train Loss: 0.0426... Val Loss: 0.3023... Val Acc: 0.9535... F1-Score: 0.9538...\n",
      "Epoch: 350/600... Train Loss: 0.0422... Val Loss: 0.3058... Val Acc: 0.9533... F1-Score: 0.9539...\n",
      "Epoch: 351/600... Train Loss: 0.0453... Val Loss: 0.3076... Val Acc: 0.9524... F1-Score: 0.9530...\n",
      "Epoch: 352/600... Train Loss: 0.0429... Val Loss: 0.3352... Val Acc: 0.9498... F1-Score: 0.9504...\n",
      "Epoch: 353/600... Train Loss: 0.0451... Val Loss: 0.3011... Val Acc: 0.9526... F1-Score: 0.9531...\n",
      "Epoch: 354/600... Train Loss: 0.0425... Val Loss: 0.3075... Val Acc: 0.9488... F1-Score: 0.9494...\n",
      "Epoch: 355/600... Train Loss: 0.0396... Val Loss: 0.3041... Val Acc: 0.9513... F1-Score: 0.9517...\n",
      "Epoch: 356/600... Train Loss: 0.0470... Val Loss: 0.3078... Val Acc: 0.9505... F1-Score: 0.9511...\n",
      "Epoch: 357/600... Train Loss: 0.0422... Val Loss: 0.3001... Val Acc: 0.9511... F1-Score: 0.9516...\n",
      "Epoch: 358/600... Train Loss: 0.0424... Val Loss: 0.3396... Val Acc: 0.9511... F1-Score: 0.9517...\n",
      "Epoch: 359/600... Train Loss: 0.0584... Val Loss: 0.3984... Val Acc: 0.9457... F1-Score: 0.9462...\n",
      "Epoch: 360/600... Train Loss: 0.0487... Val Loss: 0.3086... Val Acc: 0.9520... F1-Score: 0.9525...\n",
      "Epoch: 361/600... Train Loss: 0.0476... Val Loss: 0.2972... Val Acc: 0.9505... F1-Score: 0.9511...\n",
      "Epoch: 362/600... Train Loss: 0.0454... Val Loss: 0.2955... Val Acc: 0.9515... F1-Score: 0.9519...\n",
      "Epoch: 363/600... Train Loss: 0.0437... Val Loss: 0.3123... Val Acc: 0.9524... F1-Score: 0.9529...\n",
      "Epoch: 364/600... Train Loss: 0.0405... Val Loss: 0.2869... Val Acc: 0.9531... F1-Score: 0.9537...\n",
      "Epoch: 365/600... Train Loss: 0.0430... Val Loss: 0.3045... Val Acc: 0.9524... F1-Score: 0.9528...\n",
      "Epoch: 366/600... Train Loss: 0.0415... Val Loss: 0.2948... Val Acc: 0.9509... F1-Score: 0.9514...\n",
      "Epoch: 367/600... Train Loss: 0.0424... Val Loss: 0.2891... Val Acc: 0.9546... F1-Score: 0.9551...\n",
      "Epoch: 368/600... Train Loss: 0.0431... Val Loss: 0.3032... Val Acc: 0.9533... F1-Score: 0.9539...\n",
      "Epoch: 369/600... Train Loss: 0.0419... Val Loss: 0.2892... Val Acc: 0.9541... F1-Score: 0.9545...\n",
      "Epoch: 370/600... Train Loss: 0.0411... Val Loss: 0.3524... Val Acc: 0.9451... F1-Score: 0.9457...\n",
      "Epoch: 371/600... Train Loss: 0.0538... Val Loss: 0.3501... Val Acc: 0.9403... F1-Score: 0.9406...\n",
      "Epoch: 372/600... Train Loss: 0.0458... Val Loss: 0.3054... Val Acc: 0.9524... F1-Score: 0.9529...\n",
      "Epoch: 373/600... Train Loss: 0.0431... Val Loss: 0.2945... Val Acc: 0.9535... F1-Score: 0.9541...\n",
      "Epoch: 374/600... Train Loss: 0.0432... Val Loss: 0.2942... Val Acc: 0.9542... F1-Score: 0.9547...\n",
      "Epoch: 375/600... Train Loss: 0.0422... Val Loss: 0.2896... Val Acc: 0.9552... F1-Score: 0.9557...\n",
      "Epoch: 376/600... Train Loss: 0.0433... Val Loss: 0.3058... Val Acc: 0.9511... F1-Score: 0.9517...\n",
      "Epoch: 377/600... Train Loss: 0.0404... Val Loss: 0.3063... Val Acc: 0.9531... F1-Score: 0.9536...\n",
      "Epoch: 378/600... Train Loss: 0.0416... Val Loss: 0.3290... Val Acc: 0.9518... F1-Score: 0.9522...\n",
      "Epoch: 379/600... Train Loss: 0.0424... Val Loss: 0.3087... Val Acc: 0.9518... F1-Score: 0.9524...\n",
      "Epoch: 380/600... Train Loss: 0.0433... Val Loss: 0.2938... Val Acc: 0.9548... F1-Score: 0.9553...\n",
      "Epoch: 381/600... Train Loss: 0.0408... Val Loss: 0.3058... Val Acc: 0.9485... F1-Score: 0.9491...\n",
      "Epoch: 382/600... Train Loss: 0.0457... Val Loss: 0.2979... Val Acc: 0.9518... F1-Score: 0.9523...\n",
      "Epoch: 383/600... Train Loss: 0.0514... Val Loss: 0.3199... Val Acc: 0.9494... F1-Score: 0.9500...\n",
      "Epoch: 384/600... Train Loss: 0.0490... Val Loss: 0.3174... Val Acc: 0.9503... F1-Score: 0.9509...\n",
      "Epoch: 385/600... Train Loss: 0.0406... Val Loss: 0.3348... Val Acc: 0.9498... F1-Score: 0.9503...\n",
      "Epoch: 386/600... Train Loss: 0.0419... Val Loss: 0.3162... Val Acc: 0.9526... F1-Score: 0.9530...\n",
      "Epoch: 387/600... Train Loss: 0.0427... Val Loss: 0.3113... Val Acc: 0.9516... F1-Score: 0.9521...\n",
      "Epoch: 388/600... Train Loss: 0.0446... Val Loss: 0.3107... Val Acc: 0.9492... F1-Score: 0.9500...\n",
      "Epoch: 389/600... Train Loss: 0.0483... Val Loss: 0.3328... Val Acc: 0.9488... F1-Score: 0.9494...\n",
      "Epoch: 390/600... Train Loss: 0.0440... Val Loss: 0.3235... Val Acc: 0.9522... F1-Score: 0.9524...\n",
      "Epoch: 391/600... Train Loss: 0.0402... Val Loss: 0.2981... Val Acc: 0.9531... F1-Score: 0.9535...\n",
      "Epoch: 392/600... Train Loss: 0.0445... Val Loss: 0.3200... Val Acc: 0.9479... F1-Score: 0.9485...\n",
      "Epoch: 393/600... Train Loss: 0.0436... Val Loss: 0.2996... Val Acc: 0.9533... F1-Score: 0.9538...\n",
      "Epoch: 394/600... Train Loss: 0.0412... Val Loss: 0.3125... Val Acc: 0.9529... F1-Score: 0.9534...\n",
      "Epoch: 395/600... Train Loss: 0.0442... Val Loss: 0.2974... Val Acc: 0.9505... F1-Score: 0.9510...\n",
      "Epoch: 396/600... Train Loss: 0.0426... Val Loss: 0.3074... Val Acc: 0.9546... F1-Score: 0.9550...\n",
      "Epoch: 397/600... Train Loss: 0.0431... Val Loss: 0.2891... Val Acc: 0.9531... F1-Score: 0.9536...\n",
      "Epoch: 398/600... Train Loss: 0.0422... Val Loss: 0.2977... Val Acc: 0.9554... F1-Score: 0.9557...\n",
      "Epoch: 399/600... Train Loss: 0.0403... Val Loss: 0.3043... Val Acc: 0.9522... F1-Score: 0.9528...\n",
      "Epoch: 400/600... Train Loss: 0.0393... Val Loss: 0.3158... Val Acc: 0.9515... F1-Score: 0.9522...\n",
      "Epoch: 401/600... Train Loss: 0.0417... Val Loss: 0.3124... Val Acc: 0.9524... F1-Score: 0.9529...\n",
      "Epoch: 402/600... Train Loss: 0.0408... Val Loss: 0.3294... Val Acc: 0.9507... F1-Score: 0.9513...\n",
      "Epoch: 403/600... Train Loss: 0.0509... Val Loss: 0.3071... Val Acc: 0.9529... F1-Score: 0.9533...\n",
      "Epoch: 404/600... Train Loss: 0.0471... Val Loss: 0.2858... Val Acc: 0.9526... F1-Score: 0.9531...\n",
      "Epoch: 405/600... Train Loss: 0.0404... Val Loss: 0.3059... Val Acc: 0.9507... F1-Score: 0.9510...\n",
      "Epoch: 406/600... Train Loss: 0.0418... Val Loss: 0.3083... Val Acc: 0.9509... F1-Score: 0.9515...\n",
      "Epoch: 407/600... Train Loss: 0.0417... Val Loss: 0.3264... Val Acc: 0.9520... F1-Score: 0.9524...\n",
      "Epoch: 408/600... Train Loss: 0.0400... Val Loss: 0.3058... Val Acc: 0.9526... F1-Score: 0.9530...\n",
      "Epoch: 409/600... Train Loss: 0.0423... Val Loss: 0.3094... Val Acc: 0.9516... F1-Score: 0.9520...\n",
      "Epoch: 410/600... Train Loss: 0.0402... Val Loss: 0.2969... Val Acc: 0.9529... F1-Score: 0.9533...\n",
      "Epoch: 411/600... Train Loss: 0.0416... Val Loss: 0.2985... Val Acc: 0.9526... F1-Score: 0.9530...\n",
      "Epoch: 412/600... Train Loss: 0.0425... Val Loss: 0.3048... Val Acc: 0.9515... F1-Score: 0.9519...\n",
      "Epoch: 413/600... Train Loss: 0.0405... Val Loss: 0.3061... Val Acc: 0.9552... F1-Score: 0.9556...\n",
      "Epoch: 414/600... Train Loss: 0.0414... Val Loss: 0.3095... Val Acc: 0.9522... F1-Score: 0.9527...\n",
      "Epoch: 415/600... Train Loss: 0.0400... Val Loss: 0.3077... Val Acc: 0.9516... F1-Score: 0.9521...\n",
      "Epoch: 416/600... Train Loss: 0.0453... Val Loss: 0.3280... Val Acc: 0.9528... F1-Score: 0.9533...\n",
      "Epoch: 417/600... Train Loss: 0.0427... Val Loss: 0.3053... Val Acc: 0.9520... F1-Score: 0.9525...\n",
      "Epoch: 418/600... Train Loss: 0.0425... Val Loss: 0.3122... Val Acc: 0.9498... F1-Score: 0.9503...\n",
      "Epoch: 419/600... Train Loss: 0.0408... Val Loss: 0.3095... Val Acc: 0.9531... F1-Score: 0.9537...\n",
      "Epoch: 420/600... Train Loss: 0.0391... Val Loss: 0.3100... Val Acc: 0.9541... F1-Score: 0.9544...\n",
      "Epoch: 421/600... Train Loss: 0.0403... Val Loss: 0.3188... Val Acc: 0.9518... F1-Score: 0.9523...\n",
      "Epoch: 422/600... Train Loss: 0.0574... Val Loss: 0.3452... Val Acc: 0.9509... F1-Score: 0.9513...\n",
      "Epoch: 423/600... Train Loss: 0.0407... Val Loss: 0.3041... Val Acc: 0.9550... F1-Score: 0.9554...\n",
      "Epoch: 424/600... Train Loss: 0.0399... Val Loss: 0.3214... Val Acc: 0.9539... F1-Score: 0.9543...\n",
      "Epoch: 425/600... Train Loss: 0.0414... Val Loss: 0.3058... Val Acc: 0.9529... F1-Score: 0.9535...\n",
      "Epoch: 426/600... Train Loss: 0.0411... Val Loss: 0.3668... Val Acc: 0.9503... F1-Score: 0.9509...\n",
      "Epoch: 427/600... Train Loss: 0.0442... Val Loss: 0.3244... Val Acc: 0.9533... F1-Score: 0.9541...\n",
      "Epoch: 428/600... Train Loss: 0.0438... Val Loss: 0.3120... Val Acc: 0.9529... F1-Score: 0.9532...\n",
      "Epoch: 429/600... Train Loss: 0.0400... Val Loss: 0.3375... Val Acc: 0.9509... F1-Score: 0.9515...\n",
      "Epoch: 430/600... Train Loss: 0.0397... Val Loss: 0.3280... Val Acc: 0.9528... F1-Score: 0.9532...\n",
      "Epoch: 431/600... Train Loss: 0.0451... Val Loss: 0.3157... Val Acc: 0.9515... F1-Score: 0.9522...\n",
      "Epoch: 432/600... Train Loss: 0.0397... Val Loss: 0.3098... Val Acc: 0.9516... F1-Score: 0.9522...\n",
      "Epoch: 433/600... Train Loss: 0.0401... Val Loss: 0.3517... Val Acc: 0.9515... F1-Score: 0.9519...\n",
      "Epoch: 434/600... Train Loss: 0.0401... Val Loss: 0.3117... Val Acc: 0.9535... F1-Score: 0.9540...\n",
      "Epoch: 435/600... Train Loss: 0.0399... Val Loss: 0.3139... Val Acc: 0.9544... F1-Score: 0.9549...\n",
      "Epoch: 436/600... Train Loss: 0.0399... Val Loss: 0.3335... Val Acc: 0.9542... F1-Score: 0.9548...\n",
      "Epoch: 437/600... Train Loss: 0.0425... Val Loss: 0.3104... Val Acc: 0.9555... F1-Score: 0.9560...\n",
      "Epoch: 438/600... Train Loss: 0.0398... Val Loss: 0.3198... Val Acc: 0.9516... F1-Score: 0.9521...\n",
      "Epoch: 439/600... Train Loss: 0.0403... Val Loss: 0.3202... Val Acc: 0.9546... F1-Score: 0.9551...\n",
      "Epoch: 440/600... Train Loss: 0.0400... Val Loss: 0.3181... Val Acc: 0.9535... F1-Score: 0.9540...\n",
      "Epoch: 441/600... Train Loss: 0.0464... Val Loss: 0.3492... Val Acc: 0.9513... F1-Score: 0.9517...\n",
      "Epoch: 442/600... Train Loss: 0.0397... Val Loss: 0.3152... Val Acc: 0.9539... F1-Score: 0.9544...\n",
      "Epoch: 443/600... Train Loss: 0.0415... Val Loss: 0.3141... Val Acc: 0.9524... F1-Score: 0.9531...\n",
      "Epoch: 444/600... Train Loss: 0.0418... Val Loss: 0.3075... Val Acc: 0.9541... F1-Score: 0.9545...\n",
      "Epoch: 445/600... Train Loss: 0.0389... Val Loss: 0.3170... Val Acc: 0.9528... F1-Score: 0.9533...\n",
      "Epoch: 446/600... Train Loss: 0.0390... Val Loss: 0.3268... Val Acc: 0.9550... F1-Score: 0.9556...\n",
      "Epoch: 447/600... Train Loss: 0.0470... Val Loss: 0.3246... Val Acc: 0.9526... F1-Score: 0.9531...\n",
      "Epoch: 448/600... Train Loss: 0.0446... Val Loss: 0.3183... Val Acc: 0.9507... F1-Score: 0.9513...\n",
      "Epoch: 449/600... Train Loss: 0.0420... Val Loss: 0.3139... Val Acc: 0.9550... F1-Score: 0.9554...\n",
      "Epoch: 450/600... Train Loss: 0.0408... Val Loss: 0.3101... Val Acc: 0.9565... F1-Score: 0.9568...\n",
      "Epoch: 451/600... Train Loss: 0.0414... Val Loss: 0.3114... Val Acc: 0.9539... F1-Score: 0.9544...\n",
      "Epoch: 452/600... Train Loss: 0.0411... Val Loss: 0.3209... Val Acc: 0.9531... F1-Score: 0.9538...\n",
      "Epoch: 453/600... Train Loss: 0.0461... Val Loss: 0.3132... Val Acc: 0.9539... F1-Score: 0.9544...\n",
      "Epoch: 454/600... Train Loss: 0.0413... Val Loss: 0.3168... Val Acc: 0.9505... F1-Score: 0.9509...\n",
      "Epoch: 455/600... Train Loss: 0.0438... Val Loss: 0.3181... Val Acc: 0.9501... F1-Score: 0.9507...\n",
      "Epoch: 456/600... Train Loss: 0.0418... Val Loss: 0.3202... Val Acc: 0.9496... F1-Score: 0.9503...\n",
      "Epoch: 457/600... Train Loss: 0.0404... Val Loss: 0.3281... Val Acc: 0.9531... F1-Score: 0.9536...\n",
      "Epoch: 458/600... Train Loss: 0.0430... Val Loss: 0.3061... Val Acc: 0.9528... F1-Score: 0.9532...\n",
      "Epoch: 459/600... Train Loss: 0.0411... Val Loss: 0.3108... Val Acc: 0.9546... F1-Score: 0.9552...\n",
      "Epoch: 460/600... Train Loss: 0.0399... Val Loss: 0.3310... Val Acc: 0.9522... F1-Score: 0.9526...\n",
      "Epoch: 461/600... Train Loss: 0.0395... Val Loss: 0.3381... Val Acc: 0.9518... F1-Score: 0.9524...\n",
      "Epoch: 462/600... Train Loss: 0.0419... Val Loss: 0.3264... Val Acc: 0.9531... F1-Score: 0.9535...\n",
      "Epoch: 463/600... Train Loss: 0.0399... Val Loss: 0.3205... Val Acc: 0.9544... F1-Score: 0.9548...\n",
      "Epoch: 464/600... Train Loss: 0.0396... Val Loss: 0.3127... Val Acc: 0.9542... F1-Score: 0.9547...\n",
      "Epoch: 465/600... Train Loss: 0.0411... Val Loss: 0.3225... Val Acc: 0.9544... F1-Score: 0.9550...\n",
      "Epoch: 466/600... Train Loss: 0.0399... Val Loss: 0.3244... Val Acc: 0.9546... F1-Score: 0.9552...\n",
      "Epoch: 467/600... Train Loss: 0.0422... Val Loss: 0.3608... Val Acc: 0.9505... F1-Score: 0.9511...\n",
      "Epoch: 468/600... Train Loss: 0.0413... Val Loss: 0.3201... Val Acc: 0.9529... F1-Score: 0.9535...\n",
      "Epoch: 469/600... Train Loss: 0.0436... Val Loss: 0.3501... Val Acc: 0.9539... F1-Score: 0.9543...\n",
      "Epoch: 470/600... Train Loss: 0.0469... Val Loss: 0.3208... Val Acc: 0.9542... F1-Score: 0.9547...\n",
      "Epoch: 471/600... Train Loss: 0.0415... Val Loss: 0.3201... Val Acc: 0.9539... F1-Score: 0.9543...\n",
      "Epoch: 472/600... Train Loss: 0.0403... Val Loss: 0.3150... Val Acc: 0.9537... F1-Score: 0.9542...\n",
      "Epoch: 473/600... Train Loss: 0.0432... Val Loss: 0.3249... Val Acc: 0.9518... F1-Score: 0.9524...\n",
      "Epoch: 474/600... Train Loss: 0.0399... Val Loss: 0.3279... Val Acc: 0.9539... F1-Score: 0.9545...\n",
      "Epoch: 475/600... Train Loss: 0.0397... Val Loss: 0.3330... Val Acc: 0.9524... F1-Score: 0.9529...\n",
      "Epoch: 476/600... Train Loss: 0.0411... Val Loss: 0.3280... Val Acc: 0.9522... F1-Score: 0.9526...\n",
      "Epoch: 477/600... Train Loss: 0.0413... Val Loss: 0.3404... Val Acc: 0.9524... F1-Score: 0.9528...\n",
      "Epoch: 478/600... Train Loss: 0.0435... Val Loss: 0.3277... Val Acc: 0.9515... F1-Score: 0.9520...\n",
      "Epoch: 479/600... Train Loss: 0.0469... Val Loss: 0.3657... Val Acc: 0.9297... F1-Score: 0.9302...\n",
      "Epoch: 480/600... Train Loss: 0.0436... Val Loss: 0.3137... Val Acc: 0.9554... F1-Score: 0.9558...\n",
      "Epoch: 481/600... Train Loss: 0.0403... Val Loss: 0.3312... Val Acc: 0.9535... F1-Score: 0.9540...\n",
      "Epoch: 482/600... Train Loss: 0.0426... Val Loss: 0.3170... Val Acc: 0.9541... F1-Score: 0.9547...\n",
      "Epoch: 483/600... Train Loss: 0.0396... Val Loss: 0.3204... Val Acc: 0.9542... F1-Score: 0.9548...\n",
      "Epoch: 484/600... Train Loss: 0.0424... Val Loss: 0.3339... Val Acc: 0.9526... F1-Score: 0.9529...\n",
      "Epoch: 485/600... Train Loss: 0.0394... Val Loss: 0.3261... Val Acc: 0.9535... F1-Score: 0.9541...\n",
      "Epoch: 486/600... Train Loss: 0.0417... Val Loss: 0.3322... Val Acc: 0.9529... F1-Score: 0.9535...\n",
      "Epoch: 487/600... Train Loss: 0.0437... Val Loss: 0.3570... Val Acc: 0.9498... F1-Score: 0.9502...\n",
      "Epoch: 488/600... Train Loss: 0.0527... Val Loss: 0.2992... Val Acc: 0.9531... F1-Score: 0.9535...\n",
      "Epoch: 489/600... Train Loss: 0.0412... Val Loss: 0.3088... Val Acc: 0.9542... F1-Score: 0.9546...\n",
      "Epoch: 490/600... Train Loss: 0.0403... Val Loss: 0.3110... Val Acc: 0.9548... F1-Score: 0.9553...\n",
      "Epoch: 491/600... Train Loss: 0.0409... Val Loss: 0.2914... Val Acc: 0.9550... F1-Score: 0.9556...\n",
      "Epoch: 492/600... Train Loss: 0.0397... Val Loss: 0.3142... Val Acc: 0.9518... F1-Score: 0.9522...\n",
      "Epoch: 493/600... Train Loss: 0.0392... Val Loss: 0.3135... Val Acc: 0.9548... F1-Score: 0.9553...\n",
      "Epoch: 494/600... Train Loss: 0.0442... Val Loss: 0.3222... Val Acc: 0.9520... F1-Score: 0.9527...\n",
      "Epoch: 495/600... Train Loss: 0.0423... Val Loss: 0.3300... Val Acc: 0.9505... F1-Score: 0.9511...\n",
      "Epoch: 496/600... Train Loss: 0.0413... Val Loss: 0.3051... Val Acc: 0.9546... F1-Score: 0.9550...\n",
      "Epoch: 497/600... Train Loss: 0.0390... Val Loss: 0.3049... Val Acc: 0.9548... F1-Score: 0.9553...\n",
      "Epoch: 498/600... Train Loss: 0.0393... Val Loss: 0.3081... Val Acc: 0.9559... F1-Score: 0.9563...\n",
      "Epoch: 499/600... Train Loss: 0.0385... Val Loss: 0.3172... Val Acc: 0.9548... F1-Score: 0.9552...\n",
      "Epoch: 500/600... Train Loss: 0.0399... Val Loss: 0.3099... Val Acc: 0.9554... F1-Score: 0.9559...\n",
      "Epoch: 501/600... Train Loss: 0.0453... Val Loss: 0.4296... Val Acc: 0.9187... F1-Score: 0.9186...\n",
      "Epoch: 502/600... Train Loss: 0.0488... Val Loss: 0.3014... Val Acc: 0.9550... F1-Score: 0.9556...\n",
      "Epoch: 503/600... Train Loss: 0.0398... Val Loss: 0.3466... Val Acc: 0.9522... F1-Score: 0.9526...\n",
      "Epoch: 504/600... Train Loss: 0.0429... Val Loss: 0.3231... Val Acc: 0.9542... F1-Score: 0.9548...\n",
      "Epoch: 505/600... Train Loss: 0.0400... Val Loss: 0.3110... Val Acc: 0.9546... F1-Score: 0.9550...\n",
      "Epoch: 506/600... Train Loss: 0.0394... Val Loss: 0.3285... Val Acc: 0.9539... F1-Score: 0.9544...\n",
      "Epoch: 507/600... Train Loss: 0.0431... Val Loss: 0.3172... Val Acc: 0.9496... F1-Score: 0.9501...\n",
      "Epoch: 508/600... Train Loss: 0.0404... Val Loss: 0.3167... Val Acc: 0.9524... F1-Score: 0.9528...\n",
      "Epoch: 509/600... Train Loss: 0.0380... Val Loss: 0.3245... Val Acc: 0.9529... F1-Score: 0.9534...\n",
      "Epoch: 510/600... Train Loss: 0.0404... Val Loss: 0.3250... Val Acc: 0.9511... F1-Score: 0.9517...\n",
      "Epoch: 511/600... Train Loss: 0.0460... Val Loss: 0.3023... Val Acc: 0.9494... F1-Score: 0.9499...\n",
      "Epoch: 512/600... Train Loss: 0.0396... Val Loss: 0.3152... Val Acc: 0.9537... F1-Score: 0.9541...\n",
      "Epoch: 513/600... Train Loss: 0.0407... Val Loss: 0.3017... Val Acc: 0.9548... F1-Score: 0.9552...\n",
      "Epoch: 514/600... Train Loss: 0.0402... Val Loss: 0.3253... Val Acc: 0.9524... F1-Score: 0.9530...\n",
      "Epoch: 515/600... Train Loss: 0.0417... Val Loss: 0.3177... Val Acc: 0.9548... F1-Score: 0.9553...\n",
      "Epoch: 516/600... Train Loss: 0.0396... Val Loss: 0.3239... Val Acc: 0.9537... F1-Score: 0.9542...\n",
      "Epoch: 517/600... Train Loss: 0.0412... Val Loss: 0.3382... Val Acc: 0.9522... F1-Score: 0.9524...\n",
      "Epoch: 518/600... Train Loss: 0.0432... Val Loss: 0.3379... Val Acc: 0.9500... F1-Score: 0.9505...\n",
      "Epoch: 519/600... Train Loss: 0.0400... Val Loss: 0.3277... Val Acc: 0.9526... F1-Score: 0.9530...\n",
      "Epoch: 520/600... Train Loss: 0.0388... Val Loss: 0.3111... Val Acc: 0.9546... F1-Score: 0.9551...\n",
      "Epoch: 521/600... Train Loss: 0.0382... Val Loss: 0.3259... Val Acc: 0.9548... F1-Score: 0.9554...\n",
      "Epoch: 522/600... Train Loss: 0.0387... Val Loss: 0.3142... Val Acc: 0.9544... F1-Score: 0.9550...\n",
      "Epoch: 523/600... Train Loss: 0.0478... Val Loss: 0.3279... Val Acc: 0.9481... F1-Score: 0.9488...\n",
      "Epoch: 524/600... Train Loss: 0.0485... Val Loss: 0.3196... Val Acc: 0.9500... F1-Score: 0.9504...\n",
      "Epoch: 525/600... Train Loss: 0.0489... Val Loss: 0.3000... Val Acc: 0.9544... F1-Score: 0.9550...\n",
      "Epoch: 526/600... Train Loss: 0.0412... Val Loss: 0.2912... Val Acc: 0.9537... F1-Score: 0.9543...\n",
      "Epoch: 527/600... Train Loss: 0.0411... Val Loss: 0.2968... Val Acc: 0.9541... F1-Score: 0.9545...\n",
      "Epoch: 528/600... Train Loss: 0.0427... Val Loss: 0.3076... Val Acc: 0.9501... F1-Score: 0.9506...\n",
      "Epoch: 529/600... Train Loss: 0.0491... Val Loss: 0.3176... Val Acc: 0.9535... F1-Score: 0.9539...\n",
      "Epoch: 530/600... Train Loss: 0.0408... Val Loss: 0.3205... Val Acc: 0.9550... F1-Score: 0.9554...\n",
      "Epoch: 531/600... Train Loss: 0.0404... Val Loss: 0.3090... Val Acc: 0.9554... F1-Score: 0.9558...\n",
      "Epoch: 532/600... Train Loss: 0.0388... Val Loss: 0.3148... Val Acc: 0.9548... F1-Score: 0.9552...\n",
      "Epoch: 533/600... Train Loss: 0.0477... Val Loss: 0.3097... Val Acc: 0.9515... F1-Score: 0.9519...\n",
      "Epoch: 534/600... Train Loss: 0.0409... Val Loss: 0.3267... Val Acc: 0.9505... F1-Score: 0.9510...\n",
      "Epoch: 535/600... Train Loss: 0.0414... Val Loss: 0.3087... Val Acc: 0.9533... F1-Score: 0.9537...\n",
      "Epoch: 536/600... Train Loss: 0.0402... Val Loss: 0.3126... Val Acc: 0.9544... F1-Score: 0.9550...\n",
      "Epoch: 537/600... Train Loss: 0.0411... Val Loss: 0.3193... Val Acc: 0.9498... F1-Score: 0.9505...\n",
      "Epoch: 538/600... Train Loss: 0.0396... Val Loss: 0.3042... Val Acc: 0.9548... F1-Score: 0.9552...\n",
      "Epoch: 539/600... Train Loss: 0.0421... Val Loss: 0.3133... Val Acc: 0.9537... F1-Score: 0.9541...\n",
      "Epoch: 540/600... Train Loss: 0.0394... Val Loss: 0.3013... Val Acc: 0.9535... F1-Score: 0.9540...\n",
      "Epoch: 541/600... Train Loss: 0.0403... Val Loss: 0.3051... Val Acc: 0.9537... F1-Score: 0.9543...\n",
      "Epoch: 542/600... Train Loss: 0.0402... Val Loss: 0.3200... Val Acc: 0.9554... F1-Score: 0.9559...\n",
      "Epoch: 543/600... Train Loss: 0.0399... Val Loss: 0.3219... Val Acc: 0.9537... F1-Score: 0.9542...\n",
      "Epoch: 544/600... Train Loss: 0.0385... Val Loss: 0.3151... Val Acc: 0.9529... F1-Score: 0.9534...\n",
      "Epoch: 545/600... Train Loss: 0.0485... Val Loss: 0.3021... Val Acc: 0.9516... F1-Score: 0.9524...\n",
      "Epoch: 546/600... Train Loss: 0.0405... Val Loss: 0.2918... Val Acc: 0.9548... F1-Score: 0.9553...\n",
      "Epoch: 547/600... Train Loss: 0.0393... Val Loss: 0.3017... Val Acc: 0.9542... F1-Score: 0.9548...\n",
      "Epoch: 548/600... Train Loss: 0.0381... Val Loss: 0.3063... Val Acc: 0.9552... F1-Score: 0.9556...\n",
      "Epoch: 549/600... Train Loss: 0.0430... Val Loss: 0.2950... Val Acc: 0.9531... F1-Score: 0.9535...\n",
      "Epoch: 550/600... Train Loss: 0.0414... Val Loss: 0.3095... Val Acc: 0.9550... F1-Score: 0.9553...\n",
      "Epoch: 551/600... Train Loss: 0.0398... Val Loss: 0.3253... Val Acc: 0.9563... F1-Score: 0.9568...\n",
      "Epoch: 552/600... Train Loss: 0.0383... Val Loss: 0.3154... Val Acc: 0.9550... F1-Score: 0.9555...\n",
      "Epoch: 553/600... Train Loss: 0.0384... Val Loss: 0.3099... Val Acc: 0.9531... F1-Score: 0.9538...\n",
      "Epoch: 554/600... Train Loss: 0.0383... Val Loss: 0.3123... Val Acc: 0.9548... F1-Score: 0.9553...\n",
      "Epoch: 555/600... Train Loss: 0.0386... Val Loss: 0.3023... Val Acc: 0.9554... F1-Score: 0.9559...\n",
      "Epoch: 556/600... Train Loss: 0.0396... Val Loss: 0.3044... Val Acc: 0.9548... F1-Score: 0.9554...\n",
      "Epoch: 557/600... Train Loss: 0.0384... Val Loss: 0.3286... Val Acc: 0.9559... F1-Score: 0.9563...\n",
      "Epoch: 558/600... Train Loss: 0.0492... Val Loss: 0.3147... Val Acc: 0.9546... F1-Score: 0.9551...\n",
      "Epoch: 559/600... Train Loss: 0.0403... Val Loss: 0.3112... Val Acc: 0.9554... F1-Score: 0.9559...\n",
      "Epoch: 560/600... Train Loss: 0.0460... Val Loss: 0.2977... Val Acc: 0.9542... F1-Score: 0.9546...\n",
      "Epoch: 561/600... Train Loss: 0.0455... Val Loss: 0.3042... Val Acc: 0.9528... F1-Score: 0.9532...\n",
      "Epoch: 562/600... Train Loss: 0.0464... Val Loss: 0.3183... Val Acc: 0.9505... F1-Score: 0.9509...\n",
      "Epoch: 563/600... Train Loss: 0.0423... Val Loss: 0.3043... Val Acc: 0.9520... F1-Score: 0.9523...\n",
      "Epoch: 564/600... Train Loss: 0.0418... Val Loss: 0.3161... Val Acc: 0.9520... F1-Score: 0.9525...\n",
      "Epoch: 565/600... Train Loss: 0.0400... Val Loss: 0.3054... Val Acc: 0.9528... F1-Score: 0.9532...\n",
      "Epoch: 566/600... Train Loss: 0.0389... Val Loss: 0.3027... Val Acc: 0.9526... F1-Score: 0.9531...\n",
      "Epoch: 567/600... Train Loss: 0.0396... Val Loss: 0.3249... Val Acc: 0.9537... F1-Score: 0.9542...\n",
      "Epoch: 568/600... Train Loss: 0.0393... Val Loss: 0.3046... Val Acc: 0.9542... F1-Score: 0.9549...\n",
      "Epoch: 569/600... Train Loss: 0.0380... Val Loss: 0.3047... Val Acc: 0.9559... F1-Score: 0.9564...\n",
      "Epoch: 570/600... Train Loss: 0.0460... Val Loss: 0.3083... Val Acc: 0.9509... F1-Score: 0.9515...\n",
      "Epoch: 571/600... Train Loss: 0.0418... Val Loss: 0.3109... Val Acc: 0.9520... F1-Score: 0.9524...\n",
      "Epoch: 572/600... Train Loss: 0.0395... Val Loss: 0.2979... Val Acc: 0.9570... F1-Score: 0.9574...\n",
      "Epoch: 573/600... Train Loss: 0.0392... Val Loss: 0.2972... Val Acc: 0.9541... F1-Score: 0.9546...\n",
      "Epoch: 574/600... Train Loss: 0.0401... Val Loss: 0.2878... Val Acc: 0.9528... F1-Score: 0.9533...\n",
      "Epoch: 575/600... Train Loss: 0.0388... Val Loss: 0.2870... Val Acc: 0.9554... F1-Score: 0.9558...\n",
      "Epoch: 576/600... Train Loss: 0.0387... Val Loss: 0.2958... Val Acc: 0.9557... F1-Score: 0.9562...\n",
      "Epoch: 577/600... Train Loss: 0.0393... Val Loss: 0.3045... Val Acc: 0.9542... F1-Score: 0.9548...\n",
      "Epoch: 578/600... Train Loss: 0.0392... Val Loss: 0.3085... Val Acc: 0.9546... F1-Score: 0.9551...\n",
      "Epoch: 579/600... Train Loss: 0.0389... Val Loss: 0.3048... Val Acc: 0.9544... F1-Score: 0.9549...\n",
      "Epoch: 580/600... Train Loss: 0.0390... Val Loss: 0.2993... Val Acc: 0.9537... F1-Score: 0.9543...\n",
      "Epoch: 581/600... Train Loss: 0.0407... Val Loss: 0.3007... Val Acc: 0.9539... F1-Score: 0.9543...\n",
      "Epoch: 582/600... Train Loss: 0.0499... Val Loss: 0.3115... Val Acc: 0.9528... F1-Score: 0.9532...\n",
      "Epoch: 583/600... Train Loss: 0.0399... Val Loss: 0.3067... Val Acc: 0.9539... F1-Score: 0.9543...\n",
      "Epoch: 584/600... Train Loss: 0.0412... Val Loss: 0.2962... Val Acc: 0.9561... F1-Score: 0.9567...\n",
      "Epoch: 585/600... Train Loss: 0.0385... Val Loss: 0.2969... Val Acc: 0.9552... F1-Score: 0.9557...\n",
      "Epoch: 586/600... Train Loss: 0.0394... Val Loss: 0.2992... Val Acc: 0.9559... F1-Score: 0.9564...\n",
      "Epoch: 587/600... Train Loss: 0.0391... Val Loss: 0.3276... Val Acc: 0.9537... F1-Score: 0.9541...\n",
      "Epoch: 588/600... Train Loss: 0.0397... Val Loss: 0.3299... Val Acc: 0.9518... F1-Score: 0.9524...\n",
      "Epoch: 589/600... Train Loss: 0.0385... Val Loss: 0.3284... Val Acc: 0.9555... F1-Score: 0.9559...\n",
      "Epoch: 590/600... Train Loss: 0.0381... Val Loss: 0.3348... Val Acc: 0.9533... F1-Score: 0.9540...\n",
      "Epoch: 591/600... Train Loss: 0.0446... Val Loss: 0.3140... Val Acc: 0.9537... F1-Score: 0.9540...\n",
      "Epoch: 592/600... Train Loss: 0.0393... Val Loss: 0.3157... Val Acc: 0.9539... F1-Score: 0.9544...\n",
      "Epoch: 593/600... Train Loss: 0.0383... Val Loss: 0.3093... Val Acc: 0.9559... F1-Score: 0.9564...\n",
      "Epoch: 594/600... Train Loss: 0.0399... Val Loss: 0.3127... Val Acc: 0.9541... F1-Score: 0.9547...\n",
      "Epoch: 595/600... Train Loss: 0.0379... Val Loss: 0.3192... Val Acc: 0.9541... F1-Score: 0.9546...\n",
      "Epoch: 596/600... Train Loss: 0.0437... Val Loss: 0.3048... Val Acc: 0.9535... F1-Score: 0.9540...\n",
      "Epoch: 597/600... Train Loss: 0.0398... Val Loss: 0.3198... Val Acc: 0.9537... F1-Score: 0.9541...\n",
      "Epoch: 598/600... Train Loss: 0.0381... Val Loss: 0.3159... Val Acc: 0.9533... F1-Score: 0.9538...\n",
      "Epoch: 599/600... Train Loss: 0.0421... Val Loss: 0.3122... Val Acc: 0.9524... F1-Score: 0.9529...\n",
      "Epoch: 600/600... Train Loss: 0.0405... Val Loss: 0.3112... Val Acc: 0.9518... F1-Score: 0.9522...\n"
     ]
    }
   ],
   "source": [
    "def train(net, epochs=600, batch_size=64, lr=0.001):\n",
    "    # opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    opt = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "    # opt = torch.optim.RMSprop(net.parameters(), lr=lr, momentum=0.1)\n",
    "    # opt = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "        batch_size=batch_size, shuffle=True, drop_last = True)  \n",
    "\n",
    "    test_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "        batch_size=batch_size, shuffle=False, drop_last = True) \n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "     \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # initialize hidden state\n",
    "        # h = net.init_hidden(batch_size)         \n",
    "        train_losses = []    \n",
    "        net.train()\n",
    "        # for batch in iterate_minibatches(X_train, y_train, batch_size):\n",
    "        for batch in train_loader:\n",
    "            x, y = batch\n",
    "\n",
    "            # inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            inputs, targets = x.to(device), y.to(device)  \n",
    "\n",
    "            # if(train_on_gpu):\n",
    "            #         inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            # h = tuple([each.data for each in h])\n",
    "            \n",
    "            # h = h[0].reshape((batch_size, -1)) # for GRU\n",
    "            \n",
    "            # zero accumulated gradients\n",
    "            opt.zero_grad()   \n",
    "            \n",
    "            # get the output from the model\n",
    "            output = net(inputs)\n",
    "            # loss = criterion(output, torch.from_numpy(to_categorical(y, num_classes=NUM_CLASSES)).to(device))\n",
    "            loss = criterion(output, torch.argmax(targets,dim=1))\n",
    "            # print(output.shape)\n",
    "            # print(targets.shape)\n",
    "            # loss = criterion(output, targets)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "        # val_h = net.init_hidden(batch_size)\n",
    "        val_losses = []\n",
    "        accuracy=0\n",
    "        f1score=0\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_true = []\n",
    "        total_pred = []\n",
    "        \n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                x, y = batch\n",
    "                inputs, targets = x.to(device), y.to(device)  \n",
    " \n",
    "                # print(images.shape)            \n",
    "            # for batch in iterate_minibatches(X_test, y_test, batch_size):\n",
    "            #     x, y = batch     \n",
    "\n",
    "                # inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "                # val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                    \n",
    "                output = net(inputs)\n",
    "\n",
    "                # val_loss = criterion(output, torch.from_numpy(to_categorical(y, num_classes=NUM_CLASSES)).to(device))\n",
    "                val_loss = criterion(output, torch.argmax(targets,dim=1))\n",
    "                # val_loss = criterion(output, targets)\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "                predicted = torch.argmax(output.data, dim=1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == torch.argmax(targets, dim=1)).sum().item()\n",
    "\n",
    "                total_pred = total_pred + predicted.cpu().numpy().tolist()\n",
    "                total_true = total_true + (torch.argmax(targets, dim=1).cpu().numpy().tolist())\n",
    "\n",
    "\n",
    "#                 top_p, top_class = output.topk(1, dim=1)\n",
    "                \n",
    "#                 # equals = top_class == torch.argmax(targets, dim=1)\n",
    "#                 equals = top_class == targets.view(*top_class.shape).long()\n",
    "#                 accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "#                 # f1score += metrics.f1_score(top_class.cpu(), torch.argmax(targets, dim=1).cpu(), average='micro')\n",
    "#                 f1score += metrics.f1_score(top_class.cpu(), targets.view(*top_class.shape).long().cpu(), average='micro')\n",
    "        net.train() # reset to train mode after iterationg through validation data\n",
    "    \n",
    "        # print(f'Test Accuracy: {100.0 * correct / total} %')\n",
    "        # print(\" | \".join(act_labels_txt))\n",
    "        # conf_mat = confusion_matrix(y_true = total_true, y_pred = total_pred)\n",
    "        # conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "        # print(np.array(conf_mat).round(3) * 100)  \n",
    "        f1_score = metrics.f1_score(y_true = total_true, y_pred = total_pred, average='weighted')\n",
    "        # print('F1 score:', f1_score)\n",
    "        # print('')      \n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "        \"Train Loss: {:.4f}...\".format(np.mean(train_losses)),\n",
    "        \"Val Loss: {:.4f}...\".format(np.mean(val_losses)),\n",
    "        \"Val Acc: {:.4f}...\".format(correct / total),\n",
    "        \"F1-Score: {:.4f}...\".format(f1_score))\n",
    "        \n",
    "        # PATH = 'opportunity_ConvAttn_ep'+str(e)+'.pt'\n",
    "        # torch.save(net.state_dict(), PATH)\n",
    "        \n",
    "## check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')\n",
    "\n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eeccfaf-7e5f-49e4-881a-2bb2e68002eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = 'HHAR_Time_ConvAttn_2.pt'\n",
    "# torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e461cc9b-e4fc-457e-93e6-4b8c426337ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b682f-33db-45d8-a57c-15d4dc0ed939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50aa021-ec97-415d-9d8e-6eb2d8a581a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5296bdc-d492-4460-ac38-ab6cea4e8229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d3b8c-c10f-4928-8a6b-405f8c46bae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2544ca9-94ee-4662-b674-0ef24b39b29f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
