{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from preprocessing import Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUR_DIR = os.path.dirname(os.path.abspath('__file__'))  # Path to current directory\n",
    "DATA_DIR = os.path.join(CUR_DIR, \"../../data/\")  # Path to dataset directory\n",
    "TRAIN_SUBJECTS = [1, 3, 5, 6, 7, 8, 11, 14, 15, 16, 17, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30]\n",
    "TEST_SUBJECTS = [2, 4, 9, 10, 12, 13, 18, 20, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_signal(signal: pd.DataFrame) -> pd.DataFrame:\n",
    "    _signal = signal.copy()\n",
    "    of = Preprocess()\n",
    "    _signal = of.apply_filter(_signal, filter=\"median\")\n",
    "    _signal = of.apply_filter(_signal, filter=\"butterworth\")\n",
    "    _signal = of.segment_signal(_signal)\n",
    "    return _signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(\n",
    "    signal: pd.DataFrame, scaler=\"normalize\", minmax_range: Optional[Tuple[int, int]] = (0, 1)\n",
    ") -> pd.DataFrame:\n",
    "    if scaler == \"normalize\":\n",
    "        signal = StandardScaler().fit_transform(signal)\n",
    "        return pd.DataFrame(signal, columns=[\"x\", \"y\", \"z\"])\n",
    "    elif scaler == \"minmax\":\n",
    "        signal = MinMaxScaler(feature_range=minmax_range).fit_transform(signal)\n",
    "        return pd.DataFrame(signal, columns=[\"x\", \"y\", \"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_raw_data(scaler):\n",
    "    acc_files = sorted(glob.glob(os.path.join(DATA_DIR, \"hapt_data_set/RawData/acc*.txt\")))\n",
    "    gyro_files = sorted(glob.glob(os.path.join(DATA_DIR, \"hapt_data_set/RawData/gyro*.txt\")))\n",
    "    label_info = pd.read_table(\n",
    "        os.path.join(DATA_DIR, \"hapt_data_set/RawData/labels.txt\"),\n",
    "        sep=\" \",\n",
    "        header=None,\n",
    "        names=[\"ExpID\", \"UserID\", \"ActID\", \"ActStart\", \"ActEnd\"],\n",
    "    )\n",
    "\n",
    "    X_train = np.array([])\n",
    "    X_test = np.array([])\n",
    "\n",
    "    for acc_file, gyro_file in zip(acc_files, gyro_files):\n",
    "        exp_id = int(acc_file.split(\"exp\")[1][:2])\n",
    "        user_id = int(acc_file.split(\"user\")[1][:2])\n",
    "\n",
    "        temp_label_info = label_info[\n",
    "            (label_info.ExpID == exp_id)\n",
    "            & (label_info.UserID == user_id)\n",
    "            & (label_info.ActID.isin([1, 2, 3, 4, 5, 6]))\n",
    "        ]\n",
    "\n",
    "        acc_raw = pd.read_table(acc_file, sep=\" \", header=None, names=[\"x\", \"y\", \"z\"])\n",
    "        gyro_raw = pd.read_table(gyro_file, sep=\" \", header=None, names=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "        acc_raw = scale(acc_raw, scaler=scaler)\n",
    "        gyro_raw = scale(gyro_raw, scaler=scaler)\n",
    "\n",
    "        for _, _, act_id, act_start, act_end in temp_label_info.values:\n",
    "            temp_acc_raw = acc_raw.iloc[act_start : act_end + 1]\n",
    "            temp_gyro_raw = gyro_raw.iloc[act_start : act_end + 1]\n",
    "            tAccXYZ = preprocess_signal(temp_acc_raw)\n",
    "            tBodyGyroXYZ = preprocess_signal(temp_gyro_raw)\n",
    "            features = np.zeros((len(tAccXYZ), 128, 6))\n",
    "\n",
    "            for i in range(len(tAccXYZ)):\n",
    "                feature = pd.DataFrame(\n",
    "                    np.concatenate((tAccXYZ[i], tBodyGyroXYZ[i]), 1),\n",
    "                    columns=[\"AccX\", \"AccY\", \"AccZ\", \"GyroX\", \"GyroY\", \"GyroZ\"],\n",
    "                )\n",
    "                features[i] = feature\n",
    "\n",
    "            if user_id in TRAIN_SUBJECTS:\n",
    "                if len(X_train) == 0:\n",
    "                    X_train = features\n",
    "                else:\n",
    "                    X_train = np.vstack((X_train, features))\n",
    "            else:\n",
    "                if len(X_test) == 0:\n",
    "                    X_test = features\n",
    "                else:\n",
    "                    X_test = np.vstack((X_test, features))\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 6, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 6, 1)\n",
    "\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
