{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb8d2ed-260b-40da-8e00-4f336ad95266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from model import *\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deb8e0b2-4bb9-4d7b-8903-3ec79224fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.config = 'default'\n",
    "        self.dataset = 'pamap2'\n",
    "        self.model = 'UniTS'\n",
    "        self.log = 'log'\n",
    "        self.exp = ''\n",
    "        self.seed = 0\n",
    "        self.ratio = 0.2\n",
    "        self.n_gpu = 2\n",
    "        self.epochs = 25\n",
    "        self.lr = 1e-3\n",
    "        # self.sigma = 0.35\n",
    "        self.batch_size = 64\n",
    "        self.save = True #'BCE'\n",
    "        self.test_only = False\n",
    "        self.input_size = 171 # 24 #256    \n",
    "        self.input_channel = 27 # 113 #45\n",
    "        self.hheads = 9\n",
    "        self.SENSOR_AXIS = 3\n",
    "        \n",
    "        # self.momentum = 0.1\n",
    "        # self.c = 0.01\n",
    "        # self.svmLR = 1e-4\n",
    "        # self.Ntest = 100\n",
    "        # self.gpuNo = 2\n",
    "        # self.cuda_id = 2\n",
    "        # self.multimodalZ = False\n",
    "        # self.window_len = 512\n",
    "        # self.stride_len = 20\n",
    "        # self.act_list = [1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24]\n",
    "        # self.imSize = 64\n",
    "        # self.sigma = [60, 80]\n",
    "        # # self.sigma = 0.3\n",
    "        # self.random_seed = 0\n",
    "        # self.train_split = 0.8\n",
    "        \n",
    "args = Args()\n",
    "args.num_labels=12\n",
    "\n",
    "args.log_path = os.path.join(args.log, args.dataset)\n",
    "if not os.path.exists(args.log_path):\n",
    "    os.mkdir(args.log_path)\n",
    "torch.cuda.set_device(args.n_gpu)\n",
    "args.model_save_path = os.path.join(args.log_path, args.model + '_'+ args.config + '.pt')\n",
    "config = read_config(args.config + '.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805010fb-b372-42c8-8aa4-4dedcf6ba7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba25b3a3-c0b5-4e61-903d-8bb57828010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_num:\t1\n",
      "\n",
      "window_list:\t[7, 16, 32, 48, 64, 80, 96, 112, 128]\n",
      "\n",
      "stride_list:\t[3, 8, 16, 24, 32, 40, 48, 56, 64]\n",
      "\n",
      "k_list:\t[3, 8, 16, 24, 24, 32, 32, 40, 40]\n",
      "\n",
      "hidden_channel:\t48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Commented our parse_args to use in jupyter notebook\n",
    "'''\n",
    "# def parse_args():\n",
    "#     parser = argparse.ArgumentParser(description='train and test')\n",
    "#     parser.add_argument('--config', default = 'default', type =str) # Read UniTS hyperparameters\n",
    "#     parser.add_argument('--dataset', default = 'opportunity_lc', type = str,\n",
    "#                         choices=['opportunity_lc', 'seizure', 'wifi', 'keti'])\n",
    "#     parser.add_argument('--model', default='UniTS', type=str,\n",
    "#                         choices=['UniTS', 'THAT', 'RFNet', 'ResNet', 'MaDNN', 'MaCNN', 'LaxCat', 'static'])\n",
    "#     parser.add_argument('--seed', default=0, type=int)\n",
    "#     parser.add_argument('--log', default='log', type=str,\n",
    "#                         help=\"Log directory\")\n",
    "#     parser.add_argument('--exp', default='', type=str,\n",
    "#                         choices = ['','noise','missing_data'])\n",
    "#     parser.add_argument('--ratio', default=0.2, type=float)\n",
    "#     parser.add_argument('--n_gpu', default=0, type =int)\n",
    "    \n",
    "#     parser.add_argument('--epochs', default = 50, type = int)\n",
    "#     parser.add_argument('--lr', default = 1e-3, type = float)\n",
    "#     parser.add_argument('--batch_size', default = 64, type = int)\n",
    "\n",
    "#     parser.add_argument('--save', action = 'store_true')\n",
    "#     parser.add_argument('--test_only', action = 'store_true')\n",
    "#     args = parser.parse_args()\n",
    "#     config = read_config(args.config + '.yaml')\n",
    "#     if not os.path.exists(args.log):\n",
    "#         os.mkdir(args.log)\n",
    "#     args.log_path = os.path.join(args.log, args.dataset)\n",
    "#     if not os.path.exists(args.log_path):\n",
    "#         os.mkdir(args.log_path)\n",
    "#     torch.cuda.set_device(args.n_gpu)\n",
    "\n",
    "#     if args.dataset == 'opportunity_lc':\n",
    "#         args.input_size = 256\n",
    "#         args.input_channel = 45\n",
    "#         args.hheads = 9\n",
    "#         args.SENSOR_AXIS = 3\n",
    "#     elif args.dataset == 'seizure':\n",
    "#         args.input_channel = 18\n",
    "#         args.input_size = 256\n",
    "#         args.hheads = 6\n",
    "#         args.SENSOR_AXIS = 1\n",
    "#     elif args.dataset == 'wifi':\n",
    "#         args.input_channel = 180\n",
    "#         args.input_size = 256\n",
    "#         args.batch_size = 16\n",
    "#         args.hheads = 9\n",
    "#         args.SENSOR_AXIS = 3\n",
    "#     elif args.dataset == 'keti':\n",
    "#         args.input_channel = 4\n",
    "#         args.input_size = 256\n",
    "#         args.hheads = 4\n",
    "#         args.SENSOR_AXIS = 1\n",
    "#     args.model_save_path = os.path.join(args.log_path, args.model + '_'+ args.config + '.pt')\n",
    "#     return args, config\n",
    "\n",
    "# args, config = parse_args()\n",
    "log = set_up_logging(args, config)\n",
    "args.log = log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b49a47-2842-4fb6-ad59-f774c6ac777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sliding_window import sliding_window\n",
    "import pickle as cp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1bdc7907-248c-4905-b2f7-932e16431b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_PAMAP2(root_path='../../../PAMAP2_Dataset/Protocol/subject10'):\n",
    "    X=[]\n",
    "    user_labels=[]\n",
    "    act_labels=[]\n",
    "\n",
    "    window_len = 512\n",
    "    stride_len = 20\n",
    "    # columns for IMU data\n",
    "    imu_locs = [4,5,6, 10,11,12, 13,14,15, \n",
    "                21,22,23, 27,28,29, 30,31,32, \n",
    "                38,39,40, 44,45,46, 47,48,49\n",
    "            ] \n",
    "    \n",
    "    act_list = [1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    # scaler = StandardScaler()\n",
    "\n",
    "    for uid in np.arange(1,10):\n",
    "        path = root_path + str(uid) + '.dat'\n",
    "        df = pd.read_table(path, sep=' ', header=None)\n",
    "        act_imu_filter = df.iloc[:, imu_locs] \n",
    "\n",
    "        for act_id in range(len(act_list)):\n",
    "            act_filter =  act_imu_filter[df.iloc[:, 1] == act_list[act_id]]\n",
    "            act_data = act_filter.to_numpy()\n",
    "                \n",
    "            act_data = np.transpose(act_data)\n",
    "            # sliding window segmentation\n",
    "            start_idx = 0\n",
    "            while start_idx + window_len < act_data.shape[1]:\n",
    "                window_data = act_data[:, start_idx:start_idx + window_len]\n",
    "                downsamp_data = window_data[:, ::3] # downsample from 100hz to 33.3hz\n",
    "                downsamp_data = np.nan_to_num(downsamp_data) # remove nan\n",
    "\n",
    "                X.append(downsamp_data)\n",
    "                user_labels.append(uid)\n",
    "                act_labels.append(act_id)\n",
    "                start_idx = start_idx + stride_len\n",
    "\n",
    "    X_n = np.array(X).astype('float32')\n",
    "\n",
    "    normalized_X = np.zeros_like(X_n) # allocate numpy array for normalized data\n",
    "    for ch_id in range(X_n.shape[1]): # loop the 27 sensor channels\n",
    "        ch_data = X_n[:, ch_id, :] # the data of channel id\n",
    "        scaler = MinMaxScaler() # maybe different scalers?\n",
    "        ch_data = scaler.fit_transform(ch_data) # scale the data in this channel to [0,1]\n",
    "        normalized_X[:, ch_id, :] = ch_data # assign normalized data to normalized_X\n",
    "    normalized_X = np.transpose(normalized_X, (0, 2, 1)) # overwrote X here, changed dimensions into: num_samples, sequence_length, feature_length\n",
    "        \n",
    "    # convert list to numpy array\n",
    "    # normalized_X= normalized_X.reshape(normalized_X.shape[0], 1, normalized_X.shape[1], normalized_X.shape[2]) \n",
    "    act_labels = np.array(act_labels).astype('float32')\n",
    "    # act_labels = act_labels.reshape(act_labels.shape[0],1)\n",
    "    # act_labels = to_categorical(act_labels, num_classes=len(act_list))\n",
    "\n",
    "    return normalized_X, act_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a16e55b-f1a4-4e27-98df-1bc245f19a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X, act_labels = prepare_data_PAMAP2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a200e8d3-bec0-4039-a6be-332358e6c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(normalized_X, act_labels, test_size=args.ratio, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1258c186-fd3b-4a38-9f8b-eaa7762f5f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.  5. 10. ...  6.  0.  3.]\n"
     ]
    }
   ],
   "source": [
    "# print(X_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5954663b-b379-4faf-99be-e0f70b57986d",
   "metadata": {},
   "source": [
    "## Our pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08a1abce-131c-4350-9b48-223c162bc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sliding_window import sliding_window\n",
    "# import pickle as cp\n",
    "# from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c399ec4-5672-4dc2-9a54-453c139afbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Number of Sensor Channels used in the OPPORTUNITY dataset.\n",
    "# NB_SENSOR_CHANNELS = 113\n",
    "\n",
    "# # Number of classes in which data is classified (or to be classified).\n",
    "# NUM_CLASSES = 5\n",
    "\n",
    "# # Length of the sliding window used to segmenting the time-series-data.\n",
    "# SLIDING_WINDOW_LENGTH = 24\n",
    "\n",
    "# # Steps of the sliding window used in segmenting the data.\n",
    "# SLIDING_WINDOW_STEP = 12\n",
    "\n",
    "# act_labels_txt = ['std', 'wlk', 'sit', 'lie', 'null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "222ca6f3-7e63-40b1-a6e9-7083044fc899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_dataset(filename):\n",
    "\n",
    "#     f = open(filename, 'rb')\n",
    "#     data = cp.load(f)\n",
    "#     f.close()\n",
    "\n",
    "#     X_train, y_train = data[0]\n",
    "#     X_test, y_test = data[1]\n",
    "\n",
    "#     print(\" ..from file {}\".format(filename))\n",
    "#     print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "#     X_train = X_train.astype(np.float32)\n",
    "#     X_test = X_test.astype(np.float32)\n",
    "\n",
    "#     # The targets are casted to int8 for GPU compatibility.\n",
    "#     y_train = y_train.astype(np.uint8)\n",
    "#     y_test = y_test.astype(np.uint8)\n",
    "\n",
    "#     return X_train, y_train, X_test, y_test\n",
    "\n",
    "# print(\"Loading Data...\")\n",
    "# X_train, y_train, X_test, y_test = load_dataset('../../../data/oppChallenge_gestures.data')\n",
    "\n",
    "# assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
    "# def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "#     data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
    "#     data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
    "#     return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
    "\n",
    "# # Sensor data is segmented using a sliding window mechanism\n",
    "# X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "# print(\" ..after sliding window (testing): inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "# # Data is reshaped since the input of the network is a 4 dimension tensor\n",
    "# X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS))\n",
    "# # X_test = np.transpose(X_test, (0, 2, 1))\n",
    "# # X_test= X_test.reshape(X_test.shape[0], 1, X_test.shape[1], X_test.shape[2]) # convert list to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27a38b35-a013-4b70-a003-7b5b3343ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "# print(\" ..after sliding window (training): inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
    "# X_train = X_train.reshape((-1,SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS))\n",
    "# # X_train = np.transpose(X_train, (0, 2, 1))\n",
    "# # X_train= X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2]) # convert list to numpy array\n",
    "\n",
    "# X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04121ee0-f98c-4659-9865-3245aed065c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "# y_test = to_categorical(y_test, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "38bc08ab-59e3-49ad-a620-fac421d3784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(X_train)\n",
    "X_test = list(X_test)\n",
    "xtrain, ytrain, xtest, ytest = X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "13986f31-12d5-4017-a111-cdd4157e0869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train for OPPO (46495, 24, 113)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac8bc813-0034-474b-b0f2-27d284f2c7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 16, 32, 48, 64, 80]\n",
      "[3, 8, 16, 24, 32, 40]\n",
      "[3, 8, 16, 24, 24, 32]\n",
      "1\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print(config.window_list)\n",
    "print(config.stride_list)\n",
    "print(config.k_list)\n",
    "print(config.layer_num)\n",
    "print(config.hidden_channel)\n",
    "# Adjust model parameters based on our preprocessing\n",
    "config.window_list = [7,16,32, 48, 64, 80]\n",
    "config.stride_list = [3, 8, 16, 24, 32, 40]\n",
    "config.k_list = [3, 8, 16, 24, 24, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fd02e-9eea-4076-ba64-069d2312513d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b58b696-1cfe-48d4-a3ca-077683206d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 1992630\n"
     ]
    }
   ],
   "source": [
    "if args.model == 'UniTS':\n",
    "    model = UniTS(input_size = args.input_size, sensor_num = args.input_channel, layer_num = config.layer_num,\n",
    "    window_list = config.window_list, stride_list = config.stride_list, k_list = config.k_list,\n",
    "    out_dim = args.num_labels, hidden_channel = config.hidden_channel).cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "# elif args.model == 'static':\n",
    "#     model = static_UniTS(input_size = args.input_size, sensor_num = args.input_channel, layer_num = config.layer_num,\n",
    "#     window_list = config.window_list, stride_list = config.stride_list, k_list = config.k_list,\n",
    "#     out_dim = args.num_labels, hidden_channel = config.hidden_channel).cuda()\n",
    "\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "# elif args.model == 'THAT':\n",
    "#     args.hlayers = 5\n",
    "#     args.vlayers = 1\n",
    "#     args.vheads = 16\n",
    "#     args.K = 10\n",
    "#     args.sample = 4\n",
    "#     model = HARTrans(args).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# elif args.model == 'RFNet':\n",
    "#     model = RFNet(num_classes = args.num_labels, input_channel = args.input_channel, win_len = args.input_size).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "# elif args.model == 'ResNet':\n",
    "#     model = ResNet(input_size = args.input_size, input_channel = args.input_channel, num_label = args.num_labels).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)        \n",
    "\n",
    "# elif args.model == 'MaDNN':\n",
    "#     model = MaDNN(input_size = args.input_size, input_channel = args.input_channel, num_label = args.num_labels).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)   \n",
    "\n",
    "# elif args.model == 'MaCNN':\n",
    "#     model = MaCNN(input_size = args.input_size, input_channel = args.input_channel, num_label = args.num_labels, \n",
    "#         sensor_num = int(args.input_channel / args.SENSOR_AXIS)).cuda()\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "# elif args.model == 'LaxCat':\n",
    "#     model = LaxCat(input_size = args.input_size, input_channel = args.input_channel, num_label = args.num_labels,\n",
    "#         hidden_dim = 64, kernel_size = 32, stride = 8).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "log('Total parameters: ' + str(total_params))\n",
    "\n",
    "if args.test_only:\n",
    "    if os.path.exists(args.model_save_path):\n",
    "        model.load_state_dict(torch.load(args.model_save_path))\n",
    "        test(model, xtest, ytest)\n",
    "    else:\n",
    "        log(\"Model state dict not found!\")\n",
    "    # return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "45ad2c60-ecbe-4fc1-af93-922bebd8de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "random.shuffle(xtrain)\n",
    "random.seed(args.seed)\n",
    "random.shuffle(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee211e-5b53-4ffe-8cb9-5e028023ae96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "398743d4-afe5-4957-a2d2-339a9e706202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, xtest, ytest):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i in range(0, len(xtest), args.batch_size):\n",
    "            if i + args.batch_size <= len(xtest):\n",
    "                x = torch.Tensor(xtest[i: i+args.batch_size]).cuda()\n",
    "                # print(type(ytest[i: i+args.batch_size]))\n",
    "                y_true += list(ytest[i: i+args.batch_size])\n",
    "            else:\n",
    "                x = torch.Tensor(xtest[i:]).cuda()\n",
    "                y_true += list(ytest[i:])\n",
    "            out = model(x)\n",
    "            pred = torch.argmax(out, dim = -1)\n",
    "            y_pred += pred.cpu().tolist()\n",
    "\n",
    "    log(\"Accuracy : \" + str(accuracy_score(y_true, y_pred)) +\n",
    "        \"\\nWeighted F1 : \" + str(f1_score(y_true, y_pred, labels=list(range(args.num_labels)),average='weighted')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e9ea90dd-d38c-414d-aa80-17c0337aa9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch : 1\n",
      "Training loss : 0.22837813920400277\n",
      "Accuracy : 0.9538437220085357\n",
      "Weighted F1 : 0.9539509332476872\n",
      "----------------------------\n",
      "Training epoch : 2\n",
      "Training loss : 0.08400580414977685\n",
      "Accuracy : 0.9726539859845091\n",
      "Weighted F1 : 0.9727869522095438\n",
      "----------------------------\n",
      "Training epoch : 3\n",
      "Training loss : 0.05026092524370065\n",
      "Accuracy : 0.9821908425101428\n",
      "Weighted F1 : 0.9823181681773392\n",
      "----------------------------\n",
      "Training epoch : 4\n",
      "Training loss : 0.03573713502294495\n",
      "Accuracy : 0.9416723747299647\n",
      "Weighted F1 : 0.939246228365403\n",
      "----------------------------\n",
      "Training epoch : 5\n",
      "Training loss : 0.029756427915852063\n",
      "Accuracy : 0.9902523842141314\n",
      "Weighted F1 : 0.9902329987549917\n",
      "----------------------------\n",
      "Training epoch : 6\n",
      "Training loss : 0.022905549714251162\n",
      "Accuracy : 0.9936772221929501\n",
      "Weighted F1 : 0.9936902487255769\n",
      "----------------------------\n",
      "Training epoch : 7\n",
      "Training loss : 0.01972888499169012\n",
      "Accuracy : 0.9938879814531851\n",
      "Weighted F1 : 0.9938856541358142\n",
      "----------------------------\n",
      "Training epoch : 8\n",
      "Training loss : 0.016937623350138268\n",
      "Accuracy : 0.995152537014595\n",
      "Weighted F1 : 0.9951547673112872\n",
      "----------------------------\n",
      "Training epoch : 9\n",
      "Training loss : 0.014698386300731708\n",
      "Accuracy : 0.9897254860635439\n",
      "Weighted F1 : 0.9897082439347569\n",
      "----------------------------\n",
      "Training epoch : 10\n",
      "Training loss : 0.01525802839151561\n",
      "Accuracy : 0.9982085462880025\n",
      "Weighted F1 : 0.9982087351676509\n",
      "----------------------------\n",
      "Training epoch : 11\n",
      "Training loss : 0.01137378360278023\n",
      "Accuracy : 0.9977870277675326\n",
      "Weighted F1 : 0.9977862916455564\n",
      "----------------------------\n",
      "Training epoch : 12\n",
      "Training loss : 0.01262851574371704\n",
      "Accuracy : 0.9980504768428263\n",
      "Weighted F1 : 0.998051719843416\n",
      "----------------------------\n",
      "Training epoch : 13\n",
      "Training loss : 0.013391382122226358\n",
      "Accuracy : 0.9972074398018863\n",
      "Weighted F1 : 0.9972080549188103\n",
      "----------------------------\n",
      "Training epoch : 14\n",
      "Training loss : 0.010575470948243463\n",
      "Accuracy : 0.9969439907265926\n",
      "Weighted F1 : 0.9969471814304873\n",
      "----------------------------\n",
      "Training epoch : 15\n",
      "Training loss : 0.007815476962892455\n",
      "Accuracy : 0.9794509721270879\n",
      "Weighted F1 : 0.9794311510684489\n",
      "----------------------------\n",
      "Training epoch : 16\n",
      "Training loss : 0.01181185485797455\n",
      "Accuracy : 0.9984193055482375\n",
      "Weighted F1 : 0.9984202185743933\n",
      "----------------------------\n",
      "Training epoch : 17\n",
      "Training loss : 0.007056409198724048\n",
      "Accuracy : 0.9978924073976501\n",
      "Weighted F1 : 0.9978935680335029\n",
      "----------------------------\n",
      "Training epoch : 18\n",
      "Training loss : 0.009040831838713983\n",
      "Accuracy : 0.9977870277675326\n",
      "Weighted F1 : 0.9977868632061941\n",
      "----------------------------\n",
      "Training epoch : 19\n",
      "Training loss : 0.008033239836681555\n",
      "Accuracy : 0.9987881342536488\n",
      "Weighted F1 : 0.9987882609410139\n",
      "----------------------------\n",
      "Training epoch : 20\n",
      "Training loss : 0.008519912332508059\n",
      "Accuracy : 0.9987881342536488\n",
      "Weighted F1 : 0.998788928887166\n",
      "----------------------------\n",
      "Training epoch : 21\n",
      "Training loss : 0.008222006389453102\n",
      "Accuracy : 0.99915696295906\n",
      "Weighted F1 : 0.9991571700729229\n",
      "----------------------------\n",
      "Training epoch : 22\n",
      "Training loss : 0.006547509475781334\n",
      "Accuracy : 0.9978924073976501\n",
      "Weighted F1 : 0.9978912245183555\n",
      "----------------------------\n",
      "Training epoch : 23\n",
      "Training loss : 0.0068298593279089975\n",
      "Accuracy : 0.99915696295906\n",
      "Weighted F1 : 0.9991573328678875\n",
      "----------------------------\n",
      "Training epoch : 24\n",
      "Training loss : 0.00769758215960195\n",
      "Accuracy : 0.9989988935138837\n",
      "Weighted F1 : 0.9989989439727135\n",
      "----------------------------\n",
      "Training epoch : 25\n",
      "Training loss : 0.006036974835906125\n",
      "Accuracy : 0.998946203698825\n",
      "Weighted F1 : 0.9989464150350763\n",
      "----------------------------\n",
      "Training epoch : 26\n",
      "Training loss : 0.007745648715982936\n",
      "Accuracy : 0.9991042731440013\n",
      "Weighted F1 : 0.9991044941972819\n",
      "----------------------------\n",
      "Training epoch : 27\n",
      "Training loss : 0.006240602392117903\n",
      "Accuracy : 0.99747088887718\n",
      "Weighted F1 : 0.9974717109949279\n",
      "----------------------------\n",
      "Training epoch : 28\n",
      "Training loss : 0.007191660437761761\n",
      "Accuracy : 0.9988935138837662\n",
      "Weighted F1 : 0.9988934346303981\n",
      "----------------------------\n",
      "Training epoch : 29\n",
      "Training loss : 0.00682339498145493\n",
      "Accuracy : 0.998946203698825\n",
      "Weighted F1 : 0.9989466402015555\n",
      "----------------------------\n",
      "Training epoch : 30\n",
      "Training loss : 0.004173322986992339\n",
      "Accuracy : 0.9995257916644713\n",
      "Weighted F1 : 0.9995258241660698\n",
      "----------------------------\n",
      "Training epoch : 31\n",
      "Training loss : 0.006541083730999175\n",
      "Accuracy : 0.9990515833289425\n",
      "Weighted F1 : 0.9990517946103472\n",
      "----------------------------\n",
      "Training epoch : 32\n",
      "Training loss : 0.005243245879312002\n",
      "Accuracy : 0.9977870277675326\n",
      "Weighted F1 : 0.9977830812603586\n",
      "----------------------------\n",
      "Training epoch : 33\n",
      "Training loss : 0.006469918227930309\n",
      "Accuracy : 0.99915696295906\n",
      "Weighted F1 : 0.9991570303439304\n",
      "----------------------------\n",
      "Training epoch : 34\n",
      "Exiting from training early\n",
      "Accuracy : 0.9989988935138837\n",
      "Weighted F1 : 0.9989989613794182\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "try:\n",
    "    for ep in range(1, 1+args.epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        log(\"Training epoch : \" + str(ep))\n",
    "        for i in range(0, len(xtrain), args.batch_size):\n",
    "            if i + args.batch_size <= len(xtrain):\n",
    "                x = torch.Tensor(xtrain[i: i+args.batch_size]).cuda()\n",
    "                y = torch.LongTensor(ytrain[i: i+args.batch_size]).cuda()  \n",
    "            else:\n",
    "                x = torch.Tensor(xtrain[i:]).cuda()\n",
    "                y = torch.LongTensor(ytrain[i:]).cuda()                      \n",
    "            out = model(x)\n",
    "            loss = loss_func(out, y)\n",
    "            epoch_loss += loss.cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()           \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        log(\"Training loss : \" + str(epoch_loss / (i / args.batch_size + 1)))\n",
    "        test(model, xtest, ytest)\n",
    "        log(\"----------------------------\")\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Exiting from training early')\n",
    "    test(model, xtest, ytest)\n",
    "if args.save:\n",
    "    torch.save(model.state_dict(), args.model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ed1c8c2e-c9a3-43f6-9903-6390cbdd8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), args.model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928d156a-3436-4203-b76c-614cb601c51c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
