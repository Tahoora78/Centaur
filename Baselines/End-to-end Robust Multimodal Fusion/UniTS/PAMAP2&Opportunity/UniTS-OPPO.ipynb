{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ceb8d2ed-260b-40da-8e00-4f336ad95266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from model import *\n",
    "from sliding_window import sliding_window\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62f2e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 2 # index starts from 0\n",
    "\n",
    "if gpu_id>=2:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "deb8e0b2-4bb9-4d7b-8903-3ec79224fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.config = 'default1'\n",
    "        self.dataset = 'opportunity_lc'\n",
    "        self.model = 'UniTS'\n",
    "        self.log = 'log'\n",
    "        self.exp = ''\n",
    "        self.seed = 0\n",
    "        self.ratio = 0.2\n",
    "        self.gpu_id = 0\n",
    "        self.epochs = 25\n",
    "        self.lr = 1e-3\n",
    "        # self.sigma = 0.35\n",
    "        self.batch_size = 64\n",
    "        self.save = True #'BCE'\n",
    "        self.test_only = False\n",
    "        self.input_size = 24 #256    \n",
    "        self.input_channel = 113 #45\n",
    "        self.hheads = 9\n",
    "        self.SENSOR_AXIS = 3\n",
    "        \n",
    "        # self.momentum = 0.1\n",
    "        # self.c = 0.01\n",
    "        # self.svmLR = 1e-4\n",
    "        # self.Ntest = 100\n",
    "        # self.gpuNo = 2\n",
    "        # self.cuda_id = 2\n",
    "        # self.multimodalZ = False\n",
    "        # self.window_len = 512\n",
    "        # self.stride_len = 20\n",
    "        # self.act_list = [1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24]\n",
    "        # self.imSize = 64\n",
    "        # self.sigma = [60, 80]\n",
    "        # # self.sigma = 0.3\n",
    "        # self.random_seed = 0\n",
    "        # self.train_split = 0.8\n",
    "        \n",
    "args = Args()\n",
    "args.num_labels=5\n",
    "\n",
    "args.log_path = os.path.join(args.log, args.dataset)\n",
    "if not os.path.exists(args.log_path):\n",
    "    os.mkdir(args.log_path)\n",
    "torch.cuda.set_device(args.gpu_id)\n",
    "args.model_save_path = os.path.join(args.log_path, args.model + '_'+ args.config + '.pt')\n",
    "#args.model_save_path = '........../UniTS_default.pt'\n",
    "config = read_config(args.config + '.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53513087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt1(x, sigma=0.2):\n",
    "    x=torch.Tensor(x)\n",
    "    noise = sigma * (torch.randn(x.size()).type_as(x))\n",
    "    return x + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb3fea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt2(x, sigma=[6,10]):\n",
    "        # print(x.shape)\n",
    "        # current: torch.Size([18944, 1, 27, 171])\n",
    "        # expected: torch.Size([171, 64, 27])\n",
    "        #9894, 24, 113\n",
    "        # time * batch_size * feature\n",
    "        # lambdas reuse the sigma variable, unpack\n",
    "        lambda_corr = sigma[0] # lambda for missing data period\n",
    "        lambda_norm = sigma[1] # lambda for normal data periodß\n",
    "        # corrupted_x = copy.deepcopy(x)\n",
    "        \n",
    "        # failure_mat = np.random.uniform(size = x.shape) < failure_rate\n",
    "        # num_failures = np.sum(failure_mat)\n",
    "        # failure_durations = np.random.exponential(scale = duration_scale, size = num_failures).astype(int)\n",
    "        x = torch.from_numpy(x)\n",
    "        mask = torch.ones_like(x)\n",
    "        #print(mask)\n",
    "        #print(x.shape)\n",
    "        # failure_id = 0\n",
    "        # sample_id is the batch size : 64\n",
    "        # ch_id is the features: 113\n",
    "        # mask.shape[0]: 171\n",
    "       # 46495, 24, 113\n",
    "        # print(mask.shape[0])\n",
    "        # print(mask.shape[1])\n",
    "        # print(mask.shape[2])\n",
    "        for sample_id in range(mask.shape[0]):\n",
    "            for ch_id in range(mask.shape[1]):  \n",
    "                ptr = 0\n",
    "                is_corrupted = False\n",
    "                while ptr < mask.shape[2]:\n",
    "                    if is_corrupted:\n",
    "                        corr_duration = int(np.random.exponential(scale=lambda_corr))\n",
    "                        #  mask[ptr:min(mask.shape[0], ptr + corr_duration), sample_id, ch_id] = 0\n",
    "                        mask[sample_id ,ch_id, ptr:min(mask.shape[2], ptr + corr_duration)] = 0\n",
    "                        ptr = min(mask.shape[2], ptr + corr_duration)\n",
    "                        is_corrupted = False\n",
    "                    else:\n",
    "                        norm_duration = int(np.random.exponential(scale=lambda_norm))\n",
    "                        ptr = min(mask.shape[2], ptr + norm_duration)\n",
    "                        is_corrupted = True\n",
    "        return torch.mul(x, mask)   \n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dbdb3d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt3(x, sigma=[0.1, 6,10]):\n",
    "        # print(x.shape)\n",
    "        # current: torch.Size([18944, 1, 27, 171])\n",
    "        # expected: torch.Size([171, 64, 27])\n",
    "        #9894, 24, 113\n",
    "        x=torch.Tensor(x)\n",
    "\n",
    "        noise = sigma[0] * (torch.randn(x.size()).type_as(x))\n",
    "        x= x+noise\n",
    "        # time * batch_size * feature\n",
    "        # lambdas reuse the sigma variable, unpack\n",
    "        lambda_corr = sigma[1] # lambda for missing data period\n",
    "        lambda_norm = sigma[2] # lambda for normal data periodß\n",
    "        # corrupted_x = copy.deepcopy(x)\n",
    "        \n",
    "        # failure_mat = np.random.uniform(size = x.shape) < failure_rate\n",
    "        # num_failures = np.sum(failure_mat)\n",
    "        # failure_durations = np.random.exponential(scale = duration_scale, size = num_failures).astype(int)\n",
    "        #x = torch.from_numpy(x)\n",
    "        mask = torch.ones_like(x)\n",
    "        #print(mask)\n",
    "        #print(x.shape)\n",
    "        # failure_id = 0\n",
    "        # sample_id is the batch size : 64\n",
    "        # ch_id is the features: 113\n",
    "        # mask.shape[0]: 171\n",
    "       # 46495, 24, 113\n",
    "        print(mask.shape[0])\n",
    "        print(mask.shape[1])\n",
    "        print(mask.shape[2])\n",
    "        for sample_id in range(mask.shape[0]):\n",
    "            for ch_id in range(mask.shape[1]):  \n",
    "                ptr = 0\n",
    "                is_corrupted = False\n",
    "                while ptr < mask.shape[2]:\n",
    "                    if is_corrupted:\n",
    "                        corr_duration = int(np.random.exponential(scale=lambda_corr))\n",
    "                        #  mask[ptr:min(mask.shape[0], ptr + corr_duration), sample_id, ch_id] = 0\n",
    "                        mask[sample_id ,ch_id, ptr:min(mask.shape[2], ptr + corr_duration)] = 0\n",
    "                        ptr = min(mask.shape[2], ptr + corr_duration)\n",
    "                        is_corrupted = False\n",
    "                    else:\n",
    "                        norm_duration = int(np.random.exponential(scale=lambda_norm))\n",
    "                        ptr = min(mask.shape[2], ptr + norm_duration)\n",
    "                        is_corrupted = True\n",
    "        return torch.mul(x, mask)   \n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba25b3a3-c0b5-4e61-903d-8bb57828010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_num:\t1\n",
      "\n",
      "window_list:\t[7, 16]\n",
      "\n",
      "stride_list:\t[3, 8]\n",
      "\n",
      "k_list:\t[3, 8]\n",
      "\n",
      "hidden_channel:\t48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Commented our parse_args to use in jupyter notebook\n",
    "'''\n",
    "# def parse_args():\n",
    "#     parser = argparse.ArgumentParser(description='train and test')\n",
    "#     parser.add_argument('--config', default = 'default', type =str) # Read UniTS hyperparameters\n",
    "#     parser.add_argument('--dataset', default = 'opportunity_lc', type = str,\n",
    "#                         choices=['opportunity_lc', 'seizure', 'wifi', 'keti'])\n",
    "#     parser.add_argument('--model', default='UniTS', type=str,\n",
    "#                         choices=['UniTS', 'THAT', 'RFNet', 'ResNet', 'MaDNN', 'MaCNN', 'LaxCat', 'static'])\n",
    "#     parser.add_argument('--seed', default=0, type=int)\n",
    "#     parser.add_argument('--log', default='log', type=str,\n",
    "#                         help=\"Log directory\")\n",
    "#     parser.add_argument('--exp', default='', type=str,\n",
    "#                         choices = ['','noise','missing_data'])\n",
    "#     parser.add_argument('--ratio', default=0.2, type=float)\n",
    "#     parser.add_argument('--n_gpu', default=0, type =int)\n",
    "    \n",
    "#     parser.add_argument('--epochs', default = 50, type = int)\n",
    "#     parser.add_argument('--lr', default = 1e-3, type = float)\n",
    "#     parser.add_argument('--batch_size', default = 64, type = int)\n",
    "\n",
    "#     parser.add_argument('--save', action = 'store_true')\n",
    "#     parser.add_argument('--test_only', action = 'store_true')\n",
    "#     args = parser.parse_args()\n",
    "#     config = read_config(args.config + '.yaml')\n",
    "#     if not os.path.exists(args.log):\n",
    "#         os.mkdir(args.log)\n",
    "#     args.log_path = os.path.join(args.log, args.dataset)\n",
    "#     if not os.path.exists(args.log_path):\n",
    "#         os.mkdir(args.log_path)\n",
    "#     torch.cuda.set_device(args.n_gpu)\n",
    "\n",
    "#     if args.dataset == 'opportunity_lc':\n",
    "#         args.input_size = 256\n",
    "#         args.input_channel = 45\n",
    "#         args.hheads = 9\n",
    "#         args.SENSOR_AXIS = 3\n",
    "#     elif args.dataset == 'seizure':\n",
    "#         args.input_channel = 18\n",
    "#         args.input_size = 256\n",
    "#         args.hheads = 6\n",
    "#         args.SENSOR_AXIS = 1\n",
    "#     elif args.dataset == 'wifi':\n",
    "#         args.input_channel = 180\n",
    "#         args.input_size = 256\n",
    "#         args.batch_size = 16\n",
    "#         args.hheads = 9\n",
    "#         args.SENSOR_AXIS = 3\n",
    "#     elif args.dataset == 'keti':\n",
    "#         args.input_channel = 4\n",
    "#         args.input_size = 256\n",
    "#         args.hheads = 4\n",
    "#         args.SENSOR_AXIS = 1\n",
    "#     args.model_save_path = os.path.join(args.log_path, args.model + '_'+ args.config + '.pt')\n",
    "#     return args, config\n",
    "\n",
    "# args, config = parse_args()\n",
    "log = set_up_logging(args, config)\n",
    "args.log = log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa54a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Opportunity Dataset.\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00226/OpportunityUCIDataset.zip --no-check-certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"............/UniTS-Sensory-Time-Series-Classification/source/OpportunityUCIDataset.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8f1e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sliding_window import sliding_window\n",
    "import pickle as cp\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python \"................./Copy of preprocess_data.py\" -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f055568",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python \"......./Copy of preprocess_data.py\" -i ........../UniTS/UniTS-Sensory-Time-Series-Classification/source/OpportunityUCIDataset.zip -o oppChallenge_gestures.data -t locomotion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de5f209-eb15-4bcf-8091-9a853fd5b5b0",
   "metadata": {},
   "source": [
    "## UniTS original pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e82020a-2cf0-49c6-8eef-3cc57bc3be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_data(args, config):\n",
    "#     path = os.path.join('../dataset', args.dataset)\n",
    "#     x_train = np.load(os.path.join(path, 'x_train.npy'))\n",
    "#     y_train = np.load(os.path.join(path, 'y_train.npy')).astype('int64').tolist()\n",
    "#     x_test = np.load(os.path.join(path, 'x_test.npy'))\n",
    "#     y_test = np.load(os.path.join(path, 'y_test.npy')).astype('int64').tolist()\n",
    "#     np.random.seed(args.seed)\n",
    "\n",
    "#     if args.exp == 'noise': # Robustness test (noise)\n",
    "#         for i in range(len(x_train)):\n",
    "#             for j in range(x_train.shape[2]):\n",
    "#                 noise = np.random.normal(1,1 , size= x_train[i][:, j].shape)\n",
    "#                 x_train[i][:, j] = x_train[i][:, j] + noise * args.ratio * np.mean(np.absolute(x_train[i][:, j] ))\n",
    "#         for i in range(len(x_test)):\n",
    "#             for j in range(x_test.shape[2]):\n",
    "#                 noise = np.random.normal(1, 1, size= x_test[i][:, j].shape)\n",
    "#                 x_test[i][:, j] = x_test[i][:, j] + noise * args.ratio * np.mean(np.absolute(x_test[i][:, j] ))\n",
    "\n",
    "#     elif args.exp == 'missing_data': # Robustness test (missing value)\n",
    "#         for i in range(len(x_train)):\n",
    "#             for j in range(x_train.shape[2]):\n",
    "#                 mask = np.random.random(x_train[i][:, j].shape) >= args.ratio\n",
    "#                 x_train[i][:, j] = x_train[i][:, j] * mask\n",
    "#         for i in range(len(x_test)):\n",
    "#             for j in range(x_test.shape[2]):\n",
    "#                 mask = np.random.random(x_test[i][:, j].shape) >= args.ratio\n",
    "#                 x_test[i][:, j] = x_test[i][:, j] * mask\n",
    "\n",
    "#     args.num_labels = max(y_train) + 1\n",
    "#     summary = [0 for i in range(args.num_labels)]\n",
    "#     for i in y_train:\n",
    "#         summary[i] += 1\n",
    "#     args.log(\"Label num cnt: \"+ str(summary))\n",
    "#     args.log(\"Training size: \" + str(len(y_train)))\n",
    "#     args.log(\"Testing size: \" + str(len(y_test)))\n",
    "#     return list(x_train), y_train, list(x_test), y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ec54e-6ccc-4863-8344-2fb308ee8190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtrain, ytrain, xtest, ytest = read_data(args, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5954663b-b379-4faf-99be-e0f70b57986d",
   "metadata": {},
   "source": [
    "## Our pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08a1abce-131c-4350-9b48-223c162bc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sliding_window import sliding_window\n",
    "import pickle as cp\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b43f7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    mean = data.mean()\n",
    "    std =data.std()\n",
    "    norm = (data - mean)/std\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c399ec4-5672-4dc2-9a54-453c139afbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Sensor Channels used in the OPPORTUNITY dataset.\n",
    "NB_SENSOR_CHANNELS = 113\n",
    "\n",
    "# Number of classes in which data is classified (or to be classified).\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "# Length of the sliding window used to segmenting the time-series-data.\n",
    "SLIDING_WINDOW_LENGTH = 24\n",
    "\n",
    "# Steps of the sliding window used in segmenting the data.\n",
    "SLIDING_WINDOW_STEP = 12\n",
    "\n",
    "act_labels_txt = ['std', 'wlk', 'sit', 'lie', 'null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "222ca6f3-7e63-40b1-a6e9-7083044fc899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      " ..from file .../oppChallenge_gestures.data\n",
      " ..reading instances: train (557963, 113), test (118750, 113)\n",
      " ..after sliding window (testing): inputs (9894, 24, 113), targets (9894,)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(filename):\n",
    "\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = cp.load(f,encoding='latin1')\n",
    "\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_test)\n",
    "\n",
    "    print(\" ..from file {}\".format(filename))\n",
    "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "print(\"Loading Data...\")\n",
    "X_train, y_train, X_test, y_test = load_dataset('......./oppChallenge_gestures.data')\n",
    "\n",
    "\n",
    "\n",
    "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
    "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
    "\n",
    "# Sensor data is segmented using a sliding window mechanism\n",
    "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "print(\" ..after sliding window (testing): inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
    "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS))\n",
    "# X_test = np.transpose(X_test, (0, 2, 1))\n",
    "# X_test= X_test.reshape(X_test.shape[0], 1, X_test.shape[1], X_test.shape[2]) # convert list to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27a38b35-a013-4b70-a003-7b5b3343ff04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ..after sliding window (training): inputs (46495, 24, 113), targets (46495,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(46495, 24, 113)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "print(\" ..after sliding window (training): inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
    "X_train = X_train.reshape((-1,SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS))\n",
    "# X_train = np.transpose(X_train, (0, 2, 1))\n",
    "# X_train= X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2]) # convert list to numpy array\n",
    "\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38bc08ab-59e3-49ad-a620-fac421d3784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = list(X_train)\n",
    "# X_test = list(X_test)\n",
    "xtrain, ytrain, xtest, ytest = X_train, y_train, X_test, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a1d1f12",
   "metadata": {},
   "source": [
    "Create a copy of xtest for evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57e80760",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90fc032c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46495\n",
      "24\n",
      "113\n",
      "9894\n",
      "24\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "xtrain = corrupt3(xtrain)\n",
    "xtest = corrupt3(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac8bc813-0034-474b-b0f2-27d284f2c7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 16]\n",
      "[3, 8]\n",
      "[3, 8]\n",
      "1\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print(config.window_list)\n",
    "print(config.stride_list)\n",
    "print(config.k_list)\n",
    "print(config.layer_num)\n",
    "print(config.hidden_channel)\n",
    "# Adjust model parameters based on our preprocessing\n",
    "config.window_list = [7,16]\n",
    "config.stride_list = [3,8]\n",
    "config.k_list = [3,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f2fba582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, xtest, ytest):\n",
    "    #print(type(xtest))\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i in range(0, len(xtest), args.batch_size):\n",
    "            if i + args.batch_size <= len(xtest):\n",
    "               \n",
    "                x = torch.Tensor(xtest[i: i+args.batch_size]).cuda()\n",
    "               # x_new = float(x.item())\n",
    "                # print(type(ytest[i: i+args.batch_size]))\n",
    "                y_true += list(ytest[i: i+args.batch_size])\n",
    "            else:\n",
    "                x = torch.Tensor(xtest[i:]).cuda()\n",
    "                y_true += list(ytest[i:])\n",
    "            out = model(x)\n",
    "            pred = torch.argmax(out, dim = -1)\n",
    "            y_pred += pred.cpu().tolist()\n",
    "\n",
    "    log(\"Accuracy : \" + str(accuracy_score(y_true, y_pred)) +\n",
    "        \"\\nWeighted F1 : \" + str(f1_score(y_true, y_pred, labels=list(range(args.num_labels)),average='weighted')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad2c60-ecbe-4fc1-af93-922bebd8de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(args.seed)\n",
    "# random.shuffle(xtrain)\n",
    "# random.seed(args.seed)\n",
    "# random.shuffle(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0cc0ecf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 512927\n"
     ]
    }
   ],
   "source": [
    "if args.model == 'UniTS':\n",
    "    model = UniTS(input_size = args.input_size, sensor_num = args.input_channel, layer_num = config.layer_num,\n",
    "    window_list = config.window_list,  stride_list = config.stride_list, k_list = config.k_list,\n",
    "    out_dim = args.num_labels, hidden_channel = config.hidden_channel).cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "# elif args.model == 'static':\n",
    "#     model = static_UniTS(input_size = args.input_size, sensor_num = args.input_channel, layer_num = config.layer_num,\n",
    "#     window_list = config.window_list, stride_list = config.stride_list, k_list = config.k_list,\n",
    "#     out_dim = args.num_labels, hidden_channel = config.hidden_channel).cuda()\n",
    "\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "# elif args.model == 'THAT':\n",
    "#     args.hlayers = 5\n",
    "#     args.vlayers = 1\n",
    "#     args.vheads = 16\n",
    "#     args.K = 10\n",
    "#     args.sample = 4\n",
    "#     model = HARTrans(args).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# elif args.model == 'RFNet':\n",
    "#     model = RFNet(num_classes = args.num_labels, input_channel = args.input_channel, win_len = args.input_size).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "# elif args.model == 'ResNet':\n",
    "#     model = ResNet(input_size = args.input_size, input_channel = args.input_channel, num_label = args.num_labels).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)        \n",
    "\n",
    "# elif args.model == 'MaDNN':\n",
    "#     model = MaDNN(input_size = args.input_size, input_channel = args.input_channel, num_label = args.num_labels).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)   \n",
    "\n",
    "# elif args.model == 'MaCNN':\n",
    "#     model = MaCNN(input_size = args.input_size, input_channel = args.input_channel, num_label = args.num_labels, \n",
    "#         sensor_num = int(args.input_channel / args.SENSOR_AXIS)).cuda()\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "# elif args.model == 'LaxCat':\n",
    "#     model = LaxCat(input_size = args.input_size, input_channel = args.input_channel, num_label = args.num_labels,\n",
    "#         hidden_dim = 64, kernel_size = 32, stride = 8).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "log('Total parameters: ' + str(total_params))\n",
    "\n",
    "if args.test_only:\n",
    "    if os.path.exists(args.model_save_path):\n",
    "        model.load_state_dict(torch.load(args.model_save_path))\n",
    "       \n",
    "        test(model, xtest, ytest)\n",
    "\n",
    "    else:\n",
    "        log(\"Model state dict not found!\")\n",
    "    # return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "19f00a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(args.model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc0a224c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['ts_encoders.0.FIC.conv.weight', 'ts_encoders.0.RPC.weight', 'ts_encoders.0.RPC.bias', 'ts_encoders.1.FIC.conv.weight', 'ts_encoders.1.RPC.weight', 'ts_encoders.1.RPC.bias', 'multi_channel_fusion.0.weight', 'multi_channel_fusion.0.bias', 'multi_channel_fusion.1.weight', 'multi_channel_fusion.1.bias', 'conv_branches.0.0.conv1.0.weight', 'conv_branches.0.0.conv1.0.bias', 'conv_branches.0.0.bn1.0.weight', 'conv_branches.0.0.bn1.0.bias', 'conv_branches.0.0.bn1.0.running_mean', 'conv_branches.0.0.bn1.0.running_var', 'conv_branches.0.0.bn1.0.num_batches_tracked', 'conv_branches.0.0.conv2.0.weight', 'conv_branches.0.0.conv2.0.bias', 'conv_branches.0.0.bn2.0.weight', 'conv_branches.0.0.bn2.0.bias', 'conv_branches.0.0.bn2.0.running_mean', 'conv_branches.0.0.bn2.0.running_var', 'conv_branches.0.0.bn2.0.num_batches_tracked', 'conv_branches.0.1.weight', 'conv_branches.0.1.bias', 'conv_branches.0.3.conv1.0.weight', 'conv_branches.0.3.conv1.0.bias', 'conv_branches.0.3.bn1.0.weight', 'conv_branches.0.3.bn1.0.bias', 'conv_branches.0.3.bn1.0.running_mean', 'conv_branches.0.3.bn1.0.running_var', 'conv_branches.0.3.bn1.0.num_batches_tracked', 'conv_branches.0.3.conv2.0.weight', 'conv_branches.0.3.conv2.0.bias', 'conv_branches.0.3.bn2.0.weight', 'conv_branches.0.3.bn2.0.bias', 'conv_branches.0.3.bn2.0.running_mean', 'conv_branches.0.3.bn2.0.running_var', 'conv_branches.0.3.bn2.0.num_batches_tracked', 'bns.0.weight', 'bns.0.bias', 'bns.0.running_mean', 'bns.0.running_var', 'bns.0.num_batches_tracked', 'bns.1.weight', 'bns.1.bias', 'bns.1.running_mean', 'bns.1.running_var', 'bns.1.num_batches_tracked', 'end_linear.0.weight', 'end_linear.0.bias', 'end_linear.1.weight', 'end_linear.1.bias', 'classifier.weight', 'classifier.bias'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(args.model_save_path).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "81deeec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch : 1\n",
      "Training loss : 1.1094472211320594\n",
      "Accuracy : 0.7290276935516474\n",
      "Weighted F1 : 0.6599292126196044\n",
      "----------------------------\n",
      "Training epoch : 2\n",
      "Training loss : 0.8336756201627494\n",
      "Accuracy : 0.7375176874873661\n",
      "Weighted F1 : 0.690538210373143\n",
      "----------------------------\n",
      "Training epoch : 3\n",
      "Training loss : 0.6319536424691609\n",
      "Accuracy : 0.7552051748534465\n",
      "Weighted F1 : 0.7228710654150127\n",
      "----------------------------\n",
      "Training epoch : 4\n",
      "Training loss : 0.502492505872553\n",
      "Accuracy : 0.7624823125126339\n",
      "Weighted F1 : 0.7372415503426201\n",
      "----------------------------\n",
      "Training epoch : 5\n",
      "Training loss : 0.4005906425846902\n",
      "Accuracy : 0.7603598140287042\n",
      "Weighted F1 : 0.7413536603975446\n",
      "----------------------------\n",
      "Training epoch : 6\n",
      "Training loss : 0.32053625598636953\n",
      "Accuracy : 0.757630887406509\n",
      "Weighted F1 : 0.7359470286449848\n",
      "----------------------------\n",
      "Training epoch : 7\n",
      "Training loss : 0.242390499139612\n",
      "Accuracy : 0.7554073175662017\n",
      "Weighted F1 : 0.732374367061669\n",
      "----------------------------\n",
      "Training epoch : 8\n",
      "Training loss : 0.1808130352812636\n",
      "Accuracy : 0.7489387507580352\n",
      "Weighted F1 : 0.728240008418073\n",
      "----------------------------\n",
      "Training epoch : 9\n",
      "Training loss : 0.1320693535908629\n",
      "Accuracy : 0.748231251263392\n",
      "Weighted F1 : 0.7243227752143757\n",
      "----------------------------\n",
      "Training epoch : 10\n",
      "Training loss : 0.10151790878558538\n",
      "Accuracy : 0.7406508995350718\n",
      "Weighted F1 : 0.6987230422643911\n",
      "----------------------------\n",
      "Training epoch : 11\n",
      "Training loss : 0.08518319387262342\n",
      "Accuracy : 0.7307459066100667\n",
      "Weighted F1 : 0.6911555830633939\n",
      "----------------------------\n",
      "Training epoch : 12\n",
      "Training loss : 0.10012586590616444\n",
      "Accuracy : 0.730139478471801\n",
      "Weighted F1 : 0.6970590154607035\n",
      "----------------------------\n",
      "Training epoch : 13\n",
      "Training loss : 0.07774341536048207\n",
      "Accuracy : 0.7294319789771578\n",
      "Weighted F1 : 0.69099680169657\n",
      "----------------------------\n",
      "Training epoch : 14\n",
      "Training loss : 0.04619930753971327\n",
      "Accuracy : 0.718213058419244\n",
      "Weighted F1 : 0.6745558460609747\n",
      "----------------------------\n",
      "Training epoch : 15\n",
      "Training loss : 0.03767473823924297\n",
      "Accuracy : 0.7184152011319992\n",
      "Weighted F1 : 0.6780157295173055\n",
      "----------------------------\n",
      "Training epoch : 16\n",
      "Training loss : 0.04295906509180031\n",
      "Accuracy : 0.7213462704669497\n",
      "Weighted F1 : 0.6809843655737037\n",
      "----------------------------\n",
      "Training epoch : 17\n",
      "Training loss : 0.05018083837268477\n",
      "Accuracy : 0.7293309076207802\n",
      "Weighted F1 : 0.6996066815514973\n",
      "----------------------------\n",
      "Training epoch : 18\n",
      "Training loss : 0.0390761354635142\n",
      "Accuracy : 0.7320598342429755\n",
      "Weighted F1 : 0.691834449101587\n",
      "----------------------------\n",
      "Training epoch : 19\n",
      "Training loss : 0.03683560565406916\n",
      "Accuracy : 0.7311501920355771\n",
      "Weighted F1 : 0.6985680760101063\n",
      "----------------------------\n",
      "Training epoch : 20\n",
      "Training loss : 0.0281923763981792\n",
      "Accuracy : 0.7122498483929655\n",
      "Weighted F1 : 0.6726129134442214\n",
      "----------------------------\n",
      "Training epoch : 21\n",
      "Training loss : 0.02788045683627439\n",
      "Accuracy : 0.7046694966646453\n",
      "Weighted F1 : 0.6647986543150313\n",
      "----------------------------\n",
      "Training epoch : 22\n",
      "Training loss : 0.022568651679433355\n",
      "Accuracy : 0.7309480493228219\n",
      "Weighted F1 : 0.6852216608246354\n",
      "----------------------------\n",
      "Training epoch : 23\n",
      "Training loss : 0.021871137424030893\n",
      "Accuracy : 0.7253891247220537\n",
      "Weighted F1 : 0.6856670277078158\n",
      "----------------------------\n",
      "Training epoch : 24\n",
      "Training loss : 0.04435758734890381\n",
      "Accuracy : 0.7173034162118456\n",
      "Weighted F1 : 0.6814426999189733\n",
      "----------------------------\n",
      "Training epoch : 25\n",
      "Training loss : 0.03450632297166635\n",
      "Accuracy : 0.7453001819284415\n",
      "Weighted F1 : 0.724158411090523\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "try:\n",
    "    for ep in range(1, 1+args.epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        log(\"Training epoch : \" + str(ep))\n",
    "        for i in range(0, len(xtrain), args.batch_size):\n",
    "            if i + args.batch_size <= len(xtrain):\n",
    "                x = torch.Tensor(xtrain[i: i+args.batch_size]).cuda()\n",
    "\n",
    "                y = torch.LongTensor(ytrain[i: i+args.batch_size]).cuda()  \n",
    "            else:\n",
    "                x = torch.Tensor(xtrain[i:]).cuda()\n",
    "                y = torch.LongTensor(ytrain[i:]).cuda()                      \n",
    "            out = model(x)\n",
    "            loss = loss_func(out, y)\n",
    "            epoch_loss += loss.cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()           \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        log(\"Training loss : \" + str(epoch_loss / (i / args.batch_size + 1)))\n",
    "     \n",
    "        test(model, xtest, ytest)\n",
    "\n",
    "        log(\"----------------------------\")\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Exiting from training early')\n",
    "    test(model, xtest, ytest)\n",
    "if args.save:\n",
    "    torch.save(model.state_dict(), args.model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ed1c8c2e-c9a3-43f6-9903-6390cbdd8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), args.model_save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f33cf3dc",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a842f395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9894\n",
      "24\n",
      "113\n",
      "Accuracy : 0.7473216090559935\n",
      "Weighted F1 : 0.7267344819479478\n"
     ]
    }
   ],
   "source": [
    "#xtest_eval = corrupt1(X_test,sigma=0.05)\n",
    "xtest_eval = corrupt3(X_test,sigma=[0.2,8, 10])\n",
    "\n",
    "\n",
    "test(model, xtest_eval, ytest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
