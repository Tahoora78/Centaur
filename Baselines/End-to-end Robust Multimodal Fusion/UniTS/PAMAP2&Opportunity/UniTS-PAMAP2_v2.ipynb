{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb8d2ed-260b-40da-8e00-4f336ad95266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from model import *\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb8e0b2-4bb9-4d7b-8903-3ec79224fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.config = 'default'\n",
    "        self.dataset = 'pamap2'\n",
    "        self.model = 'UniTS'\n",
    "        self.log = 'log'\n",
    "        self.exp = ''\n",
    "        self.seed = 0\n",
    "        self.ratio = 0.2\n",
    "        self.n_gpu = 2\n",
    "        # no of epochs for pamap2 is set to 25\n",
    "        self.epochs = 25\n",
    "        self.lr = 1e-3\n",
    "        self.batch_size = 64\n",
    "        self.save = True #'BCE'\n",
    "        self.test_only = False\n",
    "        self.input_size = 171 # 24 #256    \n",
    "        self.input_channel = 27 # 113 #45\n",
    "        self.hheads = 9\n",
    "        self.SENSOR_AXIS = 3\n",
    "        \n",
    "    \n",
    "    # def corrupt1(self,x):\n",
    "    #     print(type(x))\n",
    "    #     #sigma = 0.2\n",
    "    #     noise = self.sigma * (torch.randn(x.size()).type_as(x))\n",
    "    #     return x + noise\n",
    "    \n",
    "    \n",
    "        \n",
    "args = Args()\n",
    "args.num_labels=12\n",
    "\n",
    "args.log_path = os.path.join(args.log, args.dataset)\n",
    "if not os.path.exists(args.log_path):\n",
    "    os.mkdir(args.log_path)\n",
    "torch.cuda.set_device(args.n_gpu)\n",
    "args.model_save_path = os.path.join(args.log_path, args.model + '_'+ args.config + '.pt')\n",
    "config = read_config(args.config + '.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12689b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt1(x, sigma=0.2):\n",
    "    print(type(x))\n",
    "    sigma = 0.2\n",
    "    noise = sigma * (torch.randn(x.size()).type_as(x))\n",
    "    return x + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ef7bdbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt2(x, sigma=[50,80]):\n",
    "        # print(x.shape)\n",
    "        # current: torch.Size([18944, 1, 27, 171])\n",
    "        # expected: torch.Size([171, 64, 27])\n",
    "        #18979,171,27\n",
    "        # time * batch_size * feature\n",
    "        # lambdas reuse the sigma variable, unpack\n",
    "        #sigma =[40,80]\n",
    "        lambda_corr = sigma[0] # lambda for missing data period\n",
    "        lambda_norm = sigma[1] # lambda for normal data periodß\n",
    "        # corrupted_x = copy.deepcopy(x)\n",
    "        \n",
    "        # failure_mat = np.random.uniform(size = x.shape) < failure_rate\n",
    "        # num_failures = np.sum(failure_mat)\n",
    "        # failure_durations = np.random.exponential(scale = duration_scale, size = num_failures).astype(int)\n",
    "        mask = torch.ones_like(x)\n",
    "        #print(mask.shape)\n",
    "        # failure_id = 0\n",
    "        # sample_id is the batch size : 64\n",
    "        # ch_id is the features: 27\n",
    "        # mask.shape[0]: 171\n",
    "        \n",
    "        for sample_id in range(mask.shape[0]):\n",
    "            for ch_id in range(mask.shape[2]):  \n",
    "                ptr = 0\n",
    "                is_corrupted = False\n",
    "                while ptr < mask.shape[1]:\n",
    "                    if is_corrupted:\n",
    "                        corr_duration = int(np.random.exponential(scale=lambda_corr))\n",
    "                        #  mask[ptr:min(mask.shape[0], ptr + corr_duration), sample_id, ch_id] = 0\n",
    "                        mask[sample_id ,ch_id, ptr:min(mask.shape[1], ptr + corr_duration)] = 0\n",
    "                        ptr = min(mask.shape[1], ptr + corr_duration)\n",
    "                        is_corrupted = False\n",
    "                    else:\n",
    "                        norm_duration = int(np.random.exponential(scale=lambda_norm))\n",
    "                        ptr = min(mask.shape[1], ptr + norm_duration)\n",
    "                        is_corrupted = True\n",
    "        #print(mask)\n",
    "        return torch.mul(x, mask)   \n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f32b6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt3(x, sigma=[0.1, 50,80]):\n",
    "        # print(x.shape)\n",
    "        # current: torch.Size([18944, 1, 27, 171])\n",
    "        # expected: torch.Size([171, 64, 27])\n",
    "        #189882,171,27\n",
    "        noise = sigma[0] * (torch.randn(x.size()).type_as(x))\n",
    "        x= x+noise\n",
    "        # time * batch_size * feature\n",
    "        # lambdas reuse the sigma variable, unpack\n",
    "        lambda_corr = sigma[1] # lambda for missing data period\n",
    "        lambda_norm = sigma[2] # lambda for normal data periodß\n",
    "        # corrupted_x = copy.deepcopy(x)\n",
    "        \n",
    "        # failure_mat = np.random.uniform(size = x.shape) < failure_rate\n",
    "        # num_failures = np.sum(failure_mat)\n",
    "        # failure_durations = np.random.exponential(scale = duration_scale, size = num_failures).astype(int)\n",
    "        mask = torch.ones_like(x)\n",
    "        #print(mask.shape)\n",
    "\n",
    "        #print(x.shape)\n",
    "        # failure_id = 0\n",
    "        # sample_id is the batch size : 64\n",
    "        # ch_id is the features: 27\n",
    "        # mask.shape[0]: 171\n",
    "        \n",
    "        for sample_id in range(mask.shape[0]):\n",
    "            for ch_id in range(mask.shape[2]):  \n",
    "                ptr = 0\n",
    "                is_corrupted = False\n",
    "                while ptr < mask.shape[1]:\n",
    "                    if is_corrupted:\n",
    "                        corr_duration = int(np.random.exponential(scale=lambda_corr))\n",
    "                        #  mask[ptr:min(mask.shape[0], ptr + corr_duration), sample_id, ch_id] = 0\n",
    "                        mask[sample_id ,ch_id, ptr:min(mask.shape[1], ptr + corr_duration)] = 0\n",
    "                        ptr = min(mask.shape[1], ptr + corr_duration)\n",
    "                        is_corrupted = False\n",
    "                    else:\n",
    "                        norm_duration = int(np.random.exponential(scale=lambda_norm))\n",
    "                        ptr = min(mask.shape[1], ptr + norm_duration)\n",
    "                        is_corrupted = True\n",
    "        #print(mask)\n",
    "        return torch.mul(x, mask)   \n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba25b3a3-c0b5-4e61-903d-8bb57828010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_num:\t1\n",
      "\n",
      "window_list:\t[7, 16, 32, 48, 64, 80, 96, 112, 128]\n",
      "\n",
      "stride_list:\t[3, 8, 16, 24, 32, 40, 48, 56, 64]\n",
      "\n",
      "k_list:\t[3, 8, 16, 24, 24, 32, 32, 40, 40]\n",
      "\n",
      "hidden_channel:\t48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Commented our parse_args to use in jupyter notebook\n",
    "'''\n",
    "# def parse_args():\n",
    "#     parser = argparse.ArgumentParser(description='train and test')\n",
    "#     parser.add_argument('--config', default = 'default', type =str) # Read UniTS hyperparameters\n",
    "#     parser.add_argument('--dataset', default = 'opportunity_lc', type = str,\n",
    "#                         choices=['opportunity_lc', 'seizure', 'wifi', 'keti'])\n",
    "#     parser.add_argument('--model', default='UniTS', type=str,\n",
    "#                         choices=['UniTS', 'THAT', 'RFNet', 'ResNet', 'MaDNN', 'MaCNN', 'LaxCat', 'static'])\n",
    "#     parser.add_argument('--seed', default=0, type=int)\n",
    "#     parser.add_argument('--log', default='log', type=str,\n",
    "#                         help=\"Log directory\")\n",
    "#     parser.add_argument('--exp', default='', type=str,\n",
    "#                         choices = ['','noise','missing_data'])\n",
    "#     parser.add_argument('--ratio', default=0.2, type=float)\n",
    "#     parser.add_argument('--n_gpu', default=0, type =int)\n",
    "    \n",
    "#     parser.add_argument('--epochs', default = 50, type = int)\n",
    "#     parser.add_argument('--lr', default = 1e-3, type = float)\n",
    "#     parser.add_argument('--batch_size', default = 64, type = int)\n",
    "\n",
    "#     parser.add_argument('--save', action = 'store_true')\n",
    "#     parser.add_argument('--test_only', action = 'store_true')\n",
    "#     args = parser.parse_args()\n",
    "#     config = read_config(args.config + '.yaml')\n",
    "#     if not os.path.exists(args.log):\n",
    "#         os.mkdir(args.log)\n",
    "#     args.log_path = os.path.join(args.log, args.dataset)\n",
    "#     if not os.path.exists(args.log_path):\n",
    "#         os.mkdir(args.log_path)\n",
    "#     torch.cuda.set_device(args.n_gpu)\n",
    "\n",
    "#     if args.dataset == 'opportunity_lc':\n",
    "#         args.input_size = 256\n",
    "#         args.input_channel = 45\n",
    "#         args.hheads = 9\n",
    "#         args.SENSOR_AXIS = 3\n",
    "#     elif args.dataset == 'seizure':\n",
    "#         args.input_channel = 18\n",
    "#         args.input_size = 256\n",
    "#         args.hheads = 6\n",
    "#         args.SENSOR_AXIS = 1\n",
    "#     elif args.dataset == 'wifi':\n",
    "#         args.input_channel = 180\n",
    "#         args.input_size = 256\n",
    "#         args.batch_size = 16\n",
    "#         args.hheads = 9\n",
    "#         args.SENSOR_AXIS = 3\n",
    "#     elif args.dataset == 'keti':\n",
    "#         args.input_channel = 4\n",
    "#         args.input_size = 256\n",
    "#         args.hheads = 4\n",
    "#         args.SENSOR_AXIS = 1\n",
    "#     args.model_save_path = os.path.join(args.log_path, args.model + '_'+ args.config + '.pt')\n",
    "#     return args, config\n",
    "\n",
    "# args, config = parse_args()\n",
    "log = set_up_logging(args, config)\n",
    "args.log = log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b49a47-2842-4fb6-ad59-f774c6ac777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sliding_window import sliding_window\n",
    "import pickle as cp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00231/PAMAP2_Dataset.zip --no-check-certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18fc826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"PAMAP2_Dataset.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d344c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 512 # 512\n",
    "stride_len = 20 # 100\n",
    "act_list = [1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24]\n",
    "# act_list = [1, 2]\n",
    "act_labels_txt = ['lay', 'sit', 'std', 'wlk', 'run', 'cyc', 'nord', 'ups', 'dws', 'vac', 'iron', 'rop']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d8bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "user_labels=[]\n",
    "act_labels=[]\n",
    "\n",
    "# columns for IMU data\n",
    "# 4-20 IMU hand\n",
    "# 21-37 IMU chest\n",
    "# 38-54 IMU ankle\n",
    "# 2-4 3D-acceleration data (ms-2), scale: ±16g, resolution: 13-bit\n",
    "# 8-10 3D-gyroscope data (rad/s)\n",
    "# 11-13 3D-magnetometer data (μT)\n",
    "imu_locs = [4,5,6, 10,11,12, 13,14,15, \n",
    "            21,22,23, 27,28,29, 30,31,32, \n",
    "            38,39,40, 44,45,46, 47,48,49\n",
    "           ] \n",
    "\n",
    "# acc=0,1,2,9,10,11,18,19,20\n",
    "# gyrp 3,4,5, 12,13,14,21,22,23\n",
    "# mag 6,7,8,15,16,17, 24,25,26\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "for uid in np.arange(1,10):\n",
    "    path = '....../PAMAP2_Dataset/Protocol/subject10' + str(uid) + '.dat'\n",
    "    df = pd.read_table(path, sep=' ', header=None)\n",
    "    act_imu_filter = df.iloc[:, imu_locs] \n",
    "\n",
    "\n",
    "    for act_id in range(len(act_list)):\n",
    "        act_filter =  act_imu_filter[df.iloc[:, 1] == act_list[act_id]]\n",
    "        act_data = act_filter.to_numpy()\n",
    "        act_data = np.transpose(act_data)\n",
    "\n",
    "        # sliding window segmentation\n",
    "        start_idx = 0\n",
    "        while start_idx + window_len < act_data.shape[1]:\n",
    "            window_data = act_data[:, start_idx:start_idx+window_len] \n",
    "            downsamp_data = window_data[:, ::3] # downsample from 100hz to 33.3hz\n",
    "            downsamp_data = np.nan_to_num(downsamp_data) # remove nan\n",
    "            # downsamp_data = np.transpose(downsamp_data) # dim: seq_len, feature_len\n",
    "\n",
    "            data.append(downsamp_data)\n",
    "            user_labels.append(uid)\n",
    "            act_labels.append(act_id)\n",
    "            start_idx = start_idx + stride_len\n",
    "            \n",
    "data = np.array(data).astype('float32')\n",
    "\n",
    "normalized_X = np.zeros_like(data) # allocate numpy array for normalized data\n",
    "for ch_id in range(data.shape[1]): # loop the 27 sensor channels\n",
    "    ch_data = data[:, ch_id, :] # the data of channel id\n",
    "    scaler = MinMaxScaler() # maybe different scalers?\n",
    "    ch_data = scaler.fit_transform(ch_data) # scale the data in this channel to [0,1]\n",
    "    normalized_X[:, ch_id, :] = ch_data # assign normalized data to normalized_X\n",
    "normalized_X = np.transpose(normalized_X, (0, 2, 1)) # overwrote X here, changed dimensions into: num_samples, sequence_length, feature_length\n",
    "        \n",
    "    # convert list to numpy array\n",
    "    # normalized_X= normalized_X.reshape(normalized_X.shape[0], 1, normalized_X.shape[1], normalized_X.shape[2]) \n",
    "act_labels = np.array(act_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d02d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X=torch.Tensor(normalized_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a200e8d3-bec0-4039-a6be-332358e6c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(normalized_X, act_labels, test_size=args.ratio, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18600e81",
   "metadata": {},
   "source": [
    "Create a copy of xtest for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6768184",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f82c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = corrupt3(xtrain)\n",
    "xtest = corrupt3(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5954663b-b379-4faf-99be-e0f70b57986d",
   "metadata": {},
   "source": [
    "## Our pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac8bc813-0034-474b-b0f2-27d284f2c7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 16, 32, 48, 64, 80, 96, 112, 128]\n",
      "[3, 8, 16, 24, 32, 40, 48, 56, 64]\n",
      "[3, 8, 16, 24, 24, 32, 32, 40, 40]\n",
      "1\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print(config.window_list)\n",
    "print(config.stride_list)\n",
    "print(config.k_list)\n",
    "print(config.layer_num)\n",
    "print(config.hidden_channel)\n",
    "# Adjust model parameters based on our preprocessing\n",
    "# config.window_list = [7,16,32, 48, 64, 80]\n",
    "config.window_list = [7, 16, 32, 48, 64, 80, 96, 112, 128]\n",
    "# config.stride_list = [3, 8, 16, 24, 32, 40]\n",
    "config.stride_list = [3, 8, 16, 24, 32, 40, 48, 56, 64]\n",
    "# config.k_list = [3, 8, 16, 24, 24, 32]\n",
    "config.k_list = [3, 8, 16, 24, 24, 32, 32, 40, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63711ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, xtest, ytest):\n",
    "    # choose accordingly\n",
    "\n",
    "    #noise = sigma * (torch.randn(xtest.size()).type_as(xtest))\n",
    "    #xtest = corrupt3(xtest, sigma)\n",
    "    #xtest=xtest+noise\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i in range(0, len(xtest), args.batch_size):\n",
    "            if i + args.batch_size <= len(xtest):\n",
    "               \n",
    "                x = torch.Tensor(xtest[i: i+args.batch_size]).cuda()\n",
    "               # x_new = float(x.item())\n",
    "                # print(type(ytest[i: i+args.batch_size]))\n",
    "                y_true += list(ytest[i: i+args.batch_size])\n",
    "            else:\n",
    "                x = torch.Tensor(xtest[i:]).cuda()\n",
    "                y_true += list(ytest[i:])\n",
    "            out = model(x)\n",
    "            pred = torch.argmax(out, dim = -1)\n",
    "            y_pred += pred.cpu().tolist()\n",
    "\n",
    "    log(\"Accuracy : \" + str(accuracy_score(y_true, y_pred)) +\n",
    "        \"\\nWeighted F1 : \" + str(f1_score(y_true, y_pred, labels=list(range(args.num_labels)),average='weighted')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b58b696-1cfe-48d4-a3ca-077683206d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 2941078\n"
     ]
    }
   ],
   "source": [
    "if args.model == 'UniTS':\n",
    "    model = UniTS(input_size = args.input_size, sensor_num = args.input_channel, layer_num = config.layer_num,\n",
    "    window_list = config.window_list,  stride_list = config.stride_list, k_list = config.k_list,\n",
    "    out_dim = args.num_labels, hidden_channel = config.hidden_channel).cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "# elif args.model == 'static':\n",
    "#     model = static_UniTS(input_size = args.input_size, sensor_num = args.input_channel, layer_num = config.layer_num,\n",
    "#     window_list = config.window_list, stride_list = config.stride_list, k_list = config.k_list,\n",
    "#     out_dim = args.num_labels, hidden_channel = config.hidden_channel).cuda()\n",
    "\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "# elif args.model == 'THAT':\n",
    "#     args.hlayers = 5\n",
    "#     args.vlayers = 1\n",
    "#     args.vheads = 16\n",
    "#     args.K = 10\n",
    "#     args.sample = 4\n",
    "#     model = HARTrans(args).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# elif args.model == 'RFNet':\n",
    "#     model = RFNet(num_classes = args.num_labels, input_channel = args.input_channel, win_len = args.input_size).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "# elif args.model == 'ResNet':\n",
    "#     model = ResNet(input_size = args.input_size, input_channel = args.input_channel, num_label = args.num_labels).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)        \n",
    "\n",
    "# elif args.model == 'MaDNN':\n",
    "#     model = MaDNN(input_size = args.input_size, input_channel = args.input_channel, num_label = args.num_labels).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)   \n",
    "\n",
    "# elif args.model == 'MaCNN':\n",
    "#     model = MaCNN(input_size = args.input_size, input_channel = args.input_channel, num_label = args.num_labels, \n",
    "#         sensor_num = int(args.input_channel / args.SENSOR_AXIS)).cuda()\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "# elif args.model == 'LaxCat':\n",
    "#     model = LaxCat(input_size = args.input_size, input_channel = args.input_channel, num_label = args.num_labels,\n",
    "#         hidden_dim = 64, kernel_size = 32, stride = 8).cuda()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "log('Total parameters: ' + str(total_params))\n",
    "\n",
    "if args.test_only:\n",
    "    if os.path.exists(args.model_save_path):\n",
    "        model.load_state_dict(torch.load(args.model_save_path))\n",
    "        # changing while testing\n",
    "        test(model, xtest, ytest)\n",
    "        #test(model, xtest, ytest,sigma=[0.3, 60, 80])\n",
    "\n",
    "    else:\n",
    "        log(\"Model state dict not found!\")\n",
    "    # return\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d6a4c79",
   "metadata": {},
   "source": [
    "To load path during testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10c360f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(args.model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b898a721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['ts_encoders.0.FIC.conv.weight', 'ts_encoders.0.RPC.weight', 'ts_encoders.0.RPC.bias', 'ts_encoders.1.FIC.conv.weight', 'ts_encoders.1.RPC.weight', 'ts_encoders.1.RPC.bias', 'ts_encoders.2.FIC.conv.weight', 'ts_encoders.2.RPC.weight', 'ts_encoders.2.RPC.bias', 'ts_encoders.3.FIC.conv.weight', 'ts_encoders.3.RPC.weight', 'ts_encoders.3.RPC.bias', 'ts_encoders.4.FIC.conv.weight', 'ts_encoders.4.RPC.weight', 'ts_encoders.4.RPC.bias', 'ts_encoders.5.FIC.conv.weight', 'ts_encoders.5.RPC.weight', 'ts_encoders.5.RPC.bias', 'ts_encoders.6.FIC.conv.weight', 'ts_encoders.6.RPC.weight', 'ts_encoders.6.RPC.bias', 'ts_encoders.7.FIC.conv.weight', 'ts_encoders.7.RPC.weight', 'ts_encoders.7.RPC.bias', 'ts_encoders.8.FIC.conv.weight', 'ts_encoders.8.RPC.weight', 'ts_encoders.8.RPC.bias', 'multi_channel_fusion.0.weight', 'multi_channel_fusion.0.bias', 'multi_channel_fusion.1.weight', 'multi_channel_fusion.1.bias', 'multi_channel_fusion.2.weight', 'multi_channel_fusion.2.bias', 'multi_channel_fusion.3.weight', 'multi_channel_fusion.3.bias', 'multi_channel_fusion.4.weight', 'multi_channel_fusion.4.bias', 'multi_channel_fusion.5.weight', 'multi_channel_fusion.5.bias', 'multi_channel_fusion.6.weight', 'multi_channel_fusion.6.bias', 'multi_channel_fusion.7.weight', 'multi_channel_fusion.7.bias', 'multi_channel_fusion.8.weight', 'multi_channel_fusion.8.bias', 'conv_branches.0.0.conv1.0.weight', 'conv_branches.0.0.conv1.0.bias', 'conv_branches.0.0.bn1.0.weight', 'conv_branches.0.0.bn1.0.bias', 'conv_branches.0.0.bn1.0.running_mean', 'conv_branches.0.0.bn1.0.running_var', 'conv_branches.0.0.bn1.0.num_batches_tracked', 'conv_branches.0.0.conv2.0.weight', 'conv_branches.0.0.conv2.0.bias', 'conv_branches.0.0.bn2.0.weight', 'conv_branches.0.0.bn2.0.bias', 'conv_branches.0.0.bn2.0.running_mean', 'conv_branches.0.0.bn2.0.running_var', 'conv_branches.0.0.bn2.0.num_batches_tracked', 'conv_branches.0.1.weight', 'conv_branches.0.1.bias', 'conv_branches.0.3.conv1.0.weight', 'conv_branches.0.3.conv1.0.bias', 'conv_branches.0.3.bn1.0.weight', 'conv_branches.0.3.bn1.0.bias', 'conv_branches.0.3.bn1.0.running_mean', 'conv_branches.0.3.bn1.0.running_var', 'conv_branches.0.3.bn1.0.num_batches_tracked', 'conv_branches.0.3.conv2.0.weight', 'conv_branches.0.3.conv2.0.bias', 'conv_branches.0.3.bn2.0.weight', 'conv_branches.0.3.bn2.0.bias', 'conv_branches.0.3.bn2.0.running_mean', 'conv_branches.0.3.bn2.0.running_var', 'conv_branches.0.3.bn2.0.num_batches_tracked', 'conv_branches.0.5.conv1.0.weight', 'conv_branches.0.5.conv1.0.bias', 'conv_branches.0.5.bn1.0.weight', 'conv_branches.0.5.bn1.0.bias', 'conv_branches.0.5.bn1.0.running_mean', 'conv_branches.0.5.bn1.0.running_var', 'conv_branches.0.5.bn1.0.num_batches_tracked', 'conv_branches.0.5.conv2.0.weight', 'conv_branches.0.5.conv2.0.bias', 'conv_branches.0.5.bn2.0.weight', 'conv_branches.0.5.bn2.0.bias', 'conv_branches.0.5.bn2.0.running_mean', 'conv_branches.0.5.bn2.0.running_var', 'conv_branches.0.5.bn2.0.num_batches_tracked', 'conv_branches.0.7.conv1.0.weight', 'conv_branches.0.7.conv1.0.bias', 'conv_branches.0.7.bn1.0.weight', 'conv_branches.0.7.bn1.0.bias', 'conv_branches.0.7.bn1.0.running_mean', 'conv_branches.0.7.bn1.0.running_var', 'conv_branches.0.7.bn1.0.num_batches_tracked', 'conv_branches.0.7.conv2.0.weight', 'conv_branches.0.7.conv2.0.bias', 'conv_branches.0.7.bn2.0.weight', 'conv_branches.0.7.bn2.0.bias', 'conv_branches.0.7.bn2.0.running_mean', 'conv_branches.0.7.bn2.0.running_var', 'conv_branches.0.7.bn2.0.num_batches_tracked', 'conv_branches.0.9.conv1.0.weight', 'conv_branches.0.9.conv1.0.bias', 'conv_branches.0.9.bn1.0.weight', 'conv_branches.0.9.bn1.0.bias', 'conv_branches.0.9.bn1.0.running_mean', 'conv_branches.0.9.bn1.0.running_var', 'conv_branches.0.9.bn1.0.num_batches_tracked', 'conv_branches.0.9.conv2.0.weight', 'conv_branches.0.9.conv2.0.bias', 'conv_branches.0.9.bn2.0.weight', 'conv_branches.0.9.bn2.0.bias', 'conv_branches.0.9.bn2.0.running_mean', 'conv_branches.0.9.bn2.0.running_var', 'conv_branches.0.9.bn2.0.num_batches_tracked', 'conv_branches.1.0.conv1.0.weight', 'conv_branches.1.0.conv1.0.bias', 'conv_branches.1.0.bn1.0.weight', 'conv_branches.1.0.bn1.0.bias', 'conv_branches.1.0.bn1.0.running_mean', 'conv_branches.1.0.bn1.0.running_var', 'conv_branches.1.0.bn1.0.num_batches_tracked', 'conv_branches.1.0.conv2.0.weight', 'conv_branches.1.0.conv2.0.bias', 'conv_branches.1.0.bn2.0.weight', 'conv_branches.1.0.bn2.0.bias', 'conv_branches.1.0.bn2.0.running_mean', 'conv_branches.1.0.bn2.0.running_var', 'conv_branches.1.0.bn2.0.num_batches_tracked', 'conv_branches.1.1.weight', 'conv_branches.1.1.bias', 'conv_branches.1.3.conv1.0.weight', 'conv_branches.1.3.conv1.0.bias', 'conv_branches.1.3.bn1.0.weight', 'conv_branches.1.3.bn1.0.bias', 'conv_branches.1.3.bn1.0.running_mean', 'conv_branches.1.3.bn1.0.running_var', 'conv_branches.1.3.bn1.0.num_batches_tracked', 'conv_branches.1.3.conv2.0.weight', 'conv_branches.1.3.conv2.0.bias', 'conv_branches.1.3.bn2.0.weight', 'conv_branches.1.3.bn2.0.bias', 'conv_branches.1.3.bn2.0.running_mean', 'conv_branches.1.3.bn2.0.running_var', 'conv_branches.1.3.bn2.0.num_batches_tracked', 'conv_branches.1.5.conv1.0.weight', 'conv_branches.1.5.conv1.0.bias', 'conv_branches.1.5.bn1.0.weight', 'conv_branches.1.5.bn1.0.bias', 'conv_branches.1.5.bn1.0.running_mean', 'conv_branches.1.5.bn1.0.running_var', 'conv_branches.1.5.bn1.0.num_batches_tracked', 'conv_branches.1.5.conv2.0.weight', 'conv_branches.1.5.conv2.0.bias', 'conv_branches.1.5.bn2.0.weight', 'conv_branches.1.5.bn2.0.bias', 'conv_branches.1.5.bn2.0.running_mean', 'conv_branches.1.5.bn2.0.running_var', 'conv_branches.1.5.bn2.0.num_batches_tracked', 'conv_branches.2.0.conv1.0.weight', 'conv_branches.2.0.conv1.0.bias', 'conv_branches.2.0.bn1.0.weight', 'conv_branches.2.0.bn1.0.bias', 'conv_branches.2.0.bn1.0.running_mean', 'conv_branches.2.0.bn1.0.running_var', 'conv_branches.2.0.bn1.0.num_batches_tracked', 'conv_branches.2.0.conv2.0.weight', 'conv_branches.2.0.conv2.0.bias', 'conv_branches.2.0.bn2.0.weight', 'conv_branches.2.0.bn2.0.bias', 'conv_branches.2.0.bn2.0.running_mean', 'conv_branches.2.0.bn2.0.running_var', 'conv_branches.2.0.bn2.0.num_batches_tracked', 'conv_branches.2.1.weight', 'conv_branches.2.1.bias', 'conv_branches.2.3.conv1.0.weight', 'conv_branches.2.3.conv1.0.bias', 'conv_branches.2.3.bn1.0.weight', 'conv_branches.2.3.bn1.0.bias', 'conv_branches.2.3.bn1.0.running_mean', 'conv_branches.2.3.bn1.0.running_var', 'conv_branches.2.3.bn1.0.num_batches_tracked', 'conv_branches.2.3.conv2.0.weight', 'conv_branches.2.3.conv2.0.bias', 'conv_branches.2.3.bn2.0.weight', 'conv_branches.2.3.bn2.0.bias', 'conv_branches.2.3.bn2.0.running_mean', 'conv_branches.2.3.bn2.0.running_var', 'conv_branches.2.3.bn2.0.num_batches_tracked', 'conv_branches.3.0.conv1.0.weight', 'conv_branches.3.0.conv1.0.bias', 'conv_branches.3.0.bn1.0.weight', 'conv_branches.3.0.bn1.0.bias', 'conv_branches.3.0.bn1.0.running_mean', 'conv_branches.3.0.bn1.0.running_var', 'conv_branches.3.0.bn1.0.num_batches_tracked', 'conv_branches.3.0.conv2.0.weight', 'conv_branches.3.0.conv2.0.bias', 'conv_branches.3.0.bn2.0.weight', 'conv_branches.3.0.bn2.0.bias', 'conv_branches.3.0.bn2.0.running_mean', 'conv_branches.3.0.bn2.0.running_var', 'conv_branches.3.0.bn2.0.num_batches_tracked', 'conv_branches.3.1.weight', 'conv_branches.3.1.bias', 'conv_branches.3.3.conv1.0.weight', 'conv_branches.3.3.conv1.0.bias', 'conv_branches.3.3.bn1.0.weight', 'conv_branches.3.3.bn1.0.bias', 'conv_branches.3.3.bn1.0.running_mean', 'conv_branches.3.3.bn1.0.running_var', 'conv_branches.3.3.bn1.0.num_batches_tracked', 'conv_branches.3.3.conv2.0.weight', 'conv_branches.3.3.conv2.0.bias', 'conv_branches.3.3.bn2.0.weight', 'conv_branches.3.3.bn2.0.bias', 'conv_branches.3.3.bn2.0.running_mean', 'conv_branches.3.3.bn2.0.running_var', 'conv_branches.3.3.bn2.0.num_batches_tracked', 'conv_branches.4.0.conv1.0.weight', 'conv_branches.4.0.conv1.0.bias', 'conv_branches.4.0.bn1.0.weight', 'conv_branches.4.0.bn1.0.bias', 'conv_branches.4.0.bn1.0.running_mean', 'conv_branches.4.0.bn1.0.running_var', 'conv_branches.4.0.bn1.0.num_batches_tracked', 'conv_branches.4.0.conv2.0.weight', 'conv_branches.4.0.conv2.0.bias', 'conv_branches.4.0.bn2.0.weight', 'conv_branches.4.0.bn2.0.bias', 'conv_branches.4.0.bn2.0.running_mean', 'conv_branches.4.0.bn2.0.running_var', 'conv_branches.4.0.bn2.0.num_batches_tracked', 'conv_branches.4.1.weight', 'conv_branches.4.1.bias', 'conv_branches.5.0.conv1.0.weight', 'conv_branches.5.0.conv1.0.bias', 'conv_branches.5.0.bn1.0.weight', 'conv_branches.5.0.bn1.0.bias', 'conv_branches.5.0.bn1.0.running_mean', 'conv_branches.5.0.bn1.0.running_var', 'conv_branches.5.0.bn1.0.num_batches_tracked', 'conv_branches.5.0.conv2.0.weight', 'conv_branches.5.0.conv2.0.bias', 'conv_branches.5.0.bn2.0.weight', 'conv_branches.5.0.bn2.0.bias', 'conv_branches.5.0.bn2.0.running_mean', 'conv_branches.5.0.bn2.0.running_var', 'conv_branches.5.0.bn2.0.num_batches_tracked', 'conv_branches.5.1.weight', 'conv_branches.5.1.bias', 'bns.0.weight', 'bns.0.bias', 'bns.0.running_mean', 'bns.0.running_var', 'bns.0.num_batches_tracked', 'bns.1.weight', 'bns.1.bias', 'bns.1.running_mean', 'bns.1.running_var', 'bns.1.num_batches_tracked', 'bns.2.weight', 'bns.2.bias', 'bns.2.running_mean', 'bns.2.running_var', 'bns.2.num_batches_tracked', 'bns.3.weight', 'bns.3.bias', 'bns.3.running_mean', 'bns.3.running_var', 'bns.3.num_batches_tracked', 'bns.4.weight', 'bns.4.bias', 'bns.4.running_mean', 'bns.4.running_var', 'bns.4.num_batches_tracked', 'bns.5.weight', 'bns.5.bias', 'bns.5.running_mean', 'bns.5.running_var', 'bns.5.num_batches_tracked', 'bns.6.weight', 'bns.6.bias', 'bns.6.running_mean', 'bns.6.running_var', 'bns.6.num_batches_tracked', 'bns.7.weight', 'bns.7.bias', 'bns.7.running_mean', 'bns.7.running_var', 'bns.7.num_batches_tracked', 'bns.8.weight', 'bns.8.bias', 'bns.8.running_mean', 'bns.8.running_var', 'bns.8.num_batches_tracked', 'end_linear.0.weight', 'end_linear.0.bias', 'end_linear.1.weight', 'end_linear.1.bias', 'end_linear.2.weight', 'end_linear.2.bias', 'end_linear.3.weight', 'end_linear.3.bias', 'end_linear.4.weight', 'end_linear.4.bias', 'end_linear.5.weight', 'end_linear.5.bias', 'end_linear.6.weight', 'end_linear.6.bias', 'end_linear.7.weight', 'end_linear.7.bias', 'end_linear.8.weight', 'end_linear.8.bias', 'classifier.weight', 'classifier.bias'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(args.model_save_path).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad2c60-ecbe-4fc1-af93-922bebd8de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(args.seed)\n",
    "# random.shuffle(xtrain)\n",
    "# random.seed(args.seed)\n",
    "# random.shuffle(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9ea90dd-d38c-414d-aa80-17c0337aa9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch : 1\n",
      "Training loss : 0.4017756482917367\n",
      "Accuracy : 0.9347700089572686\n",
      "Weighted F1 : 0.9349686140213165\n",
      "----------------------------\n",
      "Training epoch : 2\n",
      "Training loss : 0.14318107347464676\n",
      "Accuracy : 0.9603772590758206\n",
      "Weighted F1 : 0.9604980870861523\n",
      "----------------------------\n",
      "Training epoch : 3\n",
      "Training loss : 0.09118237012013379\n",
      "Accuracy : 0.9643289952052269\n",
      "Weighted F1 : 0.9643566856442122\n",
      "----------------------------\n",
      "Training epoch : 4\n",
      "Training loss : 0.06679324012248923\n",
      "Accuracy : 0.9753411665525054\n",
      "Weighted F1 : 0.9754223977915714\n",
      "----------------------------\n",
      "Training epoch : 5\n",
      "Training loss : 0.0517402682595603\n",
      "Accuracy : 0.9836134675167291\n",
      "Weighted F1 : 0.9836297500309151\n",
      "----------------------------\n",
      "Training epoch : 6\n",
      "Training loss : 0.04300300183865554\n",
      "Accuracy : 0.985299541598609\n",
      "Weighted F1 : 0.9852842866129785\n",
      "----------------------------\n",
      "Training epoch : 7\n",
      "Training loss : 0.034383821941593624\n",
      "Accuracy : 0.9851414721534327\n",
      "Weighted F1 : 0.9851596910412089\n",
      "----------------------------\n",
      "Training epoch : 8\n",
      "Training loss : 0.030896987924860318\n",
      "Accuracy : 0.985088782338374\n",
      "Weighted F1 : 0.9850742617234136\n",
      "----------------------------\n",
      "Training epoch : 9\n",
      "Training loss : 0.025751520577629753\n",
      "Accuracy : 0.9858791295642553\n",
      "Weighted F1 : 0.9858854895202602\n",
      "----------------------------\n",
      "Training epoch : 10\n",
      "Training loss : 0.02502993965762867\n",
      "Accuracy : 0.986142578639549\n",
      "Weighted F1 : 0.9861335353034344\n",
      "----------------------------\n",
      "Training epoch : 11\n",
      "Training loss : 0.021645194261104898\n",
      "Accuracy : 0.987617893461194\n",
      "Weighted F1 : 0.9876194402590688\n",
      "----------------------------\n",
      "Training epoch : 12\n",
      "Training loss : 0.01829344288038212\n",
      "Accuracy : 0.9864587175299014\n",
      "Weighted F1 : 0.9864449574403066\n",
      "----------------------------\n",
      "Training epoch : 13\n",
      "Training loss : 0.01851635491210384\n",
      "Accuracy : 0.9913061805153064\n",
      "Weighted F1 : 0.991308772126746\n",
      "----------------------------\n",
      "Training epoch : 14\n",
      "Training loss : 0.0176923880508345\n",
      "Accuracy : 0.9875125138310764\n",
      "Weighted F1 : 0.9875126094075722\n",
      "----------------------------\n",
      "Training epoch : 15\n",
      "Training loss : 0.01381040200276318\n",
      "Accuracy : 0.9875125138310764\n",
      "Weighted F1 : 0.9875498996573528\n",
      "----------------------------\n",
      "Training epoch : 16\n",
      "Training loss : 0.014946886298280383\n",
      "Accuracy : 0.9922545971863639\n",
      "Weighted F1 : 0.992247635909963\n",
      "----------------------------\n",
      "Training epoch : 17\n",
      "Training loss : 0.012457529672908134\n",
      "Accuracy : 0.9929922545971863\n",
      "Weighted F1 : 0.9929938814892462\n",
      "----------------------------\n",
      "Training epoch : 18\n",
      "Training loss : 0.014402994349779779\n",
      "Accuracy : 0.9911481110701301\n",
      "Weighted F1 : 0.9911473743129711\n",
      "----------------------------\n",
      "Training epoch : 19\n",
      "Training loss : 0.010561023428179108\n",
      "Accuracy : 0.9917803888508351\n",
      "Weighted F1 : 0.9917777834365638\n",
      "----------------------------\n",
      "Training epoch : 20\n",
      "Training loss : 0.012361439702565381\n",
      "Accuracy : 0.9926761157068339\n",
      "Weighted F1 : 0.9926707400879264\n",
      "----------------------------\n",
      "Training epoch : 21\n",
      "Training loss : 0.009478341120214886\n",
      "Accuracy : 0.9909900416249539\n",
      "Weighted F1 : 0.990998573028626\n",
      "----------------------------\n",
      "Training epoch : 22\n",
      "Training loss : 0.010136113858654542\n",
      "Accuracy : 0.9871436851256652\n",
      "Weighted F1 : 0.9871916804406277\n",
      "----------------------------\n",
      "Training epoch : 23\n",
      "Training loss : 0.010294760263253868\n",
      "Accuracy : 0.9912008008851889\n",
      "Weighted F1 : 0.9911989289805017\n",
      "----------------------------\n",
      "Training epoch : 24\n",
      "Training loss : 0.00825404719852143\n",
      "Accuracy : 0.9938352916381263\n",
      "Weighted F1 : 0.9938379203973466\n",
      "----------------------------\n",
      "Training epoch : 25\n",
      "Training loss : 0.010367294995628992\n",
      "Accuracy : 0.9914642499604827\n",
      "Weighted F1 : 0.9914652181280481\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "try:\n",
    "    for ep in range(1, 1+args.epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        log(\"Training epoch : \" + str(ep))\n",
    "        for i in range(0, len(xtrain), args.batch_size):\n",
    "            if i + args.batch_size <= len(xtrain):\n",
    "                x = torch.Tensor(xtrain[i: i+args.batch_size]).cuda()\n",
    "\n",
    "                y = torch.LongTensor(ytrain[i: i+args.batch_size]).cuda()  \n",
    "            else:\n",
    "                x = torch.Tensor(xtrain[i:]).cuda()\n",
    "                y = torch.LongTensor(ytrain[i:]).cuda()                      \n",
    "            out = model(x)\n",
    "            loss = loss_func(out, y)\n",
    "            epoch_loss += loss.cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()           \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        log(\"Training loss : \" + str(epoch_loss / (i / args.batch_size + 1)))\n",
    "        # change while training, sigma value is passed here\n",
    "        #test(model, xtrain, ytrain,sigma=0.2)\n",
    "        test(model, xtest, ytest)\n",
    "\n",
    "        #test(model, xtest, ytest,sigma=[0.2, 50,80])\n",
    "\n",
    "        log(\"----------------------------\")\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Exiting from training early')\n",
    "    test(model, xtest, ytest)\n",
    "if args.save:\n",
    "    torch.save(model.state_dict(), args.model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed1c8c2e-c9a3-43f6-9903-6390cbdd8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), args.model_save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9810de09",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d927b8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9905158332894252\n",
      "Weighted F1 : 0.9905164607783523\n"
     ]
    }
   ],
   "source": [
    "#xtest_eval = corrupt1(Xtest,sigma=0.05)\n",
    "xtest_eval = corrupt3(Xtest,sigma=[0.2, 60, 80])\n",
    "\n",
    "\n",
    "test(model, xtest_eval, ytest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
