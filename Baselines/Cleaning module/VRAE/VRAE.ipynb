{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeseries clustering\n",
    "\n",
    "Time series clustering is to partition time series data into groups based on similarity or distance, so that time series in the same cluster are similar.\n",
    "\n",
    "Methodology followed:\n",
    "* Use Variational Recurrent AutoEncoder (VRAE) for dimensionality reduction of the timeseries\n",
    "* To visualize the clusters, PCA and t-sne are used\n",
    "\n",
    "Paper:\n",
    "https://arxiv.org/pdf/1412.6581.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents\n",
    "\n",
    "0. [Load data and preprocess](#Load-data-and-preprocess)\n",
    "1. [Initialize VRAE object](#Initialize-VRAE-object)\n",
    "2. [Fit the model onto dataset](#Fit-the-model-onto-dataset)\n",
    "3. [Transform the input timeseries to encoded latent vectors](#Transform-the-input-timeseries-to-encoded-latent-vectors)\n",
    "4. [Save the model to be fetched later](#Save-the-model-to-be-fetched-later)\n",
    "5. [Visualize using PCA and tSNE](#Visualize-using-PCA-and-tSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "# HTML('''<script>\n",
    "# code_show=true; \n",
    "# function code_toggle() {\n",
    "# if (code_show){\n",
    "# $('div.input').hide();\n",
    "# } else {\n",
    "# $('div.input').show();\n",
    "# }\n",
    "# code_show = !code_show\n",
    "# } \n",
    "# $( document ).ready(code_toggle);\n",
    "# </script>\n",
    "# <form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from vrae.vrae import VRAE\n",
    "from vrae.utils import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 2\n",
    "\n",
    "if gpu_id>=0:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    cuda_id = \"cuda:\" + str(0)  # cuda:2\n",
    "\n",
    "device = torch.device(cuda_id if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.set_device(cuda_id)\n",
    "    print(\"Current GPU ID:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dload = './model_dir' #download directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 90\n",
    "hidden_layer_depth = 1\n",
    "latent_length = 20\n",
    "batch_size = 64\n",
    "learning_rate = 0.0005\n",
    "n_epochs = 600\n",
    "dropout_rate = 0\n",
    "optimizer = 'Adam' # options: ADAM, SGD\n",
    "cuda = True # options: True, False\n",
    "print_every=30\n",
    "clip = False # options: True, False\n",
    "max_grad_norm=5\n",
    "loss = 'MSELoss' # options: SmoothL1Loss, MSELoss\n",
    "block = 'LSTM' # options: LSTM, GRU\n",
    "\n",
    "corr = 'Both' # options: Gaussian, ZeroMask, ConsecutiveZeros, Both\n",
    "sigma = 0.35 # 0.1\n",
    "if corr == 'ConsecutiveZeros':\n",
    "    sigma = [50, 80] # [lambda_corr, lambda_norm]\n",
    "if corr == 'Both':\n",
    "    sigma = [0.1, 30, 80]\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(args.random_seed)\n",
    "np.random.seed(seed)\n",
    "# generator = torch.Generator()\n",
    "# generator.manual_seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 512 # 512\n",
    "stride_len = 20 # 100\n",
    "act_list = [1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24]\n",
    "# act_list = [1, 2]\n",
    "act_labels_txt = ['lay', 'sit', 'std', 'wlk', 'run', 'cyc', 'nord', 'ups', 'dws', 'vac', 'iron', 'rop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "user_labels=[]\n",
    "act_labels=[]\n",
    "\n",
    "# columns for IMU data\n",
    "# 4-20 IMU hand\n",
    "# 21-37 IMU chest\n",
    "# 38-54 IMU ankle\n",
    "# 2-4 3D-acceleration data (ms-2), scale: ±16g, resolution: 13-bit\n",
    "# 8-10 3D-gyroscope data (rad/s)\n",
    "# 11-13 3D-magnetometer data (μT)\n",
    "imu_locs = [4,5,6, 10,11,12, 13,14,15, \n",
    "            21,22,23, 27,28,29, 30,31,32, \n",
    "            38,39,40, 44,45,46, 47,48,49\n",
    "           ] \n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "for uid in np.arange(1,10):\n",
    "    path = '../../PAMAP2_Dataset/Protocol/subject10' + str(uid) + '.dat'\n",
    "    df = pd.read_table(path, sep=' ', header=None)\n",
    "    act_imu_filter = df.iloc[:, imu_locs] \n",
    "\n",
    "\n",
    "    for act_id in range(len(act_list)):\n",
    "        act_filter =  act_imu_filter[df.iloc[:, 1] == act_list[act_id]]\n",
    "        act_data = act_filter.to_numpy()\n",
    "        act_data = np.transpose(act_data)\n",
    "\n",
    "        # sliding window segmentation\n",
    "        start_idx = 0\n",
    "        while start_idx + window_len < act_data.shape[1]:\n",
    "            window_data = act_data[:, start_idx:start_idx+window_len]\n",
    "            downsamp_data = window_data[:, ::3] # downsample from 100hz to 33.3hz\n",
    "            downsamp_data = np.nan_to_num(downsamp_data) # remove nan\n",
    "            # downsamp_data = np.transpose(downsamp_data) # dim: seq_len, feature_len\n",
    "\n",
    "            X.append(downsamp_data)\n",
    "            user_labels.append(uid)\n",
    "            act_labels.append(act_id)\n",
    "            start_idx = start_idx + stride_len\n",
    "            \n",
    "X = np.array(X).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X = np.zeros_like(X)\n",
    "for ch_id in range(X.shape[1]):\n",
    "    ch_data = X[:, ch_id, :]\n",
    "    scaler = MinMaxScaler()\n",
    "    ch_data = scaler.fit_transform(ch_data)\n",
    "    normalized_X[:, ch_id, :] = ch_data\n",
    "X = np.transpose(normalized_X, (0, 2, 1)) # num_samples, sequence_length, feature_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.reshape(X.shape[0], 1, X.shape[1], X.shape[2]) # convert list to numpy array\n",
    "act_labels = np.array(act_labels).astype('float32')\n",
    "act_labels = act_labels.reshape(act_labels.shape[0],1)\n",
    "act_labels = to_categorical(act_labels, num_classes=len(act_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(act_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.from_numpy(X), torch.from_numpy(act_labels))\n",
    "\n",
    "# Train/Test dataset split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(train_dataset,\n",
    "    batch_size=batch_size, shuffle=True) \n",
    "\n",
    "testLoader = torch.utils.data.DataLoader(test_dataset,\n",
    "    batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = X.shape[1]\n",
    "number_of_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequence_length)\n",
    "print(number_of_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize VRAE object\n",
    "\n",
    "VRAE inherits from `sklearn.base.BaseEstimator` and overrides `fit`, `transform` and `fit_transform` functions, similar to sklearn modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 5*1e-4\n",
    "vrae = VRAE(sequence_length=sequence_length,\n",
    "            number_of_features = number_of_features,\n",
    "            corr = corr,\n",
    "            sigma = sigma,\n",
    "            hidden_size = hidden_size, \n",
    "            hidden_layer_depth = hidden_layer_depth,\n",
    "            latent_length = latent_length,\n",
    "            batch_size = batch_size,\n",
    "            learning_rate = learning_rate,\n",
    "            n_epochs = n_epochs,\n",
    "            dropout_rate = dropout_rate,\n",
    "            optimizer = optimizer, \n",
    "            cuda = cuda,\n",
    "            print_every=print_every, \n",
    "            clip=clip, \n",
    "            max_grad_norm=max_grad_norm,\n",
    "            loss = loss,\n",
    "            block = block,\n",
    "            dload = dload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model onto dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "vrae.fit(train_dataset)\n",
    "\n",
    "# If the model has to be saved, with the learnt parameters use:\n",
    "# model saving during training to be implemented, use manual saving in the next block\n",
    "# vrae.fit(dataset, save = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model to be fetched later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save VRAE model\n",
    "model_name = 'vrae_' + corr\n",
    "for v in sigma:\n",
    "    model_name += '_' + str(v)\n",
    "model_name += '.pth'\n",
    "\n",
    "vrae.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VRAE model from pth file\n",
    "model_name = 'vrae_' + corr\n",
    "for v in sigma:\n",
    "    model_name += '_' + str(v)\n",
    "model_name += '.pth'\n",
    "\n",
    "vrae.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare testdata set, drop the last incomplete batch\n",
    "test_x = torch.zeros(len(test_dataset)-35, X.shape[1], X.shape[2])\n",
    "test_labels = torch.zeros(len(test_dataset)-35, len(act_list))\n",
    "for test_id in range(len(test_dataset)-35):\n",
    "    test_labels[test_id] = test_dataset[test_id][1]\n",
    "    test_x[test_id] = test_dataset[test_id][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrupt Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_test_x = vrae.encoder.corrupt(test_x.permute(1,0,2)) # Corruption process is different than used in reconstruction\n",
    "corr_test_x = corr_test_x.permute(1,0,2) # N*171*27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct testset (synthesize the entire data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_last_test_dataset = TensorDataset(test_x.permute(0, 2, 1))\n",
    "# corr_test_dataset = TensorDataset(corr_test_x.permute(0,2,1))\n",
    "corr_test_dataset = TensorDataset(corr_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_recon_test = vrae.reconstruct(corr_test_dataset)\n",
    "recon_test = torch.from_numpy(np_recon_test).permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct filling testset (fills missing values only, not valid for noisy data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_fill_test = copy.deepcopy(corr_test_x.cpu().numpy())\n",
    "np.copyto(recon_fill_test, recon_test.cpu().numpy(), where = recon_fill_test==0)\n",
    "recon_fill_test = torch.from_numpy(recon_fill_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean-Filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fill_test = copy.deepcopy(corr_test_x).detach().cpu().numpy()\n",
    "for i in range(mean_fill_test.shape[0]):\n",
    "    for j in range(mean_fill_test.shape[2]):\n",
    "        if np.count_nonzero(mean_fill_test[i,:,j]) == 0: # when all data points in this channel are missing\n",
    "            ch_mean = 0\n",
    "        else:\n",
    "            ch_mean = np.sum(mean_fill_test[i,:,j]) / np.count_nonzero(mean_fill_test[i,:,j])\n",
    "        mean_fill_test[i, mean_fill_test[i,:,j] == 0, j] = ch_mean\n",
    "mean_fill_test = torch.from_numpy(mean_fill_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_interp_test = copy.deepcopy(corr_test_x).detach().cpu().numpy()\n",
    "for i in range(linear_interp_test.shape[0]):\n",
    "    for j in range(linear_interp_test.shape[2]):\n",
    "        if np.count_nonzero(linear_interp_test[i,:,j]) == 0: # when all data points in this channel are missing\n",
    "            linear_interp_test[i, :, j] = 0.0\n",
    "        else:\n",
    "            idxs = np.arange(linear_interp_test.shape[1]) # indexes of all the samples\n",
    "            zero_filter = linear_interp_test[i,:,j] == 0 # index filter for zero values\n",
    "            zero_idxs = idxs[zero_filter] # indexes for zero values\n",
    "            non_zero_idxs = idxs[~zero_filter] # xp, indexes for non-zero values\n",
    "            non_zero_vals = linear_interp_test[i, ~zero_filter, j] # fp, non-zero values\n",
    "            interp_vals = np.interp(zero_idxs, non_zero_idxs, non_zero_vals) # interpolated values\n",
    "            linear_interp_test[i,zero_idxs,j] = interp_vals # fill interpolated values to the corrupted signal\n",
    "linear_interp_test = torch.from_numpy(linear_interp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1).cpu().numpy(), corr_test_x.reshape(corr_test_x.shape[0],-1).cpu().numpy(), squared=False)\n",
    "print('Corr RMSE:\\n' + str(corr_rms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1).cpu().numpy(), recon_test.reshape(recon_test.shape[0],-1).cpu().numpy(), squared=False)\n",
    "print('Recon RMSE:\\n' + str(recon_rms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_fill_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1).cpu().numpy(), recon_fill_test.reshape(recon_fill_test.shape[0],-1).cpu().numpy(), squared=False)\n",
    "print('Recon Fill RMSE:\\n' + str(recon_fill_rms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fill_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1), mean_fill_test.reshape(mean_fill_test.shape[0],-1).cpu().numpy(), squared=False)\n",
    "print('Mean Fill RMSE:\\n' + str(mean_fill_rms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_interp_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1), linear_interp_test.reshape(linear_interp_test.shape[0],-1).cpu().numpy(), squared=False)\n",
    "print('Linear Interpolation RMSE:\\n' + str(linear_interp_rms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = 0\n",
    "\n",
    "plt.imshow(test_x[data_id])\n",
    "plt.title('Raw Data')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(corr_test_x[data_id])\n",
    "plt.title('Corrupted')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(recon_test[data_id])\n",
    "plt.title('Reconstructed')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(recon_fill_test[data_id])\n",
    "plt.title('Recon Fill')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mean_fill_test[data_id])\n",
    "plt.title('Mean Fill')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(linear_interp_test[data_id])\n",
    "plt.title('Linear Interpolation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import HAR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_har import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_har = get_eval_model(len(act_list), model_path='pamap2_cnn.pt').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate HAR accuracy for raw data, corrupted data, and reconstructed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from N*171*27 into N*27*171\n",
    "test_x = test_x.permute(0,2,1)\n",
    "corr_test_x = corr_test_x.permute(0,2,1)\n",
    "recon_test = recon_test.permute(0,2,1)\n",
    "recon_fill_test = recon_fill_test.permute(0,2,1)\n",
    "mean_fill_test = mean_fill_test.permute(0,2,1)\n",
    "linear_interp_test = linear_interp_test.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend one dummy dimension for CNN\n",
    "raw_test_dataset = TensorDataset(test_x.reshape(test_x.shape[0], 1, test_x.shape[1], test_x.shape[2]), test_labels)\n",
    "corr_test_dataset = TensorDataset(corr_test_x.reshape(corr_test_x.shape[0], 1, corr_test_x.shape[1], corr_test_x.shape[2]), test_labels)\n",
    "recon_test_dataset = TensorDataset(recon_test.reshape(recon_test.shape[0], 1, recon_test.shape[1], recon_test.shape[2]), test_labels)\n",
    "recon_fill_test_dataset = TensorDataset(recon_fill_test.reshape(recon_fill_test.shape[0], 1, recon_fill_test.shape[1], recon_fill_test.shape[2]), test_labels)\n",
    "mean_fill_test_dataset = TensorDataset(mean_fill_test.reshape(mean_fill_test.shape[0], 1, mean_fill_test.shape[1], mean_fill_test.shape[2]), test_labels)\n",
    "linear_interp_test_dataset = TensorDataset(linear_interp_test.reshape(linear_interp_test.shape[0], 1, linear_interp_test.shape[1], linear_interp_test.shape[2]), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_har(test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_true = []\n",
    "    total_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)       \n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = eval_har(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # predicted = torch.argmax(outputs.data.cpu(), axis=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "            \n",
    "            total_pred = total_pred + predicted.cpu().numpy().tolist()\n",
    "            total_true = total_true + (torch.argmax(labels, dim=1).cpu().numpy().tolist())\n",
    "            \n",
    "    print(f'Test Accuracy: {100.0 * correct / total} %')\n",
    "    \n",
    "    print(\" | \".join(act_labels_txt))\n",
    "    conf_mat = confusion_matrix(y_true = total_true, y_pred = total_pred)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "    print(np.array(conf_mat).round(3) * 100)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Raw testset:\")\n",
    "raw_test_loader = torch.utils.data.DataLoader(raw_test_dataset,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "\n",
    "evaluate_har(raw_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Corrupted testset:\")\n",
    "corr_test_loader = torch.utils.data.DataLoader(corr_test_dataset,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "evaluate_har(corr_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reconstructed testset:\")\n",
    "recon_test_loader = torch.utils.data.DataLoader(recon_test_dataset,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "evaluate_har(recon_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recon Fill testset:\")\n",
    "recon_fill_test_loader = torch.utils.data.DataLoader(recon_fill_test_dataset,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "evaluate_har(recon_fill_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Fill testset:\")\n",
    "mean_fill_test_loader = torch.utils.data.DataLoader(mean_fill_test_dataset,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "evaluate_har(mean_fill_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear Interpolation testset:\")\n",
    "linear_interp_test_loader = torch.utils.data.DataLoader(linear_interp_test_dataset,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "evaluate_har(linear_interp_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot test data for each activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_np = torch.argmax(test_labels, dim=1).detach().cpu().numpy() # labels of testset, not one-hot\n",
    "idx_list = np.arange(len(test_labels_np)) # list for indexes of all testset\n",
    "rand_act_idxs = [] \n",
    "# randomly select a data sample for each activity\n",
    "for act_id in range(len(act_list)):\n",
    "    act_filter = test_labels_np[:] == act_id # f\n",
    "    act_idx_list = idx_list[act_filter]\n",
    "    rand_act_id = np.random.choice(act_list)\n",
    "    rand_act_idxs.append(rand_act_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(50, 25))\n",
    "\n",
    "for act_id in range(len(rand_act_idxs)):\n",
    "    ax1 = fig.add_subplot(12,5,1+5*act_id)\n",
    "    ax1.imshow(test_x[rand_act_idxs[act_id]], vmin=0, vmax=1)\n",
    "    ax1.set_title('Raw Data - ' + act_labels_txt[act_id])\n",
    "    \n",
    "    # Uncomment for plotting the difference between the target case and the raw data\n",
    "#     ax2 = fig.add_subplot(12,5,2+5*act_id)\n",
    "#     ax2.imshow(test_x[rand_act_idxs[act_id]] - corr_test_x[rand_act_idxs[act_id]], vmin=0, vmax=1)\n",
    "#     ax2.set_title('Corrupted - ' + act_labels_txt[act_id])\n",
    "    \n",
    "#     ax3 = fig.add_subplot(12,5,3+5*act_id)\n",
    "#     ax3.imshow(test_x[rand_act_idxs[act_id]] - recon_test[rand_act_idxs[act_id]], vmin=0, vmax=1)\n",
    "#     ax3.set_title('Reconstructed - ' + act_labels_txt[act_id])\n",
    "    \n",
    "#     ax4 = fig.add_subplot(12,5,4+5*act_id)\n",
    "#     ax4.imshow(test_x[rand_act_idxs[act_id]] - recon_fill_test[rand_act_idxs[act_id]], vmin=0, vmax=1)\n",
    "#     ax4.set_title('Recon Fill - ' + act_labels_txt[act_id])\n",
    "\n",
    "#     ax5 = fig.add_subplot(12,5,5+5*act_id)\n",
    "#     ax5.imshow(test_x[rand_act_idxs[act_id]] - mean_fill_test[rand_act_idxs[act_id]], vmin=0, vmax=1)\n",
    "#     ax5.set_title('Mean Fill - ' + act_labels_txt[act_id])\n",
    "\n",
    "    # Plot the target case\n",
    "    ax2 = fig.add_subplot(12,5,2+5*act_id)\n",
    "    ax2.imshow(corr_test_x[rand_act_idxs[act_id]], vmin=0, vmax=1)\n",
    "    ax2.set_title('Corrupted - ' + act_labels_txt[act_id])\n",
    "    \n",
    "    ax3 = fig.add_subplot(12,5,3+5*act_id)\n",
    "    ax3.imshow(recon_test[rand_act_idxs[act_id]], vmin=0, vmax=1)\n",
    "    ax3.set_title('Reconstructed - ' + act_labels_txt[act_id])\n",
    "    \n",
    "    ax4 = fig.add_subplot(12,5,4+5*act_id)\n",
    "    ax4.imshow(recon_fill_test[rand_act_idxs[act_id]], vmin=0, vmax=1)\n",
    "    ax4.set_title('Recon Fill - ' + act_labels_txt[act_id])\n",
    "\n",
    "    ax5 = fig.add_subplot(12,5,5+5*act_id)\n",
    "    ax5.imshow(mean_fill_test[rand_act_idxs[act_id]], vmin=0, vmax=1)\n",
    "    ax5.set_title('Mean Fill - ' + act_labels_txt[act_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the input timeseries to encoded latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_run = vrae.transform(test_dataset)\n",
    "\n",
    "# #If the latent vectors have to be saved, pass the parameter `save`\n",
    "# # z_run = vrae.transform(dataset, save = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize using PCA and tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_clustering(z_run, y_val, engine='matplotlib', download = False)\n",
    "\n",
    "# # If plotly to be used as rendering engine, uncomment below line\n",
    "# #plot_clustering(z_run, y_val, engine='plotly', download = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
