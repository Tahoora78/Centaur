{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c25dc8-18db-4931-8d8f-8a833af4c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from torch.utils.data import TensorDataset\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, f1_score\n",
    "from utils.function import *\n",
    "from models.daae_final import DAE\n",
    "from models.activity_recognition import *\n",
    "from models.dis_z import DIS_Z\n",
    "import copy\n",
    "#from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27d944f1-784f-4210-9546-deaf048b6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.root = '../data'\n",
    "        self.batchSize = 64\n",
    "        self.maxEpochs = 200\n",
    "        self.nz = 400\n",
    "        self.lr = 1e-4\n",
    "        self.fSize = 64\n",
    "        # self.outDir = 'data/experiments/DAAE_FINAL'\n",
    "        self.commit = 'eval'\n",
    "        self.alpha = 1.0\n",
    "        self.M = 5\n",
    "        self.loss = 'MSE' #'BCE'\n",
    "        self.loadDAE = False\n",
    "        # self.loadSVM = False    \n",
    "        self.load_DAE_from = None\n",
    "        self.evalMode = False\n",
    "        self.comment = ''\n",
    "        self.momentum = 0.1\n",
    "        self.c = 0.01\n",
    "        # self.svmLR = 1e-4\n",
    "        # self.Ntest = 100\n",
    "        self.multimodalZ = False\n",
    "        # self.window_len = 512\n",
    "        # self.stride_len = 20\n",
    "        # self.act_list = [1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24]\n",
    "        self.gpuNo = 2\n",
    "        self.imSize = 64\n",
    "        # self.sigma = [60, 80]\n",
    "        # self.sigma=0.25\n",
    "        self.dataset = 'OPPO' # OPPO or PAMAP2\n",
    "        self.corr = 'Gaussian'\n",
    "        self.sigma = [0.1, 3, 8]\n",
    "        self.random_seed = 0\n",
    "        self.train_split = 0.8\n",
    "\n",
    "        #self.corr= 'ZeroMask' # options: Gaussian, ZeroMask, ConsecutiveZeros\n",
    "        # if self.corr == 'ConsecutiveZeros':\n",
    "        #     self.sigma = [40, 80] # [lambda_corr, lambda_norm]\n",
    "\n",
    "        # path for corruption\"Gaussian noise for sigma=0.25\"\n",
    "        #self.dae_model_loc = \"data/experiments/DAAE1000/Ex_1\"\n",
    "\n",
    "        # path for corruption \"consecutive interval\"sigma [60,80]\n",
    "        # self.dae_model_loc = \"data/experiments/DAAE_EVAL_Noise/Ex_3\" \n",
    "        self.dae_model_loc = \"data/experiments/DAAE_FINAL/Ex_7\" \n",
    "\n",
    "        #path for corruption\"zeromask\", sigma =0.35\n",
    "        #self.dae_model_loc = \"data/experiments/DAAE1000/Ex_16\"\n",
    "\n",
    "        # self.ar_model_loc = \"data/experiments/DAAE1000/Ex_136/ar_params\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff755101-ccb9-44fb-9b83-7011f4c7ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dis(args, dae, multimodalZ):\n",
    "    if not multimodalZ:\n",
    "        print('\\n ** USING NORMAL PRIOR **')\n",
    "        prior = dae.norm_prior\n",
    "        NZ = args.nz\n",
    "    else:\n",
    "        print('\\n ** USING MULTIMODAL PRIOR **')\n",
    "        prior = dae.multi_prior\n",
    "        NZ = 2\n",
    "    dis = DIS_Z(nz=NZ, prior=prior)\n",
    "\n",
    "    return dis, NZ\n",
    "\n",
    "\n",
    "\n",
    "def analysis(args, dae, testDataset, X, num_classes):\n",
    "    # Prepare testdata set, drop the last incomplete batch\n",
    "    tail = len(testDataset) % args.batchSize\n",
    "    test_x = torch.zeros(len(testDataset)-tail, X.shape[1], X.shape[2], X.shape[3])\n",
    "    test_labels = torch.zeros(len(testDataset)-tail, num_classes)\n",
    "    for test_id in range(len(testDataset)-tail):\n",
    "        test_labels[test_id] = testDataset[test_id][1]\n",
    "        test_x[test_id] = testDataset[test_id][0]\n",
    "    #test_x = test_x.permute(0,2,1)\n",
    "    print(test_x.shape)\n",
    "\n",
    "    # Corrupt dataset\n",
    "    corr_test_x = dae.corrupt(test_x)\n",
    "    \n",
    "    mean_fill_test = interpolation_meanfilling(corr_test_x)\n",
    "    linear_interp_test = linear_interpolation(corr_test_x)\n",
    "    print(mean_fill_test.shape)\n",
    "    print(linear_interp_test.shape)\n",
    "# recon_test -> synthesize the entire dataset\n",
    "    recon_test = dae.decode(dae.encode(corr_test_x))\n",
    "\n",
    "# reconstruct filling testset (fill missing values only, not valid for noisy data)\n",
    "    recon_fill_test = copy.deepcopy(corr_test_x).detach().cpu().numpy()\n",
    "    np.copyto(recon_fill_test, recon_test.detach().numpy(), where = recon_fill_test==0)\n",
    "    recon_fill_test = torch.from_numpy(recon_fill_test)\n",
    "\n",
    "    # Reconstruct testset\n",
    "    # corr_test_dataset = TensorDataset(outputs.permute(0, 2, 1))\n",
    "    #recon_test = torch.from_numpy(recon_test)#.permute(1, 2, 0)\n",
    "\n",
    "    raw_test_dataset = TensorDataset(test_x, test_labels)\n",
    "    corr_test_dataset = TensorDataset(corr_test_x, test_labels)\n",
    "    recon_test_dataset = TensorDataset(recon_test, test_labels)\n",
    "    recon_fill_test_dataset = TensorDataset(recon_fill_test, test_labels)\n",
    "    mean_fill_test_dataset = TensorDataset(mean_fill_test, test_labels)\n",
    "    linear_interp_test_dataset = TensorDataset(linear_interp_test, test_labels)\n",
    "\n",
    "    return test_x, corr_test_x, recon_test, recon_fill_test, mean_fill_test, linear_interp_test, raw_test_dataset, corr_test_dataset, recon_test_dataset, recon_fill_test_dataset, mean_fill_test_dataset,linear_interp_test_dataset\n",
    "    #return corr_test_x, test_x, recon_test, raw_test_dataset, corr_test_dataset, recon_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac638067-7240-4159-b37b-c2532899ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation_meanfilling(corr_test_x):\n",
    "    mean_fill_test = copy.deepcopy(corr_test_x).detach().cpu().numpy()\n",
    "    for i in range(mean_fill_test.shape[0]):\n",
    "        for j in range(mean_fill_test.shape[2]):\n",
    "            if np.count_nonzero(mean_fill_test[i,:,j,:]) == 0:  \n",
    "                ch_mean = 0\n",
    "            else:\n",
    "             #ch_mean = np.sum(mean_fill_test[i][0][j]) / np.count_nonzero(mean_fill_test[i][0][j])\n",
    "                ch_mean = np.sum(mean_fill_test[i,:,j,:]) / np.count_nonzero(mean_fill_test[i,:,j,:])\n",
    "                mean_fill_test[i,:,j,:][mean_fill_test[i,:,j,:] == 0] = ch_mean\n",
    "    mean_fill_test = torch.from_numpy(mean_fill_test)\n",
    "    return mean_fill_test\n",
    "\n",
    "def linear_interpolation(corr_test_x):\n",
    "    linear_interp_test = copy.deepcopy(corr_test_x).detach().cpu().numpy()\n",
    "    # corr_text_x shape is 18944, 1, 27, 171\n",
    "    # expected shape 18944, 171, 27\n",
    "    # linear_interp_test = linear_interp_test.reshape(-1, 171,27)\n",
    "    linear_interp_test = linear_interp_test.reshape(-1, linear_interp_test.shape[3],linear_interp_test.shape[2])\n",
    "    for i in range(linear_interp_test.shape[0]):\n",
    "        for j in range(linear_interp_test.shape[2]):\n",
    "            if np.count_nonzero(linear_interp_test[i,:,j]) == 0: # when all data points in this channel are missing\n",
    "                linear_interp_test[i, :, j] = 0.0\n",
    "            else:\n",
    "                idxs = np.arange(linear_interp_test.shape[1]) # indexes of all the samples\n",
    "                zero_filter = linear_interp_test[i,:,j] == 0 # index filter for zero values\n",
    "                zero_idxs = idxs[zero_filter] # indexes for zero values\n",
    "                non_zero_idxs = idxs[~zero_filter] # xp, indexes for non-zero values\n",
    "                non_zero_vals = linear_interp_test[i, ~zero_filter,j] # fp, non-zero values\n",
    "                interp_vals = np.interp(zero_idxs, non_zero_idxs, non_zero_vals) # interpolated values\n",
    "                linear_interp_test[i,zero_idxs,j] = interp_vals # fill interpolated values to the corrupted signal\n",
    "    linear_interp_test = torch.from_numpy(linear_interp_test)\n",
    "    linear_interp_test = torch.reshape(linear_interp_test, (-1, 1, linear_interp_test.shape[2], linear_interp_test.shape[1]))\n",
    "    return linear_interp_test\n",
    "\n",
    "\n",
    "#def evaluate_rmse(corr_test_x, recon_test, test_x)\n",
    "def evaluate_rmse(corr_test_x, recon_test, recon_fill_test,mean_fill_test,linear_interp_test,test_x):\n",
    "    corr_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1).cpu().detach().numpy(), corr_test_x.reshape(corr_test_x.shape[0],-1).cpu().detach().numpy(), squared=False)\n",
    "    print('Corr RMSE:\\n' + str(corr_rms))\n",
    "\n",
    "    recon_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1).cpu().detach().numpy(), recon_test.reshape(recon_test.shape[0],-1).cpu().detach().numpy(), squared=False)\n",
    "    print('Recon RMSE:\\n' + str(recon_rms))\n",
    "\n",
    "    recon_fill_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1).cpu().detach().numpy(), recon_fill_test.reshape(recon_fill_test.shape[0],-1).cpu().detach().numpy(), squared=False)\n",
    "    print('Recon fill RMSE:\\n' + str(recon_fill_rms))\n",
    "\n",
    "    mean_fill_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1).cpu().detach().numpy(), mean_fill_test.reshape(mean_fill_test.shape[0],-1).cpu().detach().numpy(), squared=False)\n",
    "    print('Mean Fill RMSE:\\n' + str(mean_fill_rms))\n",
    "    \n",
    "    linear_interp_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1), linear_interp_test.reshape(linear_interp_test.shape[0],-1).cpu().detach().numpy(), squared=False)\n",
    "    print('Linear Interpolation RMSE:\\n' + str(linear_interp_rms))\n",
    "    return \n",
    "#def plot(test_x, corr_test_x, recon_test)\n",
    "\n",
    "def plot(test_x, corr_test_x, recon_test, recon_fill_test,mean_fill_test, linear_interp_test):\n",
    "    plt.imshow(test_x[0][0].detach())\n",
    "    plt.title('Raw Data')\n",
    "   # plt.subplot(4,1,1)\n",
    "    plt.savefig(join(args.dae_model_loc, 'raw.png'))\n",
    "\n",
    "    plt.imshow(corr_test_x[0][0].detach())\n",
    "    plt.title('Corrupted')\n",
    "   # plt.subplot(4,1,2)\n",
    "    plt.savefig(join(args.dae_model_loc, 'corr.png'))\n",
    "\n",
    "    plt.imshow(recon_test[0][0].detach())\n",
    "    plt.title('Reconstructed')\n",
    "   # plt.subplot(4,1,3)\n",
    "    plt.savefig(join(args.dae_model_loc, 'reconstructed.png'))\n",
    "\n",
    "    plt.imshow(recon_fill_test[0][0].detach())\n",
    "    plt.title('Reconstructed fill')\n",
    "   # plt.subplot(4,1,3)\n",
    "    plt.savefig(join(args.dae_model_loc, 'rec_fill.png'))\n",
    "\n",
    "    plt.imshow(mean_fill_test[0][0].detach())\n",
    "    plt.title('Mean Fill')\n",
    "   # plt.subplot(4,1,4)\n",
    "    plt.savefig(join(args.dae_model_loc, 'mean.png'))\n",
    "    \n",
    "    plt.imshow(linear_interp_test[0][0].detach())\n",
    "    plt.title('Linear Interp')\n",
    "   # plt.subplot(4,1,4)\n",
    "    plt.savefig(join(args.dae_model_loc, 'linear.png'))\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_dae(args, path, trainLoader, testLoader):\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_activity_recognition(args, path, trainLoader, testLoader):\n",
    "    pass\n",
    "\n",
    "\n",
    "def calculate_combined_accuracy(args, test_loader, sigma):\n",
    "    device = torch.device(args.gpuNo if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    #ar = ActivityRecognitionCNN(len(args.act_list))\n",
    "    ar = get_eval_model(n_sensor_channels=args.n_sensor_channels, len_seq=args.len_seq, num_classes=args.num_classes, model_path=args.ar_model_loc) #n_sensor_channels, len_seq, num_classes, model_path\n",
    "    #ar.load_state_dict(torch.load(args.ar_model_loc))\n",
    "    \n",
    "    ar.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_true = []\n",
    "    total_pred = []\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "#         for data in testLoader:\n",
    "#             # images, labels = prep_data(data, useCUDA=dae.useCUDA)\n",
    "#             images, labels = data\n",
    "#             images = images.to(device)\n",
    "#             labels = labels.to(device)\n",
    "            \n",
    "#             # calculate outputs by running images through the network\n",
    "#             outputs = ar(images)\n",
    "#             # the class with the highest energy is what we choose as prediction\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "#             #accuracy = 100 * correct // total\n",
    "#     print(f'Test Accuracy: {100 * correct / total} %')\n",
    "#     print('\\n')\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)  \n",
    "            # print(images.shape)\n",
    "            \n",
    "            # val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "            outputs = ar(images)\n",
    "\n",
    "            # _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted = torch.argmax(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "            \n",
    "            total_pred = total_pred + predicted.cpu().numpy().tolist()\n",
    "            total_true = total_true + (torch.argmax(labels, dim=1).cpu().numpy().tolist())\n",
    "            \n",
    "    print(f'Test Accuracy: {100.0 * correct / total} %')\n",
    "    \n",
    "    # print(\" | \".join(args.act_labels_txt))\n",
    "    conf_mat = confusion_matrix(y_true = total_true, y_pred = total_pred)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "    print(np.array(conf_mat).round(3) * 100)  \n",
    "    f1 = f1_score(y_true = total_true, y_pred = total_pred, average='weighted')\n",
    "    print('F1 score:', f1)\n",
    "    print('')\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7439c1-2981-41bd-88b1-1af069b44300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe668ed-2364-4e3f-86c2-da1dc345808d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd61961-f10b-4720-afe9-118da160d3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f846e27-c581-4188-a91f-50a5313dc137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ..from file ../../../../../data/oppChallenge_gestures.data\n",
      " ..reading instances: train (557963, 113), test (118750, 113)\n",
      " ..after sliding window (testing): inputs (9894, 24, 113), targets (9894,)\n",
      " ..after sliding window (training): inputs (46495, 24, 113), targets (46495,)\n",
      "loading params...\n",
      "torch.Size([9856, 1, 113, 24])\n",
      "torch.Size([9856, 1, 113, 24])\n",
      "torch.Size([9856, 1, 113, 24])\n",
      "Raw testset:\n",
      "Test Accuracy: 89.21469155844156 %\n",
      "[[79.   4.9 13.8  1.4  0.8]\n",
      " [ 0.8 93.8  4.3  1.1  0. ]\n",
      " [ 2.9 14.3 82.4  0.4  0. ]\n",
      " [ 0.6  0.6  0.  98.6  0.1]\n",
      " [ 1.5  0.   0.2  3.  95.2]]\n",
      "F1 score: 0.8912435729751317\n",
      "\n",
      "Corrupted testset:\n",
      "Test Accuracy: 67.58319805194805 %\n",
      "[[67.9  1.9 28.3  1.2  0.6]\n",
      " [ 2.5 43.9 51.4  2.2  0. ]\n",
      " [ 5.8  5.7 88.1  0.4  0. ]\n",
      " [11.1  0.8 12.  76.1  0. ]\n",
      " [ 8.4  0.2  2.8  1.9 86.6]]\n",
      "F1 score: 0.6810692389363461\n",
      "\n",
      "Reconstructed testset:\n",
      "Test Accuracy: 86.58685064935065 %\n",
      "[[72.3  7.6 16.5  2.8  0.7]\n",
      " [ 0.9 95.7  2.   1.3  0. ]\n",
      " [ 2.2 23.5 73.8  0.5  0. ]\n",
      " [ 0.4  0.9  0.  98.5  0.1]\n",
      " [ 0.4  0.   0.   1.7 97.8]]\n",
      "F1 score: 0.8630009437351089\n",
      "\n",
      "Reconstructed fill testset:\n",
      "Test Accuracy: 67.58319805194805 %\n",
      "[[67.9  1.9 28.3  1.2  0.6]\n",
      " [ 2.5 43.9 51.4  2.2  0. ]\n",
      " [ 5.8  5.7 88.1  0.4  0. ]\n",
      " [11.1  0.8 12.  76.1  0. ]\n",
      " [ 8.4  0.2  2.8  1.9 86.6]]\n",
      "F1 score: 0.6810692389363461\n",
      "\n",
      "Mean Fill testset\n",
      "Test Accuracy: 67.58319805194805 %\n",
      "[[67.9  1.9 28.3  1.2  0.6]\n",
      " [ 2.5 43.9 51.4  2.2  0. ]\n",
      " [ 5.8  5.7 88.1  0.4  0. ]\n",
      " [11.1  0.8 12.  76.1  0. ]\n",
      " [ 8.4  0.2  2.8  1.9 86.6]]\n",
      "F1 score: 0.6810692389363461\n",
      "\n",
      "Linear Interpolation testset:\n",
      "Test Accuracy: 67.58319805194805 %\n",
      "[[67.9  1.9 28.3  1.2  0.6]\n",
      " [ 2.5 43.9 51.4  2.2  0. ]\n",
      " [ 5.8  5.7 88.1  0.4  0. ]\n",
      " [11.1  0.8 12.  76.1  0. ]\n",
      " [ 8.4  0.2  2.8  1.9 86.6]]\n",
      "F1 score: 0.6810692389363461\n",
      "\n",
      "Corr RMSE:\n",
      "0.09999539\n",
      "Recon RMSE:\n",
      "0.032230828\n",
      "Recon fill RMSE:\n",
      "0.09999539\n",
      "Mean Fill RMSE:\n",
      "0.09999539\n",
      "Linear Interpolation RMSE:\n",
      "0.09999539\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = Args()\n",
    "    if args.multimodalZ:\n",
    "        args.nz = 2\n",
    "    \n",
    "    if args.dataset == 'PAMAP2':\n",
    "        args.ar_model_loc = \"data/pamap2_ConvAttn.pt\"\n",
    "        args.num_classes = 12\n",
    "        args.n_sensor_channels = 27\n",
    "        args.len_seq = 171\n",
    "        args.act_labels_txt = []\n",
    "        \n",
    "    elif args.dataset == 'OPPO':\n",
    "        args.ar_model_loc = \"data/opportunity_ConvAttn.pt\"\n",
    "        args.num_classes = 5\n",
    "        args.n_sensor_channels = 113\n",
    "        args.len_seq = 24\n",
    "        args.act_labels_txt = []\n",
    "\n",
    "        \n",
    "    # random.seed(args.random_seed)\n",
    "    # np.random.seed(args.random_seed)\n",
    "    # torch.manual_seed(args.random_seed)\n",
    "\n",
    "    # if args.dataset == 'PAMAP2':\n",
    "    #     X, labels = prepare_data(args)\n",
    "    #     trainDataset, testDataset, trainLoader, testLoader = prepare_dataloaders(args, X, labels)\n",
    "    \n",
    "    if args.dataset == 'PAMAP2':\n",
    "        X_train, X_test, y_train, y_test = prepare_data_PAMAP2(args) # x.shape = (94895, 1, 27, 171)\n",
    "        # dataset = TensorDataset(torch.from_numpy(X), torch.from_numpy(labels))\n",
    "        # Train/Test dataset split\n",
    "        # train_size = int(args.train_split * len(dataset))\n",
    "        # test_size = len(dataset) - train_size\n",
    "        # trainDataset, testDataset = torch.utils.data.random_split(dataset, [train_size, test_size])        \n",
    "    elif args.dataset == 'OPPO':\n",
    "        X_train, X_test, y_train, y_test = prepare_data_OPPO()\n",
    "    testDataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "        # trainLoader, testLoader = prepare_dataloaders_OPPO(args, X_train, X_test, y_train, y_test)        \n",
    "    \n",
    "    dae = DAE(nz=args.nz, corr=args.corr, sigma=args.sigma, dataset=args.dataset, fSize=args.fSize, multimodalZ=args.multimodalZ)\n",
    "    dae.load_params(args.dae_model_loc)\n",
    "\n",
    "    # test_dae(args, dae_path, trainLoader, testLoader)\n",
    "    # test_activity_recognition(args, ar_path, trainLoader, testLoader)\n",
    "\n",
    "    #acc = calculate_combined_accuracy(args, testLoader, sigma=0.5)\n",
    "    test_x, corr_test_x, recon_test, recon_fill_test, mean_fill_test, linear_interp_test, raw_test_dataset, corr_test_dataset, recon_test_dataset, recon_fill_test_dataset, mean_fill_test_dataset, linear_interp_test_dataset = analysis(args, dae, testDataset, X_test, args.num_classes)\n",
    "    #corr_test_x, test_x, recon_test, raw_test_dataset, corr_test_dataset, recon_test_dataset = analysis(dae, testDataset, labels)\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"Raw testset:\")\n",
    "    raw_test_loader = torch.utils.data.DataLoader(raw_test_dataset,\n",
    "    batch_size= args.batchSize, shuffle=False)\n",
    "    calculate_combined_accuracy(args, raw_test_loader, sigma=args.sigma)\n",
    "\n",
    "    print(\"Corrupted testset:\")\n",
    "    corr_test_loader = torch.utils.data.DataLoader(corr_test_dataset,\n",
    "    batch_size= args.batchSize, shuffle=False)\n",
    "    calculate_combined_accuracy(args,corr_test_loader, sigma=args.sigma)\n",
    "\n",
    "    print(\"Reconstructed testset:\")\n",
    "    recon_test_loader = torch.utils.data.DataLoader(recon_test_dataset,\n",
    "    batch_size=args.batchSize, shuffle=False)\n",
    "    calculate_combined_accuracy(args,recon_test_loader, sigma=args.sigma)\n",
    "\n",
    "\n",
    "    print(\"Reconstructed fill testset:\")\n",
    "    recon_fill_test_loader = torch.utils.data.DataLoader(recon_fill_test_dataset,\n",
    "    batch_size=args.batchSize, shuffle=False)\n",
    "    calculate_combined_accuracy(args,recon_fill_test_loader, sigma=args.sigma)\n",
    "\n",
    "\n",
    "    print(\"Mean Fill testset\")\n",
    "    mean_fill_test_loader = torch.utils.data.DataLoader(mean_fill_test_dataset,\n",
    "    batch_size=args.batchSize, shuffle=False)\n",
    "    calculate_combined_accuracy(args,mean_fill_test_loader, sigma=args.sigma)\n",
    "\n",
    "    print(\"Linear Interpolation testset:\")\n",
    "    linear_interp_test_loader = torch.utils.data.DataLoader(linear_interp_test_dataset,\n",
    "    batch_size=args.batchSize, shuffle=False)\n",
    "    calculate_combined_accuracy(args,linear_interp_test_loader, sigma=args.sigma)\n",
    "\n",
    "\n",
    "    evaluate_rmse(corr_test_x, recon_test,recon_fill_test, mean_fill_test, linear_interp_test,test_x)\n",
    "\n",
    "    plot(test_x, corr_test_x, recon_test,recon_fill_test, mean_fill_test, linear_interp_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38740a4d-b9e5-4f15-8fda-8e1f56a26a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70caf14d-7b98-45fa-b76a-67c7b109464a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cab723-d7aa-4f0a-9d48-1af0ff05c719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a3d23-b3bb-4add-8bef-d6b3f7204776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc8e4a-8f30-48d2-9575-eeb23d1aa1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f26f9-ac04-4bed-be02-ecda5e6e66a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f105479-95d0-4ede-873a-bf247659e3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06c614a-e18c-4133-a7f7-a055538779b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f1f9ee-3d05-4a2b-bf0c-5c216cc7cb53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
