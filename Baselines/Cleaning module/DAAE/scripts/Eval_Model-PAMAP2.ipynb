{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c11f73-2263-44a8-9ab6-5c4e78b53e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/home/xyang18/miniconda3/envs/pytorch/bin/ python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import WeightedRandomSampler, TensorDataset\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, BatchNorm1d, Dropout, Flatten, BCELoss\n",
    "from torch.optim import Adam, SGD\n",
    "# from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592452e-18a3-4ca4-b953-3bf3b114df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00555511-7293-4968-828b-561d95ba82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpu_id>=0:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    cuda_id = \"cuda:\" + str(0)  # cuda:2\n",
    "\n",
    "device = torch.device(cuda_id if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.set_device(cuda_id)\n",
    "    print(\"Current GPU ID:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff90bb9d-5770-44cc-9838-5f3ec86bdaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 512 # 512\n",
    "stride_len = 20 # 100\n",
    "act_list = [1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24]\n",
    "# act_list = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf03f80-c7e8-439b-82d1-ccd22adf98dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opts = get_args()\n",
    "X=[]\n",
    "user_labels=[]\n",
    "act_labels=[]\n",
    "\n",
    "# columns for IMU data\n",
    "imu_locs = [4,5,6, 10,11,12, 13,14,15, \n",
    "            21,22,23, 27,28,29, 30,31,32, \n",
    "            38,39,40, 44,45,46, 47,48,49\n",
    "           ] \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "for uid in np.arange(1,10):\n",
    "    path = '../../../PAMAP2_Dataset/Protocol/subject10' + str(uid) + '.dat'\n",
    "    df = pd.read_table(path, sep=' ', header=None)\n",
    "    act_imu_filter = df.iloc[:, imu_locs] \n",
    "\n",
    "    for act_id in range(len(act_list)):\n",
    "        act_filter =  act_imu_filter[df.iloc[:, 1] == act_list[act_id]]\n",
    "        act_data = act_filter.to_numpy()\n",
    "        if act_data.shape[0] > 0:      \n",
    "            # scaler = StandardScaler()\n",
    "            # scaler = MinMaxScaler()\n",
    "            if uid==1 and act_list[act_id] == act_list[0]:\n",
    "                scaler.fit(act_data)\n",
    "            act_data = scaler.transform(act_data)\n",
    "            \n",
    "        act_data = np.transpose(act_data)\n",
    "\n",
    "        # sliding window segmentation\n",
    "        start_idx = 0\n",
    "        while start_idx + window_len < act_data.shape[1]:\n",
    "            window_data = act_data[:, start_idx:start_idx+window_len]\n",
    "            downsamp_data = window_data[:, ::3] # downsample from 100hz to 33.3hz\n",
    "            downsamp_data = np.nan_to_num(downsamp_data) # remove nan\n",
    "\n",
    "            X.append(downsamp_data)\n",
    "            user_labels.append(uid)\n",
    "            act_labels.append(act_id)\n",
    "            start_idx = start_idx + stride_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31856f2-67aa-4118-995c-85a825d9ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).astype('float32')\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1], X.shape[2]) # convert list to numpy array\n",
    "act_labels = np.array(act_labels).astype('float32')\n",
    "act_labels = act_labels.reshape(act_labels.shape[0],1)\n",
    "act_labels = to_categorical(act_labels, num_classes=len(act_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665d9a1-3e17-43b5-b2d9-eda196cf8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Module):   \n",
    "    def __init__(self, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp_layers = Sequential(\n",
    "            Linear(256, 512), # change the first dimension based on your data\n",
    "            Dropout(0.5),\n",
    "            Linear(512, 256),\n",
    "            Dropout(0.5),\n",
    "            Linear(256, 256),\n",
    "            Linear(256, 128),\n",
    "            Dropout(0.5),\n",
    "            Linear(128, 16),\n",
    "            Dropout(0.5),\n",
    "            Linear(16, num_classes),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = torch.reshape(x, (x.shape[0], -1))\n",
    "        x = self.mlp_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2677b12a-ecf1-4e48-aafa-2a5fab0a25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel size, channel size, stride, paddings are hyper parameters and can be tuned\n",
    "class CNN(Module):   \n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(1, 64, kernel_size=[5,2], stride=1, padding=1), # change the input channel based on your data\n",
    "            # Conv2d(len(act_list), 64, kernel_size=[5,2], stride=1, padding=1), # change the input channel based on your data\n",
    "            ReLU(inplace=True),\n",
    "            BatchNorm2d(64),\n",
    "            MaxPool2d(kernel_size=[1,2]),\n",
    "            Dropout(0.25),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(64, 64, kernel_size=[5,2], stride=1, padding=1),\n",
    "            ReLU(inplace=True),\n",
    "            BatchNorm2d(64),\n",
    "            MaxPool2d(kernel_size=[1,2]),\n",
    "            Dropout(0.25),\n",
    "\n",
    "            Conv2d(64, 32, kernel_size=[5,2], stride=1, padding=1),\n",
    "            ReLU(inplace=True),\n",
    "            BatchNorm2d(32),\n",
    "            MaxPool2d(kernel_size=[1,2]),\n",
    "            Dropout(0.25),\n",
    "            Flatten(),\n",
    "            Linear(14784,128), # change the dimension based on your own data\n",
    "            ReLU(inplace=True),\n",
    "            BatchNorm1d(128),\n",
    "            Dropout(0.5),\n",
    "            Linear(128, 16),\n",
    "            ReLU(inplace=True),\n",
    "            BatchNorm1d(16),\n",
    "            Dropout(0.5),\n",
    "            Linear(16, num_classes),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        # x = torch.reshape(x, (-1, 2, 128, 1)) # change to your data dimension, the example here is 2 channel x 128 samples/channel\n",
    "        x = self.cnn_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf15862f-e1a7-4cde-acc3-4984e4a631b1",
   "metadata": {},
   "source": [
    "## Prepare your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91157c3c-6445-43b7-b86a-d91e78cfd77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795afb35-3be5-4ff2-9985-7c13efe21b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare your dataset, split into x_train, y_train, x_test, y_test\n",
    "print('Prepare data loaders...')\n",
    "\n",
    "dataset = TensorDataset(torch.from_numpy(X), torch.from_numpy(act_labels))\n",
    "\n",
    "# Train/Test dataset split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "trainDataset, testDataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainDataset,\n",
    "    batch_size=batch_size, shuffle=True) \n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testDataset,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "print('Data loaders ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb60236-8275-4b7b-92e4-7b5a58285e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_train_x = torch.from_numpy(x_train.astype('float32')) # convert from numpy array to tensor\n",
    "# tensor_train_y = torch.from_numpy(y_train.astype('float32')) # convert from numpy array to tensor\n",
    "\n",
    "# training_set = TensorDataset(tensor_train_x, tensor_train_y)\n",
    "# train_loader = list(torch.utils.data.DataLoader(training_set, batch_size=256, shuffle=True, pin_memory=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e7cc93-7904-4be0-a714-bf8156362177",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(len(act_list))\n",
    "# model = MLP(your_num_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = BCELoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "# optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "# optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dab5ca-9024-4f6f-af2e-04fa5cdbb90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        # outputs = torch.reshape(outputs, [outputs.shape[0]])\n",
    "        \n",
    "        # print(torch.argmax(outputs, dim=1))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac5606-ea17-4d94-b677-f22b20dbcf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained models\n",
    "PATH = 'pamap2_cnn.pt'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1558baf5-e103-4704-b93f-ff676ef1d90f",
   "metadata": {},
   "source": [
    "## Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa5cbf-66b4-45a4-9a9c-1bff2be02274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_test_x = torch.from_numpy(x_test.astype('float32'))\n",
    "# tensor_test_y = torch.from_numpy(y_test.astype('float32'))\n",
    "\n",
    "# test_set = TensorDataset(tensor_test_x, tensor_test_y)\n",
    "# test_loader = list(torch.utils.data.DataLoader(test_set, batch_size=512, shuffle=True, pin_memory=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46da440-2340-43d1-8e64-4247b3533f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)        \n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # print(outputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # print(predicted)\n",
    "        # predicted = torch.argmax(outputs.data.cpu(), axis=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
