{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c11f73-2263-44a8-9ab6-5c4e78b53e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/home/xyang18/miniconda3/envs/pytorch/bin/ python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle as cp\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, BatchNorm1d, Dropout, Flatten, BCELoss\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import sklearn.metrics as metrics\n",
    "from sliding_window import sliding_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00555511-7293-4968-828b-561d95ba82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id=0\n",
    "if gpu_id>=0:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    cuda_id = \"cuda:\" + str(0)  # cuda:2\n",
    "\n",
    "device = torch.device(cuda_id if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.set_device(cuda_id)\n",
    "    print(\"Current GPU ID:\", torch.cuda.current_device())\n",
    "\n",
    "## check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a2cdc1-7025-4e3d-845c-d4b4c781dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Sensor Channels used in the OPPORTUNITY dataset.\n",
    "NB_SENSOR_CHANNELS = 113\n",
    "\n",
    "# Number of classes in which data is classified (or to be classified).\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "# Length of the sliding window used to segmenting the time-series-data.\n",
    "SLIDING_WINDOW_LENGTH = 24\n",
    "\n",
    "# Steps of the sliding window used in segmenting the data.\n",
    "SLIDING_WINDOW_STEP = 12\n",
    "\n",
    "act_labels_txt = ['std', 'wlk', 'sit', 'lie', 'null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb453c5-a809-45c7-a23d-fd97db0b3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "\n",
    "    f = open(filename, 'rb')\n",
    "    data = cp.load(f)\n",
    "    f.close()\n",
    "\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    print(\" ..from file {}\".format(filename))\n",
    "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "print(\"Loading Data...\")\n",
    "X_train, y_train, X_test, y_test = load_dataset('../../data/oppChallenge_gestures.data')\n",
    "\n",
    "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
    "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
    "\n",
    "# Sensor data is segmented using a sliding window mechanism\n",
    "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "print(\" ..after sliding window (testing): inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
    "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c820654-1fd1-4d0e-a55e-130b31f599d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "print(\" ..after sliding window (training): inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
    "X_train = X_train.reshape((-1,SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b4557-6625-4893-ba69-6d7520f87f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665d9a1-3e17-43b5-b2d9-eda196cf8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HARModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_hidden=128, n_layers=1, n_filters=64, \n",
    "                 n_classes=5, filter_size=(1,5), drop_prob=0.5):\n",
    "        super(HARModel, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_filters = n_filters\n",
    "        self.n_classes = n_classes\n",
    "        self.filter_size = filter_size\n",
    "             \n",
    "        self.conv1 = nn.Conv2d(1, n_filters, filter_size)\n",
    "        self.conv2 = nn.Conv2d(n_filters, n_filters, filter_size)\n",
    "        self.conv3 = nn.Conv2d(n_filters, n_filters, filter_size)\n",
    "        self.conv4 = nn.Conv2d(n_filters, n_filters, filter_size)\n",
    "        self.lstm1  = nn.LSTM(7232, n_hidden, n_layers)\n",
    "        self.lstm2  = nn.LSTM(n_hidden, n_hidden, n_layers)\n",
    "        self.fc = nn.Linear(1024, n_classes)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "    \n",
    "    def forward(self, x, hidden, batch_size):\n",
    "        x = torch.permute(x, (0,2,1))\n",
    "        x = torch.unsqueeze(x, dim=1)        \n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "\n",
    "        x = torch.permute(x, (3,0,1,2))\n",
    "        x = x.view(x.shape[0], x.shape[1],-1)      \n",
    "        \n",
    "        x, hidden = self.lstm1(x, hidden)\n",
    "        x = self.dropout(x)\n",
    "        x, hidden = self.lstm2(x, hidden)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.permute(x, (1,0,2))\n",
    "        x = torch.reshape(x, (batch_size,-1))\n",
    "\n",
    "        out = self.fc(x)        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden\n",
    "    \n",
    "net = HARModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2677b12a-ecf1-4e48-aafa-2a5fab0a25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.LSTM:\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                torch.nn.init.orthogonal_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                torch.nn.init.orthogonal_(param.data)\n",
    "            elif 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "    elif type(m) == nn.Conv1d or type(m) == nn.Linear:\n",
    "        torch.nn.init.orthogonal_(m.weight)\n",
    "        m.bias.data.fill_(0)\n",
    "net.apply(init_weights)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf4b5b-2e10-43fc-8e4e-1cb59c708251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, epochs=20, batch_size=64, lr=0.01):\n",
    "    opt = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "        batch_size=batch_size, shuffle=True, drop_last = True)  \n",
    "\n",
    "    test_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "        batch_size=batch_size, shuffle=False, drop_last = True) \n",
    "    \n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "     \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # initialize hidden state\n",
    "        h = net.init_hidden(batch_size)         \n",
    "        train_losses = []    \n",
    "        net.train()\n",
    "\n",
    "        for batch in train_loader:\n",
    "            x, y = batch\n",
    "            inputs, targets = x.to(device), y.to(device)  \n",
    "            h = tuple([each.data for each in h])\n",
    "            opt.zero_grad()   \n",
    "            output, h = net(inputs, h, batch_size)\n",
    "\n",
    "            loss = criterion(output, torch.argmax(targets,dim=1))\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "        val_h = net.init_hidden(batch_size)\n",
    "        val_losses = []\n",
    "        accuracy=0\n",
    "        f1score=0\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_true = []\n",
    "        total_pred = []\n",
    "        \n",
    "        net.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                x, y = batch\n",
    "                inputs, targets = x.to(device), y.to(device)  \n",
    "                \n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                    \n",
    "                output, val_h= net(inputs, val_h, batch_size)\n",
    "\n",
    "                val_loss = criterion(output, torch.argmax(targets,dim=1))\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "                predicted = torch.argmax(output.data, dim=1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == torch.argmax(targets, dim=1)).sum().item()\n",
    "\n",
    "                total_pred = total_pred + predicted.cpu().numpy().tolist()\n",
    "                total_true = total_true + (torch.argmax(targets, dim=1).cpu().numpy().tolist())                \n",
    "                \n",
    "        net.train() # reset to train mode after iterationg through validation data\n",
    "                \n",
    "        f1_score = metrics.f1_score(y_true = total_true, y_pred = total_pred, average='weighted')     \n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "        \"Train Loss: {:.4f}...\".format(np.mean(train_losses)),\n",
    "        \"Val Loss: {:.4f}...\".format(np.mean(val_losses)),\n",
    "        \"Val Acc: {:.4f}...\".format(correct / total),\n",
    "        \"F1-Score: {:.4f}...\".format(f1_score))\n",
    "        \n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeccfaf-7e5f-49e4-881a-2bb2e68002eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'opportunity_deepConvLSTM.pt'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
